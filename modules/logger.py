#!/usr/bin/env python3
"""
ãƒ­ã‚°ç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬æƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ­ã‚°è¨­å®šã¨ç®¡ç†
"""

import json
import logging
import logging.handlers
import sys

logger = logging.getLogger(__name__)
from datetime import datetime
from pathlib import Path


class JSONFormatter(logging.Formatter):
    """JSONå½¢å¼ã§ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼"""

    def format(self, record: logging.LogRecord) -> str:
        """ãƒ­ã‚°ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’JSONå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        log_entry = {
            "timestamp": datetime.fromtimestamp(record.created).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }

        # ä¾‹å¤–æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if record.exc_info:
            log_entry["exception"] = self.formatException(record.exc_info)

        # è¿½åŠ å±æ€§ãŒã‚ã‚Œã°è¿½åŠ 
        for key, value in record.__dict__.items():
            if key not in [
                "name",
                "msg",
                "args",
                "levelname",
                "levelno",
                "pathname",
                "filename",
                "module",
                "exc_info",
                "exc_text",
                "stack_info",
                "lineno",
                "funcName",
                "created",
                "msecs",
                "relativeCreated",
                "thread",
                "threadName",
                "processName",
                "process",
                "getMessage",
            ]:
                log_entry[key] = str(value)

        return json.dumps(log_entry, ensure_ascii=False)


class ColorFormatter(logging.Formatter):
    """è‰²ä»˜ããƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ç”¨ï¼‰"""

    # ANSIã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰
    COLORS = {
        "DEBUG": "\033[36m",  # ã‚·ã‚¢ãƒ³
        "INFO": "\033[32m",  # ç·‘
        "WARNING": "\033[33m",  # é»„
        "ERROR": "\033[31m",  # èµ¤
        "CRITICAL": "\033[35m",  # ãƒã‚¼ãƒ³ã‚¿
        "RESET": "\033[0m",  # ãƒªã‚»ãƒƒãƒˆ
    }

    def format(self, record: logging.LogRecord) -> str:
        """è‰²ä»˜ãã§ãƒ­ã‚°ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        # æ¨™æº–ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formatted = super().format(record)

        # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ãŒè‰²ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹å ´åˆã®ã¿è‰²ä»˜ã‘
        if hasattr(sys.stderr, "isatty") and sys.stderr.isatty():
            color = self.COLORS.get(record.levelname, self.COLORS["RESET"])
            reset = self.COLORS["RESET"]
            return f"{color}{formatted}{reset}"

        return formatted


def setup_logging(config_manager, force_reload: bool = False) -> logging.Logger:
    """
    ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š

    Args:
        config_manager: è¨­å®šç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        force_reload (bool): å¼·åˆ¶çš„ã«å†è¨­å®šã™ã‚‹ã‹ã©ã†ã‹

    Returns:
        logging.Logger: ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼
    """
    root_logger = logging.getLogger()

    # ã™ã§ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆforce_reloadãŒç„¡åŠ¹ã®å ´åˆï¼‰
    if not force_reload and root_logger.handlers:
        return root_logger

    # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
        handler.close()

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    log_level = getattr(logging, config_manager.get_log_level().upper(), logging.INFO)
    root_logger.setLevel(log_level)

    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    log_file_path = Path(config_manager.get_log_file_path())
    log_file_path.parent.mkdir(parents=True, exist_ok=True)

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
    max_bytes = config_manager.get_log_max_file_size_mb() * 1024 * 1024
    backup_count = config_manager.get_log_backup_count()

    file_handler = logging.handlers.RotatingFileHandler(
        filename=log_file_path,
        maxBytes=max_bytes,
        backupCount=backup_count,
        encoding="utf-8",
    )

    # ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ï¼ˆé€šå¸¸ã®å½¢å¼ï¼‰
    file_format = config_manager.get_log_format()
    date_format = config_manager.get_log_date_format()
    file_formatter = logging.Formatter(file_format, date_format)
    file_handler.setFormatter(file_formatter)
    file_handler.setLevel(logging.DEBUG)  # ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯å…¨ãƒ¬ãƒ™ãƒ«ã‚’è¨˜éŒ²

    root_logger.addHandler(file_handler)

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    console_handler = logging.StreamHandler(sys.stdout)

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ï¼ˆè‰²ä»˜ãï¼‰
    console_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    console_formatter = ColorFormatter(console_format, date_format)
    console_handler.setFormatter(console_formatter)
    console_handler.setLevel(log_level)

    root_logger.addHandler(console_handler)

    # JSONå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    environment = config_manager.get_environment()
    if environment == "production":
        json_log_path = log_file_path.with_suffix(".json")
        json_handler = logging.handlers.RotatingFileHandler(
            filename=json_log_path,
            maxBytes=max_bytes,
            backupCount=backup_count,
            encoding="utf-8",
        )
        json_formatter = JSONFormatter()
        json_handler.setFormatter(json_formatter)
        json_handler.setLevel(logging.INFO)  # JSONãƒ­ã‚°ã¯INFOä»¥ä¸Š

        root_logger.addHandler(json_handler)

    # ç‰¹å®šã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«èª¿æ•´
    _configure_module_loggers()

    # åˆæœŸãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    logger.info(f"ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ (ãƒ¬ãƒ™ãƒ«: {config_manager.get_log_level()})")
    logger.info(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {log_file_path}")

    return root_logger


def _configure_module_loggers():
    """ç‰¹å®šã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´"""

    # å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´ï¼ˆãƒã‚¤ã‚ºå‰Šæ¸›ï¼‰
    noisy_loggers = [
        "urllib3.connectionpool",
        "requests.packages.urllib3.connectionpool",
        "googleapiclient.discovery",
        "googleapiclient.discovery_cache",
        "google.auth.transport.requests",
        "google_auth_httplib2",
    ]

    for logger_name in noisy_loggers:
        logging.getLogger(logger_name).setLevel(logging.WARNING)

    # HTTPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è©³ç´°ãƒ­ã‚°ï¼ˆDEBUGã®å ´åˆã®ã¿ï¼‰
    if logging.getLogger().getEffectiveLevel() <= logging.DEBUG:
        logging.getLogger("requests.packages.urllib3").setLevel(logging.DEBUG)
        logging.getLogger("urllib3").setLevel(logging.DEBUG)


def get_logger(name: str) -> logging.Logger:
    """
    åå‰ä»˜ããƒ­ã‚¬ãƒ¼ã‚’å–å¾—

    Args:
        name (str): ãƒ­ã‚¬ãƒ¼å

    Returns:
        logging.Logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    return logging.getLogger(name)


def log_execution_time(logger: logging.Logger):
    """å®Ÿè¡Œæ™‚é–“ã‚’ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""

    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = datetime.now()
            logger.debug(f"ğŸš€ {func.__name__} é–‹å§‹")

            try:
                result = func(*args, **kwargs)
                execution_time = datetime.now() - start_time
                logger.debug(f"âœ… {func.__name__} å®Œäº† (å®Ÿè¡Œæ™‚é–“: {execution_time})")
                return result
            except Exception as e:
                execution_time = datetime.now() - start_time
                logger.error(f"âŒ {func.__name__} ã‚¨ãƒ©ãƒ¼ (å®Ÿè¡Œæ™‚é–“: {execution_time}): {e}")
                raise

        return wrapper

    return decorator


def log_rate_limit(logger: logging.Logger, max_calls: int, time_window: int):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ããƒ­ã‚°å‡ºåŠ›"""
    call_times = []

    def rate_limited_log(level: int, message: str, *args, **kwargs):
        now = datetime.now()

        # æ™‚é–“æ å†…ã®å‘¼ã³å‡ºã—ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        call_times[:] = [t for t in call_times if (now - t).total_seconds() < time_window]

        if len(call_times) < max_calls:
            call_times.append(now)
            logger.log(level, message, *args, **kwargs)
        else:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ãŸå ´åˆã¯ã€æœ€åˆã®åˆ¶é™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ãƒ­ã‚°å‡ºåŠ›
            if len(call_times) == max_calls:
                logger.warning(f"ãƒ­ã‚°ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸ (æœ€å¤§ {max_calls} å›/{time_window}ç§’)")

    return rate_limited_log


class LogContext:
    """ãƒ­ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, logger: logging.Logger, **context):
        """
        Args:
            logger (logging.Logger): ãƒ­ã‚¬ãƒ¼
            **context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
        """
        self.logger = logger
        self.context = context

    def __enter__(self):
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’ãƒ­ã‚¬ãƒ¼ã«è¿½åŠ 
        for key, value in self.context.items():
            setattr(self.logger, key, value)
        return self.logger

    def __exit__(self, exc_type, exc_val, exc_tb):
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å‰Šé™¤
        for key in self.context.keys():
            if hasattr(self.logger, key):
                delattr(self.logger, key)


def with_log_context(logger: logging.Logger, **context):
    """
    ãƒ­ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®šã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼

    Usage:
        with with_log_context(logger, work_id=123, source="anilist"):
            logger.info("ä½œå“ã‚’å‡¦ç†ä¸­")  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ãŒè‡ªå‹•çš„ã«å«ã¾ã‚Œã‚‹
    """
    return LogContext(logger, **context)


class PerformanceLogger:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šç”¨ãƒ­ã‚¬ãƒ¼"""

    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.timers = {}

    def start_timer(self, name: str):
        """ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹"""
        self.timers[name] = datetime.now()
        self.logger.debug(f"â±ï¸ ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹: {name}")

    def stop_timer(self, name: str) -> float:
        """ã‚¿ã‚¤ãƒãƒ¼çµ‚äº†"""
        if name not in self.timers:
            self.logger.warning(f"ã‚¿ã‚¤ãƒãƒ¼ '{name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return 0.0

        elapsed = (datetime.now() - self.timers[name]).total_seconds()
        del self.timers[name]

        self.logger.info(f"â±ï¸ {name}: {elapsed:.3f}ç§’")
        return elapsed

    def log_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        try:
            import psutil

            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            self.logger.debug(f"ğŸ§  ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_mb:.1f}MB")
        except ImportError:
            self.logger.debug("psutilãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯æ¸¬å®šã§ãã¾ã›ã‚“ã€‚")


# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ­ã‚¬ãƒ¼
_module_logger = logging.getLogger(__name__)


def setup_test_logging():
    """ãƒ†ã‚¹ãƒˆç”¨ã®ç°¡æ˜“ãƒ­ã‚°è¨­å®š"""
    logging.basicConfig(
        level=logging.DEBUG,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[logging.StreamHandler(sys.stdout)],
    )


class StructuredLogger:
    """
    æ§‹é€ åŒ–ãƒ­ã‚°å‡ºåŠ›ã®ãŸã‚ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹

    ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã§ä¸€è²«ã—ãŸå½¢å¼ã®ãƒ­ã‚°å‡ºåŠ›ã‚’æä¾›ã—ã€
    å¾Œã‹ã‚‰ã®è§£æãƒ»ç›£è¦–ã‚’å®¹æ˜“ã«ã™ã‚‹ã€‚
    """

    def __init__(self, logger: logging.Logger):
        self.logger = logger

    def log_api_call(
        self,
        source: str,
        url: str,
        status_code: int = None,
        response_time: float = None,
        error: str = None,
    ):
        """APIå‘¼ã³å‡ºã—ãƒ­ã‚°"""
        log_data = {
            "event_type": "api_call",
            "source": source,
            "url": url,
            "status_code": status_code,
            "response_time_ms": round(response_time * 1000) if response_time else None,
            "error": error,
        }

        if error:
            self.logger.error(f"APIå‘¼ã³å‡ºã—å¤±æ•—: {source} - {error}", extra=log_data)
        else:
            self.logger.info(f"APIå‘¼ã³å‡ºã—æˆåŠŸ: {source} ({status_code})", extra=log_data)

    def log_data_processing(
        self,
        stage: str,
        input_count: int,
        output_count: int,
        filtered_count: int = 0,
        duration: float = None,
    ):
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚°"""
        log_data = {
            "event_type": "data_processing",
            "stage": stage,
            "input_count": input_count,
            "output_count": output_count,
            "filtered_count": filtered_count,
            "duration_ms": round(duration * 1000) if duration else None,
        }

        self.logger.info(
            f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {stage} ({input_count}â†’{output_count}, {filtered_count}ä»¶é™¤å¤–)",
            extra=log_data,
        )

    def log_notification_sent(
        self,
        notification_type: str,
        recipient: str,
        item_count: int,
        success: bool,
        error: str = None,
    ):
        """é€šçŸ¥é€ä¿¡ãƒ­ã‚°"""
        log_data = {
            "event_type": "notification",
            "type": notification_type,
            "recipient": recipient,
            "item_count": item_count,
            "success": success,
            "error": error,
        }

        if success:
            self.logger.info(f"é€šçŸ¥é€ä¿¡æˆåŠŸ: {notification_type} ({item_count}ä»¶)", extra=log_data)
        else:
            self.logger.error(f"é€šçŸ¥é€ä¿¡å¤±æ•—: {notification_type} - {error}", extra=log_data)

    def log_system_event(self, event_type: str, message: str, **metadata):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°"""
        log_data = {
            "event_type": "system_event",
            "system_event_type": event_type,
            **metadata,
        }

        self.logger.info(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ™ãƒ³ãƒˆ: {message}", extra=log_data)


def create_structured_logger(name: str) -> StructuredLogger:
    """æ§‹é€ åŒ–ãƒ­ã‚¬ãƒ¼ã®ä½œæˆ"""
    return StructuredLogger(logging.getLogger(name))
