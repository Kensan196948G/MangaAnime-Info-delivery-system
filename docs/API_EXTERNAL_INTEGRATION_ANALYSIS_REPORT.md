# APIãƒ»å¤–éƒ¨é€£æºè§£æãƒ¬ãƒãƒ¼ãƒˆ

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: MangaAnime-Info-delivery-system
**è§£ææ—¥æ™‚**: 2025-12-06
**è§£æè€…**: Backend Developer Agent

---

## ğŸ“‹ ç›®æ¬¡

1. [ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼](#ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼)
2. [AniList GraphQL APIè§£æ](#anilist-graphql-apiè§£æ)
3. [ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼APIè§£æ](#ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼apiè§£æ)
4. [ãƒãƒ³ã‚¬RSSãƒ•ã‚£ãƒ¼ãƒ‰è§£æ](#ãƒãƒ³ã‚¬rssãƒ•ã‚£ãƒ¼ãƒ‰è§£æ)
5. [Gmail APIé€£æºè§£æ](#gmail-apié€£æºè§£æ)
6. [Google Calendar APIé€£æºè§£æ](#google-calendar-apié€£æºè§£æ)
7. [è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è§£æ](#è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è§£æ)
8. [ç·åˆè©•ä¾¡ã¨æ¨å¥¨äº‹é …](#ç·åˆè©•ä¾¡ã¨æ¨å¥¨äº‹é …)

---

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

### è§£æå¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- `modules/anime_anilist.py` - AniList GraphQL API
- `modules/anime_syoboi.py` - ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼API
- `modules/manga_rss.py` - ãƒãƒ³ã‚¬RSSãƒ•ã‚£ãƒ¼ãƒ‰
- `modules/mailer.py` - Gmail API
- `modules/calendar_integration.py` - Google Calendar API
- `config.json` - ã‚·ã‚¹ãƒ†ãƒ è¨­å®š

### ä¸»è¦ãªç™ºè¦‹äº‹é …

#### âœ… å¼·ã¿
- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã•ã‚ŒãŸè¨­è¨ˆ
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å®Ÿè£…
- ãƒ­ã‚°è¨˜éŒ²ã®ä¸€è²«æ€§

#### âš ï¸ æ”¹å–„ç‚¹
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œã®ä¸è¶³
- ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã®ä¸å®Œå…¨æ€§
- è¨­å®šã®å¤–éƒ¨åŒ–ä¸è¶³
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®æ¬ å¦‚

---

## AniList GraphQL APIè§£æ

### ãƒ•ã‚¡ã‚¤ãƒ«: `modules/anime_anilist.py`

#### æ¥ç¶šçŠ¶æ…‹

**ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**:
```python
ANILIST_API_URL = "https://graphql.anilist.co"
```

**èªè¨¼**: ä¸è¦ï¼ˆãƒ‘ãƒ–ãƒªãƒƒã‚¯APIï¼‰

#### ãƒ¬ãƒ¼ãƒˆåˆ¶é™

**å…¬å¼åˆ¶é™**: 90ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/åˆ†

**ç¾åœ¨ã®å®Ÿè£…**:
```python
# ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ: æœªå®Ÿè£…
# âš ï¸ å•é¡Œ: ãƒãƒ¼ã‚¹ãƒˆçš„ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã§åˆ¶é™ã«åˆ°é”ã™ã‚‹å¯èƒ½æ€§
```

**æ¨å¥¨å®Ÿè£…**:
```python
import time
from functools import wraps

def rate_limit(calls=90, period=60):
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def decorator(func):
        timestamps = []
        @wraps(func)
        def wrapper(*args, **kwargs):
            now = time.time()
            timestamps[:] = [t for t in timestamps if now - t < period]
            if len(timestamps) >= calls:
                sleep_time = period - (now - timestamps[0])
                time.sleep(sleep_time)
            timestamps.append(time.time())
            return func(*args, **kwargs)
        return wrapper
    return decorator
```

#### GraphQLã‚¯ã‚¨ãƒªå“è³ª

**ç¾åœ¨ã®ã‚¯ã‚¨ãƒªä¾‹**:
```graphql
query ($page: Int, $perPage: Int, $season: MediaSeason, $seasonYear: Int) {
  Page(page: $page, perPage: $perPage) {
    media(season: $season, seasonYear: $seasonYear, type: ANIME) {
      id
      title { romaji native english }
      startDate { year month day }
      episodes
      genres
      coverImage { large }
    }
  }
}
```

**è©•ä¾¡**: âœ… é©åˆ‡ãªæœ€å°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å–å¾—

#### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**ç¾åœ¨ã®å®Ÿè£…**:
```python
try:
    response = requests.post(ANILIST_API_URL, json=payload)
    response.raise_for_status()
except requests.RequestException as e:
    logging.error(f"AniList API error: {e}")
    return []
```

**å•é¡Œç‚¹**:
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šãªã—
- ãƒªãƒˆãƒ©ã‚¤ãªã—
- GraphQLã‚¨ãƒ©ãƒ¼ï¼ˆ200ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ã‚‚ã‚¨ãƒ©ãƒ¼ï¼‰ã®æœªå‡¦ç†

**æ¨å¥¨å®Ÿè£…**:
```python
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

def get_session_with_retry():
    session = requests.Session()
    retry = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[500, 502, 503, 504]
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('https://', adapter)
    return session

@rate_limit(calls=90, period=60)
def fetch_anilist_data(query, variables):
    session = get_session_with_retry()
    try:
        response = session.post(
            ANILIST_API_URL,
            json={'query': query, 'variables': variables},
            timeout=10
        )
        response.raise_for_status()
        data = response.json()

        # GraphQLã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        if 'errors' in data:
            logging.error(f"GraphQL errors: {data['errors']}")
            return None

        return data.get('data')
    except requests.Timeout:
        logging.error("AniList API timeout")
        return None
    except requests.RequestException as e:
        logging.error(f"AniList API error: {e}")
        return None
```

---

## ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼APIè§£æ

### ãƒ•ã‚¡ã‚¤ãƒ«: `modules/anime_syoboi.py`

#### æ¥ç¶šçŠ¶æ…‹

**ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**:
```python
SYOBOI_API_URL = "https://cal.syoboi.jp/db.php"
```

**èªè¨¼**: ä¸è¦

#### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­è¨ˆ

**ç¾åœ¨ã®å®Ÿè£…**:
```python
params = {
    'Command': 'ProgLookup',
    'Range': f'{start_date}-{end_date}',
    'Fields': 'TID,Title,StTime,ChName'
}
```

**è©•ä¾¡**: âœ… å¿…è¦ååˆ†ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å–å¾—

#### ãƒ¬ãƒ¼ãƒˆåˆ¶é™

**å…¬å¼æƒ…å ±**: æ˜ç¤ºçš„ãªåˆ¶é™ãªã—ï¼ˆéå…¬å¼APIã®ãŸã‚é…æ…®å¿…è¦ï¼‰

**æ¨å¥¨å¯¾å¿œ**:
```python
import time

# 1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’ã®æ§ãˆã‚ãªåˆ¶é™
@rate_limit(calls=1, period=1)
def fetch_syoboi_data(start_date, end_date):
    # å®Ÿè£…
    pass
```

#### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**ç¾åœ¨ã®å•é¡Œ**:
- XML/JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®æœªå‡¦ç†
- æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œï¼ˆShift_JISï¼‰ã®ä¸å®Œå…¨ãªå‡¦ç†

**æ¨å¥¨å®Ÿè£…**:
```python
def fetch_syoboi_data(start_date, end_date):
    try:
        response = requests.get(
            SYOBOI_API_URL,
            params=params,
            timeout=10
        )
        response.encoding = 'shift_jis'  # æ˜ç¤ºçš„ã«è¨­å®š
        response.raise_for_status()

        # XMLãƒ‘ãƒ¼ã‚¹
        import xml.etree.ElementTree as ET
        try:
            root = ET.fromstring(response.content)
        except ET.ParseError as e:
            logging.error(f"XML parse error: {e}")
            return []

        return parse_syoboi_xml(root)
    except Exception as e:
        logging.error(f"Syoboi API error: {e}")
        return []
```

---

## ãƒãƒ³ã‚¬RSSãƒ•ã‚£ãƒ¼ãƒ‰è§£æ

### ãƒ•ã‚¡ã‚¤ãƒ«: `modules/manga_rss.py`

#### å¯¾å¿œRSSã‚½ãƒ¼ã‚¹

**ç¾åœ¨ã®è¨­å®š**:
```python
RSS_SOURCES = {
    "bookwalker": {
        "url": "https://bookwalker.jp/rss/",
        "enabled": True
    },
    "magapoke": {
        "url": "https://pocket.shonenmagazine.com/rss",
        "enabled": True
    },
    "jump_bookstore": {
        "url": "https://jumpbookstore.com/rss/new",
        "enabled": False  # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå»ƒæ­¢ã«ã‚ˆã‚Šç„¡åŠ¹åŒ–
    },
    "rakuten_kobo": {
        "url": "https://books.rakuten.co.jp/rss/new-comics/",
        "enabled": True
    }
}
```

#### ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—ãƒ­ã‚¸ãƒƒã‚¯

**feedparserãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨**:
```python
import feedparser

def fetch_rss_feed(url):
    try:
        feed = feedparser.parse(url)
        if feed.bozo:  # ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
            logging.warning(f"RSS parse warning: {feed.bozo_exception}")
        return feed.entries
    except Exception as e:
        logging.error(f"RSS fetch error: {e}")
        return []
```

**è©•ä¾¡**: âœ… feedparserã¯å …ç‰¢ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª

#### å•é¡Œç‚¹ã¨æ¨å¥¨å¯¾å¿œ

**ç¾åœ¨ã®å•é¡Œ**:
1. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ï¼ˆfeedparserã¯å†…éƒ¨ã§urllibã‚’ä½¿ç”¨ï¼‰
2. User-Agentæœªè¨­å®šï¼ˆä¸€éƒ¨ã‚µã‚¤ãƒˆã§ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹å¯èƒ½æ€§ï¼‰
3. ETags/Last-Modifiedéå¯¾å¿œï¼ˆç„¡é§„ãªå¸¯åŸŸæ¶ˆè²»ï¼‰

**æ¨å¥¨å®Ÿè£…**:
```python
import feedparser
import requests

def fetch_rss_feed_improved(url, etag=None, modified=None):
    """
    ETags/Last-Modifiedã«å¯¾å¿œã—ãŸRSSãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—
    """
    headers = {
        'User-Agent': 'MangaAnime-Info-Bot/1.0 (+https://example.com/bot)'
    }

    if etag:
        headers['If-None-Match'] = etag
    if modified:
        headers['If-Modified-Since'] = modified

    try:
        response = requests.get(url, headers=headers, timeout=15)

        if response.status_code == 304:
            logging.info(f"RSS not modified: {url}")
            return None, etag, modified

        response.raise_for_status()

        feed = feedparser.parse(response.content)
        new_etag = response.headers.get('ETag')
        new_modified = response.headers.get('Last-Modified')

        return feed.entries, new_etag, new_modified
    except Exception as e:
        logging.error(f"RSS fetch error for {url}: {e}")
        return [], None, None
```

#### RSSã‚½ãƒ¼ã‚¹ç®¡ç†

**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒè¿½åŠ æ¨å¥¨**:
```sql
CREATE TABLE rss_sources (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    url TEXT NOT NULL,
    enabled INTEGER DEFAULT 1,
    etag TEXT,
    last_modified TEXT,
    last_fetch DATETIME,
    error_count INTEGER DEFAULT 0,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

---

## Gmail APIé€£æºè§£æ

### ãƒ•ã‚¡ã‚¤ãƒ«: `modules/mailer.py`

#### èªè¨¼çŠ¶æ…‹

**OAuth2.0ãƒ•ãƒ­ãƒ¼**:
```python
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

SCOPES = ['https://www.googleapis.com/auth/gmail.send']

def get_gmail_service():
    creds = None
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)

    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                'credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)

        with open('token.json', 'w') as token:
            token.write(creds.to_json())

    return build('gmail', 'v1', credentials=creds)
```

**è©•ä¾¡**: âœ… æ¨™æº–çš„ãªOAuth2.0å®Ÿè£…

#### ãƒ¡ãƒ¼ãƒ«é€ä¿¡å®Ÿè£…

**ç¾åœ¨ã®å®Ÿè£…**:
```python
def send_email(to, subject, body_html):
    try:
        service = get_gmail_service()
        message = create_message(to, subject, body_html)
        send_message(service, 'me', message)
        logging.info(f"Email sent to {to}")
    except Exception as e:
        logging.error(f"Email send error: {e}")
```

**å•é¡Œç‚¹**:
1. ãƒ¬ãƒ¼ãƒˆåˆ¶é™æœªå¯¾å¿œï¼ˆGmail API: 100é€š/ç§’ï¼‰
2. ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒªãƒˆãƒ©ã‚¤ãªã—
3. ãƒãƒƒãƒé€ä¿¡æœªå¯¾å¿œ

**æ¨å¥¨å®Ÿè£…**:
```python
from googleapiclient.errors import HttpError
import time

@rate_limit(calls=100, period=1)  # 100é€š/ç§’åˆ¶é™
def send_email_with_retry(to, subject, body_html, max_retries=3):
    """
    ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ããƒ¡ãƒ¼ãƒ«é€ä¿¡
    """
    service = get_gmail_service()
    message = create_message(to, subject, body_html)

    for attempt in range(max_retries):
        try:
            send_message(service, 'me', message)
            logging.info(f"Email sent to {to}")
            return True
        except HttpError as e:
            if e.resp.status in [403, 429]:  # Rate limit
                wait_time = 2 ** attempt
                logging.warning(f"Rate limited, waiting {wait_time}s")
                time.sleep(wait_time)
            else:
                logging.error(f"Email send error: {e}")
                return False

    logging.error(f"Failed to send email after {max_retries} retries")
    return False

def send_batch_emails(recipients_data):
    """
    ãƒãƒƒãƒãƒ¡ãƒ¼ãƒ«é€ä¿¡ï¼ˆè¤‡æ•°å®›å…ˆï¼‰
    """
    results = []
    for data in recipients_data:
        result = send_email_with_retry(
            data['to'],
            data['subject'],
            data['body']
        )
        results.append(result)
        time.sleep(0.01)  # æœ€ä½10msé–“éš”

    return results
```

#### HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå“è³ª

**è©•ä¾¡é …ç›®**:
- ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³: âœ… å®Ÿè£…æ¸ˆã¿
- ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£: âš ï¸ altå±æ€§ä¸è¶³
- ã‚¹ãƒ‘ãƒ ãƒ•ã‚£ãƒ«ã‚¿å¯¾ç­–: âš ï¸ è¦æ”¹å–„

**æ¨å¥¨æ”¹å–„**:
```html
<!-- ç”»åƒã®altå±æ€§å¿…é ˆ -->
<img src="{{cover_image}}" alt="{{title}}ã®ã‚«ãƒãƒ¼ç”»åƒ" style="max-width:100%;">

<!-- ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç‰ˆã‚‚æä¾› -->
Content-Type: multipart/alternative;
```

---

## Google Calendar APIé€£æºè§£æ

### ãƒ•ã‚¡ã‚¤ãƒ«: `modules/calendar_integration.py`

#### èªè¨¼çŠ¶æ…‹

**OAuth2.0ã‚¹ã‚³ãƒ¼ãƒ—**:
```python
SCOPES = ['https://www.googleapis.com/auth/calendar']
```

**è©•ä¾¡**: âœ… é©åˆ‡ï¼ˆæœ€å°æ¨©é™ã®åŸå‰‡ã«åã™ã‚‹ãŒã€æ©Ÿèƒ½çš„ã«å¿…è¦ï¼‰

#### ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆå®Ÿè£…

**ç¾åœ¨ã®å®Ÿè£…**:
```python
def add_calendar_event(title, date, description, url):
    try:
        service = get_calendar_service()
        event = {
            'summary': title,
            'description': f"{description}\n{url}",
            'start': {
                'date': date,
                'timeZone': 'Asia/Tokyo',
            },
            'end': {
                'date': date,
                'timeZone': 'Asia/Tokyo',
            }
        }

        result = service.events().insert(
            calendarId='primary',
            body=event
        ).execute()

        logging.info(f"Calendar event created: {result['id']}")
    except Exception as e:
        logging.error(f"Calendar event error: {e}")
```

**å•é¡Œç‚¹**:
1. é‡è¤‡ã‚¤ãƒ™ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯ãªã—
2. ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼IDå›ºå®šï¼ˆprimaryï¼‰
3. ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼æœªè¨­å®š
4. è‰²åˆ†ã‘ãªã—

**æ¨å¥¨å®Ÿè£…**:
```python
from datetime import datetime, timedelta

def add_calendar_event_enhanced(title, date, description, url, category='anime'):
    """
    æ‹¡å¼µã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ
    """
    service = get_calendar_service()

    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    existing = check_existing_event(service, title, date)
    if existing:
        logging.info(f"Event already exists: {existing['id']}")
        return existing['id']

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥è‰²è¨­å®š
    color_map = {
        'anime': '9',      # é’
        'manga': '10',     # ç·‘
        'movie': '11',     # èµ¤
    }

    event = {
        'summary': title,
        'description': f"{description}\n\nURL: {url}",
        'start': {
            'date': date,
            'timeZone': 'Asia/Tokyo',
        },
        'end': {
            'date': date,
            'timeZone': 'Asia/Tokyo',
        },
        'colorId': color_map.get(category, '1'),
        'reminders': {
            'useDefault': False,
            'overrides': [
                {'method': 'popup', 'minutes': 60},
                {'method': 'popup', 'minutes': 1440},  # 1æ—¥å‰
            ],
        },
        'source': {
            'title': 'MangaAnime Info System',
            'url': url
        }
    }

    try:
        result = service.events().insert(
            calendarId='primary',
            body=event
        ).execute()

        logging.info(f"Calendar event created: {result['id']}")
        return result['id']
    except HttpError as e:
        logging.error(f"Calendar event error: {e}")
        return None

def check_existing_event(service, title, date):
    """
    æ—¢å­˜ã‚¤ãƒ™ãƒ³ãƒˆã®ç¢ºèª
    """
    time_min = f"{date}T00:00:00+09:00"
    time_max = f"{date}T23:59:59+09:00"

    events_result = service.events().list(
        calendarId='primary',
        timeMin=time_min,
        timeMax=time_max,
        q=title,
        singleEvents=True
    ).execute()

    events = events_result.get('items', [])
    for event in events:
        if event.get('summary') == title:
            return event

    return None
```

#### ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åŒæœŸæˆ¦ç•¥

**3ãƒ¶æœˆè¡¨ç¤ºæ©Ÿèƒ½ã®å®Ÿè£…**:
```python
def sync_calendar_3months():
    """
    3ãƒ¶æœˆåˆ†ã®ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã‚’ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«åŒæœŸ
    """
    from datetime import datetime, timedelta
    import sqlite3

    conn = sqlite3.connect('db.sqlite3')
    cursor = conn.cursor()

    today = datetime.now().date()
    end_date = today + timedelta(days=90)

    query = """
        SELECT w.title, r.release_date, r.platform, r.release_type, r.number
        FROM releases r
        JOIN works w ON r.work_id = w.id
        WHERE r.release_date BETWEEN ? AND ?
        AND r.calendar_synced = 0
        ORDER BY r.release_date
    """

    cursor.execute(query, (today, end_date))
    releases = cursor.fetchall()

    synced_count = 0
    for title, date, platform, rel_type, number in releases:
        event_title = f"{title} - {rel_type} {number}"
        description = f"Platform: {platform}"

        event_id = add_calendar_event_enhanced(
            event_title, date, description, ""
        )

        if event_id:
            # åŒæœŸãƒ•ãƒ©ã‚°æ›´æ–°
            cursor.execute(
                "UPDATE releases SET calendar_synced = 1 WHERE work_id = ?",
                (title,)
            )
            synced_count += 1

    conn.commit()
    conn.close()

    logging.info(f"Synced {synced_count} events to calendar")
    return synced_count
```

---

## è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è§£æ

### ãƒ•ã‚¡ã‚¤ãƒ«: `config.json`

#### ç¾åœ¨ã®æ§‹é€ 

```json
{
  "anime_sources": {
    "anilist": {
      "enabled": true,
      "api_url": "https://graphql.anilist.co"
    },
    "syoboi": {
      "enabled": true,
      "api_url": "https://cal.syoboi.jp/db.php"
    }
  },
  "manga_sources": {
    "rss_feeds": [
      {
        "name": "BookWalker",
        "url": "https://bookwalker.jp/rss/",
        "enabled": true
      },
      {
        "name": "MagaPoke",
        "url": "https://pocket.shonenmagazine.com/rss",
        "enabled": true
      }
    ]
  },
  "notification": {
    "email": {
      "enabled": true,
      "recipients": ["user@example.com"]
    },
    "calendar": {
      "enabled": true,
      "calendar_id": "primary"
    }
  },
  "filter": {
    "ng_keywords": ["ã‚¨ãƒ­", "R18", "æˆäººå‘ã‘", "BL", "ç™¾åˆ"]
  },
  "schedule": {
    "run_time": "08:00",
    "timezone": "Asia/Tokyo"
  }
}
```

#### è©•ä¾¡

**âœ… è‰¯ã„ç‚¹**:
- æ§‹é€ åŒ–ã•ã‚ŒãŸè¨­å®š
- å„ã‚½ãƒ¼ã‚¹ã®ON/OFFåˆ¶å¾¡å¯èƒ½

**âš ï¸ æ”¹å–„ç‚¹**:
1. æ©Ÿå¯†æƒ…å ±ã®æ··åœ¨ï¼ˆç’°å¢ƒå¤‰æ•°åŒ–ã™ã¹ãï¼‰
2. ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ãªã—
3. ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ãªã—

#### æ¨å¥¨æ”¹å–„

**1. ç’°å¢ƒå¤‰æ•°ã¸ã®åˆ†é›¢**:

```bash
# .env
GMAIL_CREDENTIALS_PATH=/path/to/credentials.json
GMAIL_TOKEN_PATH=/path/to/token.json
CALENDAR_CREDENTIALS_PATH=/path/to/cal_credentials.json
NOTIFICATION_EMAIL=user@example.com
DATABASE_PATH=/path/to/db.sqlite3
LOG_LEVEL=INFO
```

**2. è¨­å®šã‚¹ã‚­ãƒ¼ãƒå®šç¾©**:

```python
# config/schema.py
from pydantic import BaseModel, HttpUrl, validator
from typing import List, Optional

class AnimeSourceConfig(BaseModel):
    enabled: bool
    api_url: HttpUrl

class RSSFeedConfig(BaseModel):
    name: str
    url: HttpUrl
    enabled: bool

class EmailNotificationConfig(BaseModel):
    enabled: bool
    recipients: List[str]

    @validator('recipients')
    def validate_emails(cls, v):
        import re
        email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        for email in v:
            if not re.match(email_regex, email):
                raise ValueError(f'Invalid email: {email}')
        return v

class Config(BaseModel):
    anime_sources: dict
    manga_sources: dict
    notification: dict
    filter: dict
    schedule: dict
```

**3. è¨­å®šèª­ã¿è¾¼ã¿ãƒ˜ãƒ«ãƒ‘ãƒ¼**:

```python
# modules/config_helper.py
import json
import os
from pathlib import Path
from typing import Optional

class ConfigManager:
    """è¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_path: str = "config.json"):
        self.config_path = Path(config_path)
        self._config = None
        self.load()

    def load(self) -> dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        if not self.config_path.exists():
            raise FileNotFoundError(f"Config file not found: {self.config_path}")

        with open(self.config_path, 'r', encoding='utf-8') as f:
            self._config = json.load(f)

        # ç’°å¢ƒå¤‰æ•°ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
        self._apply_env_overrides()

        return self._config

    def _apply_env_overrides(self):
        """ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¨­å®šã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰"""
        if email := os.getenv('NOTIFICATION_EMAIL'):
            self._config['notification']['email']['recipients'] = [email]

        if db_path := os.getenv('DATABASE_PATH'):
            self._config['database_path'] = db_path

    def get(self, key: str, default=None):
        """ãƒ‰ãƒƒãƒˆè¨˜æ³•ã§ã®è¨­å®šå–å¾—"""
        keys = key.split('.')
        value = self._config

        for k in keys:
            if isinstance(value, dict):
                value = value.get(k)
            else:
                return default

        return value if value is not None else default

    def is_enabled(self, source_path: str) -> bool:
        """ã‚½ãƒ¼ã‚¹ã®æœ‰åŠ¹/ç„¡åŠ¹ãƒã‚§ãƒƒã‚¯"""
        return self.get(f"{source_path}.enabled", False)

# ä½¿ç”¨ä¾‹
config = ConfigManager()
if config.is_enabled('anime_sources.anilist'):
    # AniList APIã‚’ä½¿ç”¨
    pass
```

---

## ç·åˆè©•ä¾¡ã¨æ¨å¥¨äº‹é …

### è©•ä¾¡ã‚µãƒãƒªãƒ¼

| é …ç›® | ç¾çŠ¶ | è©•ä¾¡ | å„ªå…ˆåº¦ |
|------|------|------|--------|
| AniList API | åŸºæœ¬å®Ÿè£…æ¸ˆã¿ | âš ï¸ | é«˜ |
| ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ | åŸºæœ¬å®Ÿè£…æ¸ˆã¿ | âš ï¸ | ä¸­ |
| RSS ãƒ•ã‚£ãƒ¼ãƒ‰ | å®Ÿè£…æ¸ˆã¿ | âš ï¸ | ä¸­ |
| Gmail API | å®Ÿè£…æ¸ˆã¿ | âš ï¸ | é«˜ |
| Calendar API | å®Ÿè£…æ¸ˆã¿ | âš ï¸ | é«˜ |
| è¨­å®šç®¡ç† | JSONå®Ÿè£… | âš ï¸ | é«˜ |

### ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªé …ç›®ï¼ˆPriority: Highï¼‰

#### 1. ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å®Ÿè£…

**å½±éŸ¿**: APIåˆ¶é™ã«ã‚ˆã‚‹ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ãƒªã‚¹ã‚¯

**å¯¾ç­–**:
```python
# modules/rate_limiter.py ã‚’ä½œæˆ
import time
from collections import deque
from functools import wraps
import threading

class RateLimiter:
    """ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¯ãƒ©ã‚¹"""

    def __init__(self, calls: int, period: int):
        self.calls = calls
        self.period = period
        self.timestamps = deque()
        self.lock = threading.Lock()

    def __call__(self, func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            with self.lock:
                now = time.time()

                # æœŸé–“å¤–ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å‰Šé™¤
                while self.timestamps and now - self.timestamps[0] >= self.period:
                    self.timestamps.popleft()

                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
                if len(self.timestamps) >= self.calls:
                    sleep_time = self.period - (now - self.timestamps[0])
                    time.sleep(sleep_time)
                    now = time.time()

                self.timestamps.append(now)

            return func(*args, **kwargs)

        return wrapper

# ä½¿ç”¨ä¾‹
anilist_limiter = RateLimiter(calls=90, period=60)
gmail_limiter = RateLimiter(calls=100, period=1)
```

#### 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–

**å½±éŸ¿**: ä¸€æ™‚çš„ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã§ã‚·ã‚¹ãƒ†ãƒ åœæ­¢

**å¯¾ç­–**:
```python
# modules/error_handler.py
from functools import wraps
import logging
import time
from typing import Callable, Optional

class RetryConfig:
    """ãƒªãƒˆãƒ©ã‚¤è¨­å®š"""
    def __init__(
        self,
        max_retries: int = 3,
        backoff_factor: float = 2.0,
        retry_on: tuple = (Exception,)
    ):
        self.max_retries = max_retries
        self.backoff_factor = backoff_factor
        self.retry_on = retry_on

def with_retry(config: Optional[RetryConfig] = None):
    """ãƒªãƒˆãƒ©ã‚¤ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    if config is None:
        config = RetryConfig()

    def decorator(func: Callable):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None

            for attempt in range(config.max_retries):
                try:
                    return func(*args, **kwargs)
                except config.retry_on as e:
                    last_exception = e
                    if attempt < config.max_retries - 1:
                        wait_time = config.backoff_factor ** attempt
                        logging.warning(
                            f"{func.__name__} failed (attempt {attempt + 1}), "
                            f"retrying in {wait_time}s: {e}"
                        )
                        time.sleep(wait_time)

            logging.error(
                f"{func.__name__} failed after {config.max_retries} retries"
            )
            raise last_exception

        return wrapper

    return decorator

# ä½¿ç”¨ä¾‹
@with_retry(RetryConfig(max_retries=3, backoff_factor=2.0))
@anilist_limiter
def fetch_anilist_data(query, variables):
    # å®Ÿè£…
    pass
```

#### 3. è¨­å®šç®¡ç†ã®ç’°å¢ƒå¤‰æ•°åŒ–

**å½±éŸ¿**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ï¼ˆèªè¨¼æƒ…å ±ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ï¼‰

**å¯¾ç­–**:
```bash
# .env.example ã‚’ä½œæˆ
cp config.json config.json.example
# æ©Ÿå¯†æƒ…å ±ã‚’å‰Šé™¤ã—ã¦Gitã«è¿½åŠ 

# .gitignore ã«è¿½åŠ 
echo "config.json" >> .gitignore
echo ".env" >> .gitignore
echo "token.json" >> .gitignore
echo "credentials.json" >> .gitignore
```

### ä¸­å„ªå…ˆåº¦ã®æ”¹å–„é …ç›®ï¼ˆPriority: Mediumï¼‰

#### 4. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®è¿½åŠ 

**ã™ã¹ã¦ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ä»¥ä¸‹ã‚’é©ç”¨**:
```python
DEFAULT_TIMEOUT = 10  # ç§’

response = requests.get(url, timeout=DEFAULT_TIMEOUT)
```

#### 5. ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®æœ€é©åŒ–

```python
# modules/logger.py
import logging
import os
from logging.handlers import RotatingFileHandler

def setup_logger(name: str, log_file: str, level=logging.INFO):
    """ãƒ­ã‚¬ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    handler = RotatingFileHandler(
        log_file,
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    handler.setFormatter(formatter)

    logger = logging.getLogger(name)
    logger.setLevel(level)
    logger.addHandler(handler)

    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã‚‚è¿½åŠ 
    console = logging.StreamHandler()
    console.setFormatter(formatter)
    logger.addHandler(console)

    return logger
```

#### 6. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã®æ‹¡å¼µ

**RSSç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ **:
```sql
-- migrations/004_rss_management.sql
CREATE TABLE IF NOT EXISTS rss_sources (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    url TEXT NOT NULL,
    enabled INTEGER DEFAULT 1,
    etag TEXT,
    last_modified TEXT,
    last_fetch DATETIME,
    last_success DATETIME,
    error_count INTEGER DEFAULT 0,
    last_error TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_rss_enabled ON rss_sources(enabled);
CREATE INDEX idx_rss_last_fetch ON rss_sources(last_fetch);
```

### ä½å„ªå…ˆåº¦ã®æ©Ÿèƒ½æ‹¡å¼µï¼ˆPriority: Lowï¼‰

#### 7. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã®è¿½åŠ 

```python
# modules/cache.py
import json
import hashlib
from datetime import datetime, timedelta
from pathlib import Path

class SimpleCache:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""

    def __init__(self, cache_dir: str = ".cache", ttl: int = 3600):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.ttl = ttl

    def _get_cache_path(self, key: str) -> Path:
        """ã‚­ãƒ¼ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        hashed = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{hashed}.json"

    def get(self, key: str):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—"""
        cache_path = self._get_cache_path(key)

        if not cache_path.exists():
            return None

        with open(cache_path, 'r') as f:
            data = json.load(f)

        # TTLãƒã‚§ãƒƒã‚¯
        cached_at = datetime.fromisoformat(data['cached_at'])
        if datetime.now() - cached_at > timedelta(seconds=self.ttl):
            cache_path.unlink()
            return None

        return data['value']

    def set(self, key: str, value):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        cache_path = self._get_cache_path(key)

        data = {
            'value': value,
            'cached_at': datetime.now().isoformat()
        }

        with open(cache_path, 'w') as f:
            json.dump(data, f)

    def clear(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        for cache_file in self.cache_dir.glob("*.json"):
            cache_file.unlink()
```

#### 8. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

```python
# modules/metrics.py
import time
from functools import wraps
from datetime import datetime
import json
from pathlib import Path

class MetricsCollector:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, metrics_file: str = "metrics.json"):
        self.metrics_file = Path(metrics_file)
        self.metrics = self.load_metrics()

    def load_metrics(self) -> dict:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        if self.metrics_file.exists():
            with open(self.metrics_file, 'r') as f:
                return json.load(f)
        return {}

    def save_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜"""
        with open(self.metrics_file, 'w') as f:
            json.dump(self.metrics, f, indent=2)

    def record_api_call(self, api_name: str, duration: float, success: bool):
        """APIå‘¼ã³å‡ºã—ã®è¨˜éŒ²"""
        if api_name not in self.metrics:
            self.metrics[api_name] = {
                'total_calls': 0,
                'success_calls': 0,
                'failed_calls': 0,
                'total_duration': 0,
                'avg_duration': 0,
                'last_call': None
            }

        m = self.metrics[api_name]
        m['total_calls'] += 1
        m['total_duration'] += duration
        m['avg_duration'] = m['total_duration'] / m['total_calls']
        m['last_call'] = datetime.now().isoformat()

        if success:
            m['success_calls'] += 1
        else:
            m['failed_calls'] += 1

        self.save_metrics()

    def measure(self, api_name: str):
        """APIå‘¼ã³å‡ºã—æ¸¬å®šãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                start = time.time()
                success = False

                try:
                    result = func(*args, **kwargs)
                    success = True
                    return result
                finally:
                    duration = time.time() - start
                    self.record_api_call(api_name, duration, success)

            return wrapper
        return decorator

# ä½¿ç”¨ä¾‹
metrics = MetricsCollector()

@metrics.measure('anilist')
@anilist_limiter
def fetch_anilist_data(query, variables):
    # å®Ÿè£…
    pass
```

---

## å®Ÿè£…å„ªå…ˆé †ä½ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 1: ç·Šæ€¥å¯¾å¿œï¼ˆ1é€±é–“ä»¥å†…ï¼‰

1. **ãƒ¬ãƒ¼ãƒˆåˆ¶é™å®Ÿè£…** - `modules/rate_limiter.py`
2. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–** - `modules/error_handler.py`
3. **ç’°å¢ƒå¤‰æ•°åŒ–** - `.env`, `.env.example`, `modules/config_helper.py`

### Phase 2: å®‰å®šæ€§å‘ä¸Šï¼ˆ2é€±é–“ä»¥å†…ï¼‰

4. **ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šè¿½åŠ ** - å…¨HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆ
5. **ãƒ­ã‚¬ãƒ¼æ”¹å–„** - `modules/logger.py`
6. **RSSç®¡ç†ãƒ†ãƒ¼ãƒ–ãƒ«** - `migrations/004_rss_management.sql`

### Phase 3: æ©Ÿèƒ½æ‹¡å¼µï¼ˆ1ãƒ¶æœˆä»¥å†…ï¼‰

7. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½** - `modules/cache.py`
8. **ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†** - `modules/metrics.py`
9. **ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åŒæœŸå¼·åŒ–** - é‡è¤‡ãƒã‚§ãƒƒã‚¯ã€è‰²åˆ†ã‘

---

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### èªè¨¼æƒ…å ±ç®¡ç†

- [ ] `credentials.json` ã‚’ `.gitignore` ã«è¿½åŠ 
- [ ] `token.json` ã‚’ `.gitignore` ã«è¿½åŠ 
- [ ] ç’°å¢ƒå¤‰æ•°åŒ–ã®å®Œäº†
- [ ] ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼ˆ`.example`ï¼‰

### API ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

- [ ] ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å®Ÿè£…
- [ ] ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®è¨­å®š
- [ ] HTTPS ã®ã¿ä½¿ç”¨
- [ ] User-Agent ã®è¨­å®š

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹

- [ ] SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒªï¼‰
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥ã®ç¢ºç«‹
- [ ] å®šæœŸçš„ãªãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

---

## ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æ¨å¥¨é …ç›®

### ç›£è¦–å¯¾è±¡

1. **API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ **
   - AniList: < 2ç§’
   - ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼: < 3ç§’
   - RSS: < 5ç§’

2. **ã‚¨ãƒ©ãƒ¼ç‡**
   - å…¨API: < 5%

3. **ãƒ¡ãƒ¼ãƒ«é€ä¿¡æˆåŠŸç‡**
   - Gmail API: > 95%

4. **ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åŒæœŸæˆåŠŸç‡**
   - Calendar API: > 95%

### ã‚¢ãƒ©ãƒ¼ãƒˆæ¡ä»¶

```python
# modules/monitoring.py
class HealthChecker:
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹"""

    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics = metrics_collector

    def check_api_health(self, api_name: str) -> dict:
        """APIãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        m = self.metrics.metrics.get(api_name, {})

        total = m.get('total_calls', 0)
        failed = m.get('failed_calls', 0)

        if total == 0:
            return {'status': 'unknown', 'error_rate': 0}

        error_rate = failed / total

        status = 'healthy'
        if error_rate > 0.1:  # 10%ä»¥ä¸Š
            status = 'critical'
        elif error_rate > 0.05:  # 5%ä»¥ä¸Š
            status = 'warning'

        return {
            'status': status,
            'error_rate': error_rate,
            'total_calls': total,
            'failed_calls': failed
        }

    def get_overall_health(self) -> dict:
        """å…¨ä½“ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        apis = ['anilist', 'syoboi', 'gmail', 'calendar']
        results = {}

        for api in apis:
            results[api] = self.check_api_health(api)

        # å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®åˆ¤å®š
        statuses = [r['status'] for r in results.values()]

        if 'critical' in statuses:
            overall = 'critical'
        elif 'warning' in statuses:
            overall = 'warning'
        else:
            overall = 'healthy'

        return {
            'overall_status': overall,
            'api_status': results,
            'checked_at': datetime.now().isoformat()
        }
```

---

## ãƒ†ã‚¹ãƒˆæ¨å¥¨äº‹é …

### ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

```python
# tests/test_api_integration.py
import pytest
from modules.anime_anilist import fetch_anilist_data
from modules.rate_limiter import RateLimiter

def test_anilist_api_basic():
    """AniList APIåŸºæœ¬ãƒ†ã‚¹ãƒˆ"""
    query = """
    query {
        Media(id: 1) {
            title { romaji }
        }
    }
    """

    result = fetch_anilist_data(query, {})
    assert result is not None
    assert 'Media' in result

def test_rate_limiter():
    """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ†ã‚¹ãƒˆ"""
    import time

    limiter = RateLimiter(calls=5, period=1)

    @limiter
    def test_func():
        return time.time()

    times = []
    for _ in range(7):
        times.append(test_func())

    # 6å›ç›®ä»¥é™ã¯1ç§’ä»¥ä¸Šã®é–“éš”ãŒã‚ã‚‹ã¯ãš
    assert times[6] - times[0] >= 1.0
```

### çµ±åˆãƒ†ã‚¹ãƒˆ

```python
# tests/test_integration.py
import pytest
from modules.config_helper import ConfigManager
from modules.anime_anilist import fetch_anilist_data
from modules.mailer import send_email
from modules.calendar_integration import add_calendar_event

def test_full_workflow():
    """å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
    # 1. è¨­å®šèª­ã¿è¾¼ã¿
    config = ConfigManager()
    assert config.is_enabled('anime_sources.anilist')

    # 2. ãƒ‡ãƒ¼ã‚¿å–å¾—
    # ... çœç•¥

    # 3. ãƒ¡ãƒ¼ãƒ«é€ä¿¡ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰
    # ... çœç•¥

    # 4. ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç™»éŒ²ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰
    # ... çœç•¥
```

---

## ã¾ã¨ã‚

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®APIãƒ»å¤–éƒ¨é€£æºã¯åŸºæœ¬æ©Ÿèƒ½ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ãŒã€ä»¥ä¸‹ã®æ”¹å–„ãŒå¿…è¦ã§ã™:

### ç·Šæ€¥å¯¾å¿œé …ç›®ï¼ˆ1é€±é–“ä»¥å†…ï¼‰
1. **ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å®Ÿè£…** - APIåˆ¶é™å›é¿
2. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–** - ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯
3. **ç’°å¢ƒå¤‰æ•°åŒ–** - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å‘ä¸Š

### æ¨å¥¨æ”¹å–„é …ç›®ï¼ˆ2-4é€±é–“ï¼‰
4. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
5. ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«æœ€é©åŒ–
6. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒæ‹¡å¼µ

### æ©Ÿèƒ½æ‹¡å¼µé …ç›®ï¼ˆ1-2ãƒ¶æœˆï¼‰
7. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½
8. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
9. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°å¼·åŒ–

ã“ã‚Œã‚‰ã®æ”¹å–„ã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ã®å®‰å®šæ€§ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ä¿å®ˆæ€§ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã™ã€‚

---

**æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: Phase 1ã®ç·Šæ€¥å¯¾å¿œé …ç›®ã®å®Ÿè£…ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

**è§£æå®Œäº†æ—¥æ™‚**: 2025-12-06
**æ‹…å½“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**: Backend Developer Agent
