# Phase 1 å®Ÿè£…ã‚¬ã‚¤ãƒ‰ - ç·Šæ€¥å¯¾å¿œé …ç›®

**ä½œæˆæ—¥**: 2025-12-06
**å¯¾è±¡**: Backend Developer
**æœŸé™**: 1é€±é–“ä»¥å†…

---

## ğŸ“‹ ç›®æ¬¡

1. [å®Ÿè£…æ¦‚è¦](#å®Ÿè£…æ¦‚è¦)
2. [ãƒ¬ãƒ¼ãƒˆåˆ¶é™å®Ÿè£…](#ãƒ¬ãƒ¼ãƒˆåˆ¶é™å®Ÿè£…)
3. [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–](#ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–)
4. [ç’°å¢ƒå¤‰æ•°åŒ–](#ç’°å¢ƒå¤‰æ•°åŒ–)
5. [ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³](#ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)
6. [ãƒ†ã‚¹ãƒˆå®Ÿè£…](#ãƒ†ã‚¹ãƒˆå®Ÿè£…)
7. [ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †](#ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †)

---

## å®Ÿè£…æ¦‚è¦

### ä½œæˆæ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«

```
MangaAnime-Info-delivery-system/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ rate_limiter.py          âœ… ä½œæˆæ¸ˆã¿
â”‚   â”œâ”€â”€ error_handler.py         âœ… ä½œæˆæ¸ˆã¿
â”‚   â””â”€â”€ config_loader.py         âœ… ä½œæˆæ¸ˆã¿
â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ 004_rss_management.sql   âœ… ä½œæˆæ¸ˆã¿
â”œâ”€â”€ config.env.example           âœ… ä½œæˆæ¸ˆã¿
â””â”€â”€ docs/
    â”œâ”€â”€ API_EXTERNAL_INTEGRATION_ANALYSIS_REPORT.md  âœ… ä½œæˆæ¸ˆã¿
    â””â”€â”€ IMPLEMENTATION_GUIDE_PHASE1.md               âœ… æœ¬ãƒ•ã‚¡ã‚¤ãƒ«
```

### å®Ÿè£…ã‚¿ã‚¹ã‚¯

- [x] ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ
- [x] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ
- [x] è¨­å®šç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½œæˆ
- [x] ç’°å¢ƒå¤‰æ•°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
- [x] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³SQLä½œæˆ
- [ ] æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¿®æ­£
- [ ] ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ä½œæˆ
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°
- [ ] ãƒ‡ãƒ—ãƒ­ã‚¤

---

## ãƒ¬ãƒ¼ãƒˆåˆ¶é™å®Ÿè£…

### Step 1: æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¿®æ­£

#### 1.1 `modules/anime_anilist.py` ã®ä¿®æ­£

**Before**:
```python
import requests
import logging

def fetch_anilist_data(query, variables):
    response = requests.post(ANILIST_API_URL, json={'query': query, 'variables': variables})
    response.raise_for_status()
    return response.json()
```

**After**:
```python
import requests
import logging
from modules.rate_limiter import anilist_limiter
from modules.error_handler import with_retry, RetryConfig

@with_retry(RetryConfig(max_retries=3, backoff_factor=2.0))
@anilist_limiter
def fetch_anilist_data(query, variables):
    """
    AniList GraphQL API ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

    Args:
        query: GraphQLã‚¯ã‚¨ãƒª
        variables: ã‚¯ã‚¨ãƒªå¤‰æ•°

    Returns:
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®dataãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰

    Raises:
        requests.RequestException: APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼
    """
    try:
        response = requests.post(
            ANILIST_API_URL,
            json={'query': query, 'variables': variables},
            timeout=10,  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¿½åŠ 
            headers={'User-Agent': 'MangaAnime-Info-Bot/1.0'}
        )
        response.raise_for_status()
        data = response.json()

        # GraphQLã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        if 'errors' in data:
            error_msg = ', '.join([e.get('message', 'Unknown error') for e in data['errors']])
            logging.error(f"GraphQL errors: {error_msg}")
            raise ValueError(f"GraphQL errors: {error_msg}")

        return data.get('data')

    except requests.Timeout:
        logging.error("AniList API timeout")
        raise
    except requests.RequestException as e:
        logging.error(f"AniList API error: {e}")
        raise
```

#### 1.2 `modules/anime_syoboi.py` ã®ä¿®æ­£

**ä¿®æ­£ç®‡æ‰€**:
```python
from modules.rate_limiter import syoboi_limiter
from modules.error_handler import with_retry, RetryConfig

@with_retry(RetryConfig(max_retries=3, backoff_factor=2.0))
@syoboi_limiter
def fetch_syoboi_data(start_date, end_date):
    """
    ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

    Args:
        start_date: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰
        end_date: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰

    Returns:
        ç•ªçµ„æƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    params = {
        'Command': 'ProgLookup',
        'Range': f'{start_date}-{end_date}',
        'Fields': 'TID,Title,StTime,ChName'
    }

    try:
        response = requests.get(
            SYOBOI_API_URL,
            params=params,
            timeout=10,
            headers={'User-Agent': 'MangaAnime-Info-Bot/1.0'}
        )
        response.encoding = 'shift_jis'  # æ˜ç¤ºçš„ã«è¨­å®š
        response.raise_for_status()

        # XMLãƒ‘ãƒ¼ã‚¹
        import xml.etree.ElementTree as ET
        try:
            root = ET.fromstring(response.content)
            return parse_syoboi_xml(root)
        except ET.ParseError as e:
            logging.error(f"XML parse error: {e}")
            raise

    except Exception as e:
        logging.error(f"Syoboi API error: {e}")
        raise
```

#### 1.3 `modules/manga_rss.py` ã®ä¿®æ­£

**ä¿®æ­£ç®‡æ‰€**:
```python
import feedparser
import requests
from modules.rate_limiter import rss_limiter
from modules.error_handler import with_retry, RetryConfig
from modules.config_loader import get_config

@with_retry(RetryConfig(max_retries=3, backoff_factor=1.5))
@rss_limiter
def fetch_rss_feed(url, etag=None, modified=None):
    """
    RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆETag/Last-Modifiedå¯¾å¿œï¼‰

    Args:
        url: RSS Feed URL
        etag: å‰å›å–å¾—æ™‚ã®ETag
        modified: å‰å›å–å¾—æ™‚ã®Last-Modified

    Returns:
        (entries, new_etag, new_modified) ã®ã‚¿ãƒ—ãƒ«
    """
    headers = {
        'User-Agent': 'MangaAnime-Info-Bot/1.0 (+https://example.com/bot)'
    }

    if etag:
        headers['If-None-Match'] = etag
    if modified:
        headers['If-Modified-Since'] = modified

    try:
        response = requests.get(url, headers=headers, timeout=15)

        # 304 Not Modified
        if response.status_code == 304:
            logging.info(f"RSS not modified: {url}")
            return [], etag, modified

        response.raise_for_status()

        feed = feedparser.parse(response.content)

        if feed.bozo and feed.bozo_exception:
            logging.warning(f"RSS parse warning for {url}: {feed.bozo_exception}")

        new_etag = response.headers.get('ETag')
        new_modified = response.headers.get('Last-Modified')

        return feed.entries, new_etag, new_modified

    except Exception as e:
        logging.error(f"RSS fetch error for {url}: {e}")
        raise
```

#### 1.4 `modules/mailer.py` ã®ä¿®æ­£

**ä¿®æ­£ç®‡æ‰€**:
```python
from googleapiclient.errors import HttpError
from modules.rate_limiter import gmail_limiter
from modules.error_handler import with_retry, RetryConfig, gmail_breaker

@with_retry(RetryConfig(max_retries=3, backoff_factor=2.0))
@gmail_limiter
@gmail_breaker
def send_email(to, subject, body_html):
    """
    Gmailã§ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡

    Args:
        to: é€ä¿¡å…ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
        subject: ä»¶å
        body_html: HTMLæœ¬æ–‡

    Returns:
        æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
    """
    try:
        service = get_gmail_service()
        message = create_message(to, subject, body_html)
        result = send_message(service, 'me', message)

        logging.info(f"Email sent to {to}: {result['id']}")
        return True

    except HttpError as e:
        if e.resp.status in [403, 429]:
            logging.error(f"Gmail rate limit exceeded: {e}")
        else:
            logging.error(f"Gmail API error: {e}")
        raise

    except Exception as e:
        logging.error(f"Email send error: {e}")
        raise
```

#### 1.5 `modules/calendar_integration.py` ã®ä¿®æ­£

**ä¿®æ­£ç®‡æ‰€**:
```python
from googleapiclient.errors import HttpError
from modules.rate_limiter import calendar_limiter
from modules.error_handler import with_retry, RetryConfig, calendar_breaker
import sqlite3

@with_retry(RetryConfig(max_retries=3, backoff_factor=2.0))
@calendar_limiter
@calendar_breaker
def add_calendar_event(title, date, description, url, category='anime'):
    """
    Google ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¿½åŠ 

    Args:
        title: ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«
        date: æ—¥ä»˜ï¼ˆYYYY-MM-DDï¼‰
        description: èª¬æ˜
        url: URL
        category: ã‚«ãƒ†ã‚´ãƒªï¼ˆanime, manga, movieï¼‰

    Returns:
        ã‚¤ãƒ™ãƒ³ãƒˆIDã€å¤±æ•—æ™‚None
    """
    service = get_calendar_service()

    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    existing = check_existing_event(service, title, date)
    if existing:
        logging.info(f"Event already exists: {existing['id']}")
        return existing['id']

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥è‰²è¨­å®š
    color_map = {
        'anime': '9',      # é’
        'manga': '10',     # ç·‘
        'movie': '11',     # èµ¤
    }

    event = {
        'summary': title,
        'description': f"{description}\n\nURL: {url}",
        'start': {
            'date': date,
            'timeZone': 'Asia/Tokyo',
        },
        'end': {
            'date': date,
            'timeZone': 'Asia/Tokyo',
        },
        'colorId': color_map.get(category, '1'),
        'reminders': {
            'useDefault': False,
            'overrides': [
                {'method': 'popup', 'minutes': 60},
                {'method': 'popup', 'minutes': 1440},  # 1æ—¥å‰
            ],
        },
    }

    try:
        result = service.events().insert(
            calendarId='primary',
            body=event
        ).execute()

        event_id = result['id']
        logging.info(f"Calendar event created: {event_id}")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²
        save_calendar_event_to_db(title, date, event_id, category)

        return event_id

    except HttpError as e:
        logging.error(f"Calendar API error: {e}")
        raise

def check_existing_event(service, title, date):
    """æ—¢å­˜ã‚¤ãƒ™ãƒ³ãƒˆã®ç¢ºèª"""
    time_min = f"{date}T00:00:00+09:00"
    time_max = f"{date}T23:59:59+09:00"

    try:
        events_result = service.events().list(
            calendarId='primary',
            timeMin=time_min,
            timeMax=time_max,
            q=title,
            singleEvents=True
        ).execute()

        events = events_result.get('items', [])
        for event in events:
            if event.get('summary') == title:
                return event

    except HttpError as e:
        logging.error(f"Error checking existing event: {e}")

    return None

def save_calendar_event_to_db(title, date, event_id, category):
    """ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
    from modules.config_loader import get_config

    config = get_config()
    db_path = config.get_database_path()

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    try:
        cursor.execute("""
            INSERT INTO calendar_events (title, event_date, event_id, category)
            VALUES (?, ?, ?, ?)
        """, (title, date, event_id, category))

        conn.commit()
        logging.debug(f"Saved calendar event to database: {event_id}")

    except sqlite3.IntegrityError:
        logging.warning(f"Calendar event already exists in database: {event_id}")

    finally:
        conn.close()
```

---

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–

### Step 2: å…±é€šã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ã®è¿½åŠ 

**æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«**: `modules/common_utils.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import logging
from typing import Optional, Dict, Any
import time

logger = logging.getLogger(__name__)


def log_api_call(
    api_name: str,
    endpoint: str,
    method: str,
    status_code: Optional[int],
    success: bool,
    response_time: float,
    error_message: Optional[str] = None
):
    """
    APIå‘¼ã³å‡ºã—ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²

    Args:
        api_name: APIå
        endpoint: ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        method: HTTPãƒ¡ã‚½ãƒƒãƒ‰
        status_code: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰
        success: æˆåŠŸ/å¤±æ•—
        response_time: ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
        error_message: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    import sqlite3
    from modules.config_loader import get_config

    config = get_config()
    db_path = config.get_database_path()

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        cursor.execute("""
            INSERT INTO api_call_logs (
                api_name, endpoint, method, status_code,
                success, response_time, error_message
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            api_name, endpoint, method, status_code,
            1 if success else 0, response_time, error_message
        ))

        conn.commit()
        conn.close()

    except Exception as e:
        logger.error(f"Failed to log API call: {e}")


def measure_time(func):
    """å®Ÿè¡Œæ™‚é–“æ¸¬å®šãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    from functools import wraps

    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        try:
            result = func(*args, **kwargs)
            elapsed = time.time() - start
            logger.debug(f"{func.__name__} completed in {elapsed:.3f}s")
            return result
        except Exception as e:
            elapsed = time.time() - start
            logger.error(f"{func.__name__} failed after {elapsed:.3f}s: {e}")
            raise
    return wrapper
```

---

## ç’°å¢ƒå¤‰æ•°åŒ–

### Step 3: ç’°å¢ƒè¨­å®šã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 3.1 `.gitignore` ã®æ›´æ–°

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã§å®Ÿè¡Œ
cat >> .gitignore << 'EOF'

# Environment variables
.env
.env.local
.env.*.local

# Google API credentials
credentials.json
token.json
calendar_credentials.json
calendar_token.json

# Sensitive config
config.json
EOF
```

#### 3.2 ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ

```bash
# ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰.envã‚’ä½œæˆ
cp config.env.example .env

# ã‚¨ãƒ‡ã‚£ã‚¿ã§.envã‚’ç·¨é›†
nano .env
```

**å¿…é ˆè¨­å®šé …ç›®**:
```bash
# .env
NOTIFICATION_EMAIL=your-email@example.com
DATABASE_PATH=db.sqlite3
LOG_LEVEL=INFO
GMAIL_CREDENTIALS_PATH=credentials.json
GMAIL_TOKEN_PATH=token.json
```

#### 3.3 æ—¢å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä¿®æ­£

**ã™ã¹ã¦ã®Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å†’é ­ã«è¿½åŠ **:

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ï¼ˆæœ€å„ªå…ˆï¼‰
from dotenv import load_dotenv
load_dotenv()

import logging
from modules.config_loader import get_config

# è¨­å®šã®èª­ã¿è¾¼ã¿
config = get_config()

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=getattr(logging, config.get_log_level()),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(config.get('log_file', 'logs/app.log')),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)
```

---

## ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

### Step 4: ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ

#### 4.1 ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/run_migration.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sqlite3
import logging
from pathlib import Path
from dotenv import load_dotenv
from modules.config_loader import get_config

load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def run_migration(db_path: str, migration_file: Path):
    """
    ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ

    Args:
        db_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        migration_file: ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³SQLãƒ•ã‚¡ã‚¤ãƒ«
    """
    logger.info(f"Running migration: {migration_file.name}")

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    try:
        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³SQLã®èª­ã¿è¾¼ã¿
        with open(migration_file, 'r', encoding='utf-8') as f:
            migration_sql = f.read()

        # å®Ÿè¡Œ
        cursor.executescript(migration_sql)
        conn.commit()

        logger.info(f"Migration completed: {migration_file.name}")

    except Exception as e:
        conn.rollback()
        logger.error(f"Migration failed: {e}")
        raise

    finally:
        conn.close()


def main():
    config = get_config()
    db_path = config.get_database_path()

    migrations_dir = Path('migrations')
    migration_files = sorted(migrations_dir.glob('*.sql'))

    logger.info(f"Found {len(migration_files)} migration files")

    for migration_file in migration_files:
        run_migration(db_path, migration_file)

    logger.info("All migrations completed successfully")


if __name__ == '__main__':
    main()
```

#### 4.2 ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ

```bash
# å®Ÿè¡Œæ¨©é™ä»˜ä¸
chmod +x scripts/run_migration.py

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
python3 scripts/run_migration.py
```

#### 4.3 ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç¢ºèª

```bash
# SQLite CLIã§ç¢ºèª
sqlite3 db.sqlite3

# ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§
.tables

# rss_sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
.schema rss_sources

# åˆæœŸãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
SELECT * FROM rss_sources;

# ãƒ“ãƒ¥ãƒ¼ã®ç¢ºèª
SELECT * FROM api_call_summary;

# çµ‚äº†
.quit
```

---

## ãƒ†ã‚¹ãƒˆå®Ÿè£…

### Step 5: ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®ä½œæˆ

**æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«**: `tests/test_rate_limiter.py`

```python
import pytest
import time
from modules.rate_limiter import RateLimiter


def test_rate_limiter_basic():
    """åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãƒ†ã‚¹ãƒˆ"""
    limiter = RateLimiter(calls=5, period=1, name="Test")

    @limiter
    def test_func():
        return time.time()

    # 5å›ã¯å³åº§ã«å®Ÿè¡Œå¯èƒ½
    times = []
    for _ in range(5):
        times.append(test_func())

    # 5å›ã¨ã‚‚1ç§’ä»¥å†…ã«å®Œäº†
    assert times[4] - times[0] < 1.0

    # 6å›ç›®ã¯å¾…æ©ŸãŒç™ºç”Ÿ
    start = time.time()
    test_func()
    elapsed = time.time() - start

    # å¾…æ©Ÿæ™‚é–“ãŒç™ºç”Ÿã—ãŸã¯ãš
    assert elapsed > 0.0


def test_rate_limiter_remaining_calls():
    """æ®‹ã‚Šå‘¼ã³å‡ºã—æ•°ã®ãƒ†ã‚¹ãƒˆ"""
    limiter = RateLimiter(calls=10, period=1, name="Test")

    assert limiter.get_remaining_calls() == 10

    @limiter
    def test_func():
        pass

    # 3å›å‘¼ã³å‡ºã—
    for _ in range(3):
        test_func()

    assert limiter.get_remaining_calls() == 7


def test_rate_limiter_reset():
    """ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    limiter = RateLimiter(calls=5, period=1, name="Test")

    @limiter
    def test_func():
        pass

    # 5å›å‘¼ã³å‡ºã—
    for _ in range(5):
        test_func()

    assert limiter.get_remaining_calls() == 0

    # ãƒªã‚»ãƒƒãƒˆ
    limiter.reset()

    assert limiter.get_remaining_calls() == 5
```

**æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«**: `tests/test_error_handler.py`

```python
import pytest
from modules.error_handler import with_retry, RetryConfig, CircuitBreaker


def test_retry_success():
    """ãƒªãƒˆãƒ©ã‚¤æˆåŠŸã®ãƒ†ã‚¹ãƒˆ"""
    attempt_count = 0

    @with_retry(RetryConfig(max_retries=3, backoff_factor=0.1))
    def test_func():
        nonlocal attempt_count
        attempt_count += 1

        if attempt_count < 3:
            raise Exception("Fail")

        return "Success"

    result = test_func()
    assert result == "Success"
    assert attempt_count == 3


def test_retry_failure():
    """ãƒªãƒˆãƒ©ã‚¤å¤±æ•—ã®ãƒ†ã‚¹ãƒˆ"""
    @with_retry(RetryConfig(max_retries=3, backoff_factor=0.1))
    def test_func():
        raise ValueError("Always fail")

    with pytest.raises(ValueError):
        test_func()


def test_circuit_breaker():
    """ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    breaker = CircuitBreaker(failure_threshold=3, timeout=1, name="Test")

    @breaker
    def test_func(should_fail):
        if should_fail:
            raise Exception("Fail")
        return "Success"

    # 3å›å¤±æ•—ã•ã›ã‚‹
    for _ in range(3):
        with pytest.raises(Exception):
            test_func(True)

    # OPENçŠ¶æ…‹ã«ãªã£ã¦ã„ã‚‹ã¯ãš
    with pytest.raises(Exception, match="Circuit breaker"):
        test_func(False)

    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¾…æ©Ÿ
    time.sleep(1.1)

    # å›å¾©ã™ã‚‹ã¯ãš
    result = test_func(False)
    assert result == "Success"
```

**æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«**: `tests/test_config_loader.py`

```python
import pytest
import os
from pathlib import Path
from modules.config_loader import ConfigLoader


def test_config_loader_basic(tmp_path):
    """åŸºæœ¬çš„ãªè¨­å®šèª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆ"""
    config_file = tmp_path / "config.json"
    config_file.write_text("""
    {
        "anime_sources": {
            "anilist": {
                "enabled": true,
                "api_url": "https://example.com"
            }
        },
        "notification": {
            "email": {
                "recipients": ["test@example.com"]
            }
        }
    }
    """)

    config = ConfigLoader(str(config_file), env_file=None)

    assert config.is_enabled('anime_sources.anilist')
    assert config.get('anime_sources.anilist.api_url') == "https://example.com"
    assert config.get_notification_emails() == ["test@example.com"]


def test_env_override(tmp_path, monkeypatch):
    """ç’°å¢ƒå¤‰æ•°ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""
    config_file = tmp_path / "config.json"
    config_file.write_text("""
    {
        "notification": {
            "email": {
                "recipients": ["default@example.com"]
            }
        }
    }
    """)

    # ç’°å¢ƒå¤‰æ•°è¨­å®š
    monkeypatch.setenv('NOTIFICATION_EMAIL', 'override@example.com')

    config = ConfigLoader(str(config_file), env_file=None)

    assert config.get_notification_emails() == ["override@example.com"]
```

### ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

```bash
# ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
pytest tests/ -v

# ã‚«ãƒãƒ¬ãƒƒã‚¸ä»˜ãã§å®Ÿè¡Œ
pytest tests/ --cov=modules --cov-report=html

# ç‰¹å®šã®ãƒ†ã‚¹ãƒˆã®ã¿
pytest tests/test_rate_limiter.py -v
```

---

## ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †

### Step 6: æœ¬ç•ªç’°å¢ƒã¸ã®é©ç”¨

#### 6.1 ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp db.sqlite3 backups/db.sqlite3.backup.$(date +%Y%m%d_%H%M%S)

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp config.json backups/config.json.backup.$(date +%Y%m%d_%H%M%S)
```

#### 6.2 ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# requirements.txtã«è¿½åŠ 
cat >> requirements.txt << 'EOF'
python-dotenv==1.0.0
pydantic==2.5.0
EOF

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

#### 6.3 ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ

```bash
python3 scripts/run_migration.py
```

#### 6.4 å‹•ä½œç¢ºèª

```bash
# Pythonã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚·ã‚§ãƒ«ã§ç¢ºèª
python3

>>> from modules.rate_limiter import anilist_limiter
>>> from modules.error_handler import with_retry
>>> from modules.config_loader import get_config
>>>
>>> config = get_config()
>>> print(config.get_notification_emails())
>>>
>>> # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãƒ†ã‚¹ãƒˆ
>>> @anilist_limiter
... def test():
...     print("Called!")
...
>>> test()
>>> test()
>>>
>>> exit()
```

#### 6.5 ãƒ­ã‚°ç¢ºèª

```bash
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°
tail -f logs/app.log

# ã‚¨ãƒ©ãƒ¼ã®ã¿è¡¨ç¤º
tail -f logs/app.log | grep ERROR
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

#### 1. ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼

**ã‚¨ãƒ©ãƒ¼**:
```
ModuleNotFoundError: No module named 'modules.rate_limiter'
```

**è§£æ±ºç­–**:
```bash
# PYTHONPATHã®è¨­å®š
export PYTHONPATH=/mnt/Linux-ExHDD/MangaAnime-Info-delivery-system:$PYTHONPATH

# ã¾ãŸã¯ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§è¨­å®š
import sys
sys.path.insert(0, '/mnt/Linux-ExHDD/MangaAnime-Info-delivery-system')
```

#### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼

**ã‚¨ãƒ©ãƒ¼**:
```
sqlite3.OperationalError: table rss_sources already exists
```

**è§£æ±ºç­–**:
```sql
-- SQLiteã§ç¢ºèª
sqlite3 db.sqlite3

-- ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
DROP TABLE IF EXISTS rss_sources;

-- ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å†å®Ÿè¡Œ
.quit
python3 scripts/run_migration.py
```

#### 3. ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãŒåŠ¹ã‹ãªã„

**åŸå› **: ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã®é †åºãŒé–“é•ã£ã¦ã„ã‚‹

**æ­£ã—ã„é †åº**:
```python
@with_retry(...)      # å¤–å´
@rate_limiter         # å†…å´
@circuit_breaker      # æœ€å†…å´
def api_call():
    pass
```

---

## ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### å®Ÿè£…å‰

- [ ] æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- [ ] ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª

### å®Ÿè£…ä¸­

- [ ] rate_limiter.py ã®å‹•ä½œç¢ºèª
- [ ] error_handler.py ã®å‹•ä½œç¢ºèª
- [ ] config_loader.py ã®å‹•ä½œç¢ºèª
- [ ] å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¸ã®é©ç”¨å®Œäº†
- [ ] ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå®Œäº†

### å®Ÿè£…å¾Œ

- [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
- [ ] ãƒ­ã‚°ã®ç¢ºèª
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

### ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œ

- [ ] ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°è¨­å®š
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª
- [ ] ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †ã®ç¢ºèª

---

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆPhase 2ï¼‰

Phase 1å®Œäº†å¾Œã€ä»¥ä¸‹ã®Phase 2å®Ÿè£…ã«é€²ã¿ã¾ã™:

1. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®çµ±ä¸€
2. ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«æœ€é©åŒ–
3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½è¿½åŠ 
4. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å¼·åŒ–
5. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ§‹ç¯‰

è©³ç´°ã¯ `docs/IMPLEMENTATION_GUIDE_PHASE2.md` ã‚’å‚ç…§ã€‚

---

**ä½œæˆè€…**: Backend Developer Agent
**æœ€çµ‚æ›´æ–°**: 2025-12-06
