#!/usr/bin/env python3
"""
ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬æƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’é †æ¬¡å®Ÿè¡Œã—ã¾ã™ï¼š
1. æƒ…å ±åé›†ï¼ˆAniList APIã€RSSã€ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼‰
2. ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
4. æœªé€šçŸ¥ãƒªãƒªãƒ¼ã‚¹ã®é€šçŸ¥å‡¦ç†ï¼ˆGmail + Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼‰

Usage:
    python3 release_notifier.py [--config CONFIG_PATH] [--dry-run] [--verbose]
    
Environment Variables:
    DATABASE_PATH: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    LOG_LEVEL: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« (DEBUG, INFO, WARNING, ERROR)
    GMAIL_FROM_EMAIL: Gmailé€ä¿¡è€…ã‚¢ãƒ‰ãƒ¬ã‚¹
    GMAIL_TO_EMAIL: Gmailå—ä¿¡è€…ã‚¢ãƒ‰ãƒ¬ã‚¹
"""

import argparse
import logging
import sys
import traceback
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional
import time
import signal
import asyncio

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from modules.config import get_config, ConfigManager
from modules.db import DatabaseManager
from modules.logger import setup_logging


class ReleaseNotifierSystem:
    """ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬æƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path: Optional[str] = None, dry_run: bool = False):
        """
        ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        
        Args:
            config_path (Optional[str]): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            dry_run (bool): ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®é€šçŸ¥ã¯é€ä¿¡ã—ãªã„ï¼‰
        """
        self.dry_run = dry_run
        self.config = get_config(config_path)
        
        # ãƒ­ã‚°ã®è¨­å®š
        setup_logging(self.config)
        self.logger = logging.getLogger(__name__)
        
        self.logger.info("=" * 60)
        self.logger.info(f"ğŸš€ {self.config.get_system_name()} v{self.config.get_system_version()} é–‹å§‹")
        self.logger.info(f"ç’°å¢ƒ: {self.config.get_environment()}")
        self.logger.info(f"ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if dry_run else 'ç„¡åŠ¹'}")
        self.logger.info("=" * 60)
        
        # è¨­å®šã®æ¤œè¨¼
        config_errors = self.config.validate_config()
        if config_errors:
            for error in config_errors:
                self.logger.error(f"è¨­å®šã‚¨ãƒ©ãƒ¼: {error}")
            raise ValueError("è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
        self.db = DatabaseManager(self.config.get_db_path())
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–ï¼ˆé…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§å¾ªç’°å‚ç…§ã‚’å›é¿ï¼‰
        self._collectors = None
        self._mailer = None
        self._calendar = None
        self._filter = None
        self._email_generator = None
        
        self.start_time = datetime.now()
        self.statistics = {
            'processed_sources': 0,
            'new_works': 0,
            'new_releases': 0,
            'notifications_sent': 0,
            'calendar_events_created': 0,
            'filtered_items': 0,
            'errors': 0,
            # Phase 2: Enhanced statistics
            'duplicate_items_removed': 0,
            'total_processing_time': 0.0,
            'average_response_time': 0.0,
            'performance_grade': 'N/A'
        }
    
    def _import_modules(self):
        """å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        if self._collectors is None:
            from modules.anime_anilist import AniListCollector
            from modules.manga_rss import MangaRSSCollector
            from modules.filter_logic import ContentFilter
            from modules.mailer import GmailNotifier, EmailTemplateGenerator
            from modules.calendar import GoogleCalendarManager
            
            # è¨­å®šã‚’è¾æ›¸å½¢å¼ã§æ¸¡ã™
            config_dict = self.config._config_data if hasattr(self.config, '_config_data') else {}
            
            self._collectors = {
                'anilist': AniListCollector(config_dict),
                'manga_rss': MangaRSSCollector(self.config),
                # 'syoboi': syoboi_calendar.SyoboiCollector(self.config)  # å°†æ¥å®Ÿè£…
            }
            self._filter = ContentFilter(self.config)
            self._mailer = GmailNotifier(self.config)
            self._calendar = GoogleCalendarManager(self.config)
            self._email_generator = EmailTemplateGenerator(self.config)
            
            self.logger.info("ã™ã¹ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
    
    def collect_information(self) -> List[Dict[str, Any]]:
        """
        å„ç¨®ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±åé›† - Phase 2 Performance Optimized
        
        Returns:
            List[Dict[str, Any]]: åé›†ã—ãŸä½œå“ãƒ»ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        self.logger.info("ğŸ“¡ æƒ…å ±åé›†ã‚’é–‹å§‹ã—ã¾ã™... (Phase 2 æœ€é©åŒ–ç‰ˆ)")
        self._import_modules()
        
        # Phase 2: Performance monitoring integration
        from modules.monitoring import record_api_performance, add_monitoring_alert
        
        all_items = []
        collection_start_time = time.time()
        
        for source_name, collector in self._collectors.items():
            source_start_time = time.time()
            try:
                self.logger.info(f"  {source_name} ã‹ã‚‰æƒ…å ±åé›†ä¸­...")
                
                if source_name == 'anilist':
                    items = collector.collect()
                else:
                    items = collector.collect()
                
                source_duration = time.time() - source_start_time
                
                if items:
                    self.logger.info(f"  {source_name}: {len(items)} ä»¶ã®æƒ…å ±ã‚’å–å¾— (æ™‚é–“: {source_duration:.2f}ç§’)")
                    all_items.extend(items)
                    self.statistics['processed_sources'] += 1
                    
                    # Performance monitoring
                    record_api_performance(source_name.replace('_', ''), source_duration, True)
                else:
                    self.logger.warning(f"  {source_name}: ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ (æ™‚é–“: {source_duration:.2f}ç§’)")
                    record_api_performance(source_name.replace('_', ''), source_duration, False)
                
                # Adaptive rate limiting based on performance
                if source_duration > 5.0:
                    self.logger.info(f"  {source_name} ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé…ã„ãŸã‚ã€é•·ã‚ã®å¾…æ©Ÿæ™‚é–“ã‚’è¨­å®š")
                    time.sleep(3)  # Longer wait for slow services
                else:
                    time.sleep(1)  # Normal rate limiting
                
            except Exception as e:
                source_duration = time.time() - source_start_time
                self.logger.error(f"  {source_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e} (æ™‚é–“: {source_duration:.2f}ç§’)")
                self.statistics['errors'] += 1
                
                # Performance monitoring for errors
                record_api_performance(source_name.replace('_', ''), source_duration, False)
                add_monitoring_alert(f"ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {source_name} - {e}", 'ERROR')
                
                if self.logger.isEnabledFor(logging.DEBUG):
                    self.logger.debug(traceback.format_exc())
        
        total_collection_time = time.time() - collection_start_time
        self.logger.info(f"ğŸ“¡ æƒ…å ±åé›†å®Œäº†: ç·è¨ˆ {len(all_items)} ä»¶ (ç·æ™‚é–“: {total_collection_time:.2f}ç§’)")
        
        # Performance analysis and alerting
        if total_collection_time > 60:  # More than 1 minute
            add_monitoring_alert(f"æƒ…å ±åé›†ãŒé…ã„: {total_collection_time:.1f}ç§’", 'WARNING')
        
        if len(all_items) == 0:
            add_monitoring_alert("æƒ…å ±åé›†ã§ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶", 'WARNING')
        
        return all_items
    
    def process_and_filter_data(self, raw_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            raw_items (List[Dict[str, Any]]): åé›†ã—ãŸç”Ÿãƒ‡ãƒ¼ã‚¿
            
        Returns:
            List[Dict[str, Any]]: å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        self.logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
        self._import_modules()
        
        processed_items = []
        
        for item in raw_items:
            try:
                # NGã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if self._filter.should_filter(item):
                    self.logger.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é™¤å¤–: {item.get('title', 'ä¸æ˜')}")
                    self.statistics['filtered_items'] += 1
                    continue
                
                processed_items.append(item)
                
            except Exception as e:
                self.logger.error(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                self.statistics['errors'] += 1
        
        self.logger.info(f"ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {len(processed_items)} ä»¶ãŒæ®‹å­˜ ({len(raw_items) - len(processed_items)} ä»¶é™¤å¤–)")
        return processed_items
    
    def save_to_database(self, items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã€æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã‚’è¿”ã™
        
        Args:
            items (List[Dict[str, Any]]): å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            List[Dict[str, Any]]: æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹æƒ…å ±
        """
        self.logger.info("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚’é–‹å§‹ã—ã¾ã™...")
        
        new_releases = []
        
        for item in items:
            try:
                # ä½œå“ã®å–å¾—ã¾ãŸã¯ä½œæˆ
                work_id = self.db.get_or_create_work(
                    title=item.get('title', ''),
                    title_kana=item.get('title_kana'),
                    title_en=item.get('title_en'),
                    work_type=item.get('type', 'unknown'),
                    official_url=item.get('official_url')
                )
                
                if work_id:
                    # ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã®ä¿å­˜
                    release_id = self.db.create_release(
                        work_id=work_id,
                        release_type=item.get('release_type', 'episode' if item.get('type') == 'anime' else 'volume'),
                        number=item.get('number'),
                        platform=item.get('platform'),
                        release_date=item.get('release_date'),
                        source=item.get('source'),
                        source_url=item.get('source_url')
                    )
                    
                    if release_id:
                        # æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹ã¨ã—ã¦è¿½åŠ 
                        release_info = item.copy()
                        release_info['release_id'] = release_id
                        release_info['work_id'] = work_id
                        new_releases.append(release_info)
                        self.statistics['new_releases'] += 1
                
                if item.get('is_new_work', False):
                    self.statistics['new_works'] += 1
                    
            except Exception as e:
                self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                self.statistics['errors'] += 1
        
        self.logger.info(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: {len(new_releases)} ä»¶ã®æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹")
        return new_releases
    
    def send_notifications(self, new_releases: List[Dict[str, Any]]) -> bool:
        """
        ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã¨ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã®ä½œæˆ
        
        Args:
            new_releases (List[Dict[str, Any]]): æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹æƒ…å ±
            
        Returns:
            bool: é€šçŸ¥å‡¦ç†ãŒæˆåŠŸã—ãŸå ´åˆTrue
        """
        if not new_releases:
            self.logger.info("ğŸ“§ æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹ãŒãªã„ãŸã‚ã€é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return True
        
        self.logger.info(f"ğŸ“§ é€šçŸ¥å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™: {len(new_releases)} ä»¶")
        self._import_modules()
        
        success = True
        
        try:
            # Gmailèªè¨¼
            if not self._mailer.authenticate():
                self.logger.error("Gmailèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            # Calendarèªè¨¼
            if not self._calendar.authenticate():
                self.logger.error("Google Calendarèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
            
            if not self.dry_run:
                # ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã®ä½œæˆã¨é€ä¿¡
                try:
                    notification = self._email_generator.generate_release_notification(new_releases)
                    
                    if self._mailer.send_notification(notification):
                        self.logger.info("âœ… ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸ")
                        self.statistics['notifications_sent'] += 1
                    else:
                        self.logger.error("âŒ ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        success = False
                        
                except Exception as e:
                    self.logger.error(f"ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
                    success = False
                
                # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã®ä½œæˆ
                try:
                    calendar_results = self._calendar.bulk_create_release_events(new_releases)
                    created_events = len([v for v in calendar_results.values() if v])
                    
                    if created_events > 0:
                        self.logger.info(f"âœ… ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’ {created_events} ä»¶ä½œæˆã—ã¾ã—ãŸ")
                        self.statistics['calendar_events_created'] = created_events
                    else:
                        self.logger.warning("âš ï¸ ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                        
                except Exception as e:
                    self.logger.error(f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
                    success = False
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®é€šçŸ¥æ¸ˆã¿ãƒ•ãƒ©ã‚°æ›´æ–°
                for release in new_releases:
                    if 'release_id' in release:
                        self.db.mark_release_notified(release['release_id'])
            
            else:
                self.logger.info("ğŸ”’ ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®é€šçŸ¥ã¯é€ä¿¡ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
                # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ç”¨ã®è©³ç´°è¡¨ç¤º
                for release in new_releases:
                    title = release.get('title', 'ä¸æ˜ãªã‚¿ã‚¤ãƒˆãƒ«')
                    number = release.get('number', '')
                    platform = release.get('platform', '')
                    self.logger.info(f"  ğŸ“§ [DRY-RUN] {title} {number} ({platform})")
            
        except Exception as e:
            self.logger.error(f"é€šçŸ¥å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            success = False
        
        return success
    
    def cleanup_old_data(self):
        """å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # è¨­å®šã‹ã‚‰ä¿æŒæœŸé–“ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥ï¼‰
            retention_days = self.config.get_value('database.backup_retention_days', 30)
            cutoff_date = datetime.now() - timedelta(days=retention_days)
            
            cleaned_count = self.db.cleanup_old_releases(cutoff_date)
            if cleaned_count > 0:
                self.logger.info(f"ğŸ§¹ {cleaned_count} ä»¶ã®å¤ã„ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_report(self) -> str:
        """å®Ÿè¡Œçµæœãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ - Phase 2 Enhanced"""
        execution_time = datetime.now() - self.start_time
        
        # Phase 2: Enhanced monitoring integration
        from modules.monitoring import get_collection_health_status
        health_status = get_collection_health_status()
        
        # Calculate performance metrics
        items_per_second = (self.statistics['new_releases'] / execution_time.total_seconds() 
                           if execution_time.total_seconds() > 0 else 0)
        error_rate = (self.statistics['errors'] / max(self.statistics['processed_sources'], 1)) * 100
        
        report = f"""
{'=' * 60}
ğŸ“Š Phase 2 å®Ÿè¡Œçµæœãƒ¬ãƒãƒ¼ãƒˆ
{'=' * 60}
å®Ÿè¡Œæ™‚é–“: {execution_time.total_seconds():.1f}ç§’
é–‹å§‹æ™‚åˆ»: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
å®Œäº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ† ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ã‚°ãƒ¬ãƒ¼ãƒ‰: {health_status.get('system_health_grade', 'N/A')}

ğŸ“ˆ å‡¦ç†çµ±è¨ˆ:
  å‡¦ç†ã‚½ãƒ¼ã‚¹æ•°: {self.statistics['processed_sources']}
  æ–°ä½œå“æ•°: {self.statistics['new_works']}
  æ–°ãƒªãƒªãƒ¼ã‚¹æ•°: {self.statistics['new_releases']}
  ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é™¤å¤–æ•°: {self.statistics['filtered_items']}
  ğŸš€ å‡¦ç†é€Ÿåº¦: {items_per_second:.2f} ãƒªãƒªãƒ¼ã‚¹/ç§’
  
ğŸ“§ é€šçŸ¥çµ±è¨ˆ:
  ãƒ¡ãƒ¼ãƒ«é€šçŸ¥é€ä¿¡æ•°: {self.statistics['notifications_sent']}
  ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆæ•°: {self.statistics['calendar_events_created']}
  
âŒ ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ:
  ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå›æ•°: {self.statistics['errors']}
  ğŸ“‰ ã‚¨ãƒ©ãƒ¼ç‡: {error_rate:.1f}%

ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ:
  ç·ä½œå“æ•°: {self.db.get_work_stats().get('total', 0)}
  ç·ãƒªãƒªãƒ¼ã‚¹æ•°: {self.db.get_work_stats().get('total_releases', 0)}
  æœªé€šçŸ¥æ•°: {len(self.db.get_unnotified_releases(100))}

ğŸ“€ Phase 2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™:
  ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚¢ã‚¯ãƒ†ã‚£ãƒ–: {health_status.get('monitoring_active', False)}
  ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {health_status.get('active_alerts_count', 0)} ä»¶
  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰: {health_status.get('performance_trend', 'N/A')}
"""
        
        # Add critical issues if any
        critical_issues = health_status.get('critical_issues', [])
        if critical_issues:
            report += f"""
âš ï¸ é‡è¦ãªå•é¡Œ:
"""
            for issue in critical_issues[:5]:  # Show max 5 issues
                report += f"  â€¢ {issue}\n"
        
        # Add collection performance details
        collection_perf = health_status.get('collection_performance', {})
        if collection_perf:
            report += f"""
ğŸ” åé›†ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:
"""
            for service, metrics in collection_perf.items():
                if any(v > 0 for v in metrics.values() if isinstance(v, (int, float))):
                    report += f"  {service}:\n"
                    if 'requests' in metrics and metrics['requests'] > 0:
                        report += f"    ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {metrics['requests']}\n"
                    if 'feeds_processed' in metrics and metrics['feeds_processed'] > 0:
                        report += f"    å‡¦ç†ãƒ•ã‚£ãƒ¼ãƒ‰æ•°: {metrics['feeds_processed']}\n"
                    if 'queries' in metrics and metrics['queries'] > 0:
                        report += f"    ã‚¯ã‚¨ãƒªæ•°: {metrics['queries']}\n"
                    if 'errors' in metrics:
                        report += f"    ã‚¨ãƒ©ãƒ¼æ•°: {metrics['errors']}\n"
        
        report += f"\n{'=' * 60}\n"
        return report.strip()
    
    def run(self) -> bool:
        """
        ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œå‡¦ç†
        
        Returns:
            bool: æ­£å¸¸ã«å®Œäº†ã—ãŸå ´åˆTrue
        """
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: æƒ…å ±åé›†
            raw_items = self.collect_information()
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            processed_items = self.process_and_filter_data(raw_items)
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            new_releases = self.save_to_database(processed_items)
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: é€šçŸ¥å‡¦ç†
            notification_success = self.send_notifications(new_releases)
            
            # ã‚¹ãƒ†ãƒƒãƒ—5: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.cleanup_old_data()
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = self.generate_report()
            self.logger.info(report)
            
            if self.statistics['errors'] > 0:
                self.logger.warning(f"âš ï¸ {self.statistics['errors']} ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            
            success = notification_success and self.statistics['errors'] == 0
            
            if success:
                self.logger.info("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            else:
                self.logger.error("âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            
            return success
            
        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
            return False
        except Exception as e:
            self.logger.error(f"ğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if self.logger.isEnabledFor(logging.DEBUG):
                self.logger.debug(traceback.format_exc())
            return False
        finally:
            # ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            try:
                if hasattr(self, 'db') and self.db:
                    self.db.close()
            except Exception:
                pass
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        # ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            if hasattr(self, 'db') and self.db:
                self.db.close()
        except Exception:
            pass


def signal_handler(signum, frame):
    """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    print("\nğŸ›‘ çµ‚äº†ã‚·ã‚°ãƒŠãƒ«ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
    sys.exit(0)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # å¼•æ•°è§£æ
    parser = argparse.ArgumentParser(
        description="ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬æƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''ä½¿ç”¨ä¾‹:
  python3 release_notifier.py                    # é€šå¸¸å®Ÿè¡Œ
  python3 release_notifier.py --dry-run          # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆé€šçŸ¥ãªã—ï¼‰
  python3 release_notifier.py --verbose          # è©³ç´°ãƒ­ã‚°
  python3 release_notifier.py --config custom.json --dry-run --verbose'''
    )
    
    parser.add_argument(
        '--config', 
        type=str, 
        help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config.json)'
    )
    parser.add_argument(
        '--dry-run', 
        action='store_true', 
        help='ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®é€šçŸ¥ã¯é€ä¿¡ã—ãªã„ï¼‰'
    )
    parser.add_argument(
        '--verbose', 
        action='store_true', 
        help='è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›'
    )
    
    args = parser.parse_args()
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®š
    if args.verbose:
        import os
        os.environ['LOG_LEVEL'] = 'DEBUG'
    
    exit_code = 0
    
    try:
        # ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œ
        with ReleaseNotifierSystem(
            config_path=args.config,
            dry_run=args.dry_run
        ) as system:
            success = system.run()
            exit_code = 0 if success else 1
            
    except Exception as e:
        print(f"ğŸ’¥ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        exit_code = 2
    
    sys.exit(exit_code)


if __name__ == "__main__":
    main()