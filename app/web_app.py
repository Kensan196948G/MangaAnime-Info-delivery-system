#!/usr/bin/env python3
"""
Flask Web UI for Anime/Manga Information Delivery System
This module provides a web interface for managing anime/manga subscriptions,
viewing releases, and configuring the system.
"""

import os
import json
import sqlite3
import requests
import time
from datetime import datetime
from flask import Flask, render_template, request, jsonify, flash, redirect, url_for
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.secret_key = os.environ.get("SECRET_KEY", "dev-secret-key-change-in-production")

# ã‚«ã‚¹ã‚¿ãƒ Jinja2ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
@app.template_filter('strptime')
def strptime_filter(date_string, format='%Y-%m-%d'):
    """æ–‡å­—åˆ—ã‚’æ—¥ä»˜ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã™ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"""
    from datetime import datetime
    try:
        return datetime.strptime(date_string, format)
    except (ValueError, TypeError):
        return None

# Configuration
DATABASE_PATH = "db.sqlite3"
CONFIG_PATH = "config.json"

# Cache for API status (avoid repeated calls)
api_status_cache = {"data": None, "timestamp": 0}
CACHE_DURATION = 30  # seconds


def get_db_connection():
    """Get database connection with row factory for dict-like access"""
    conn = sqlite3.connect(DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def load_config():
    """Load configuration from config.json"""
    try:
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        # Return default config if file doesn't exist
        return {
            "ng_keywords": ["ã‚¨ãƒ­", "R18", "æˆäººå‘ã‘", "BL", "ç™¾åˆ", "ãƒœãƒ¼ã‚¤ã‚ºãƒ©ãƒ–"],
            "notification_email": "",
            "check_interval_hours": 24,
            "enabled_sources": {
                "anilist": True,
                "shobo_calendar": True,
                "bookwalker_rss": True,
                "mangapocket_rss": True,
            },
        }


def save_config(config):
    """Save configuration to config.json"""
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(config, f, indent=2, ensure_ascii=False)


def test_api_connections():
    """Test actual API connections and return status with fast timeouts"""
    import concurrent.futures

    api_status = {}

    def test_single_api(name, test_func):
        """Test a single API with error handling"""
        try:
            return name, test_func()
        except Exception as e:
            return name, {
                "status": "error",
                "response_time": 0,
                "success_rate": 0,
                "note": f"ã‚¨ãƒ©ãƒ¼: {str(e)[:20]}",
            }

    def test_anilist():
        start_time = time.time()
        response = requests.post(
            "https://graphql.anilist.co",
            json={"query": "{Media(id:1){id}}"},
            timeout=2,
            headers={"User-Agent": "MangaAnimeNotifier/1.0"},
        )
        response_time = (time.time() - start_time) * 1000
        if response.status_code == 200:
            return {
                "status": "connected",
                "response_time": round(response_time, 1),
                "success_rate": 98,
                "note": "GraphQL APIæ­£å¸¸",
            }
        else:
            return {
                "status": "warning",
                "response_time": round(response_time, 1),
                "success_rate": 75,
                "note": f"HTTP {response.status_code}",
            }

    def test_shobo():
        start_time = time.time()
        response = requests.get(
            "https://cal.syoboi.jp/json.php?Req=TitleLookup&TID=1",
            timeout=2,
            headers={"User-Agent": "MangaAnimeNotifier/1.0"},
        )
        response_time = (time.time() - start_time) * 1000
        if response.status_code == 200:
            return {
                "status": "connected",
                "response_time": round(response_time, 1),
                "success_rate": 92,
                "note": "JSON APIæ­£å¸¸",
            }
        else:
            return {
                "status": "warning",
                "response_time": round(response_time, 1),
                "success_rate": 70,
                "note": f"HTTP {response.status_code}",
            }

    def test_yahoo_rss():
        start_time = time.time()
        response = requests.get(
            "https://news.yahoo.co.jp/rss/categories/entertainment.xml",
            headers={"User-Agent": "MangaAnimeNotifier/1.0"},
            timeout=2,
        )
        response_time = (time.time() - start_time) * 1000
        if response.status_code == 200:
            return {
                "status": "connected",
                "response_time": round(response_time, 1),
                "success_rate": 95,
                "note": "Yahoo News (ä»£æ›¿)",
            }
        else:
            return {
                "status": "warning",
                "response_time": round(response_time, 1),
                "success_rate": 75,
                "note": f"HTTP {response.status_code}",
            }

    def test_nhk_rss():
        start_time = time.time()
        response = requests.get(
            "https://www3.nhk.or.jp/rss/news/cat7.xml",
            headers={"User-Agent": "MangaAnimeNotifier/1.0"},
            timeout=2,
        )
        response_time = (time.time() - start_time) * 1000
        if response.status_code == 200:
            return {
                "status": "connected",
                "response_time": round(response_time, 1),
                "success_rate": 92,
                "note": "NHK News (ä»£æ›¿)",
            }
        else:
            return {
                "status": "warning",
                "response_time": round(response_time, 1),
                "success_rate": 60,
                "note": f"HTTP {response.status_code}",
            }

    # Run all API tests in parallel with shorter timeout
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        future_to_name = {
            executor.submit(test_single_api, "anilist", test_anilist): "anilist",
            executor.submit(test_single_api, "shobo", test_shobo): "shobo",
            executor.submit(
                test_single_api, "bookwalker", test_yahoo_rss
            ): "bookwalker",
            executor.submit(test_single_api, "other_rss", test_nhk_rss): "other_rss",
        }

        for future in concurrent.futures.as_completed(future_to_name, timeout=3):
            try:
                name, result = future.result()
                api_status[name] = result
            except concurrent.futures.TimeoutError:
                name = future_to_name[future]
                api_status[name] = {
                    "status": "error",
                    "response_time": 3000,
                    "success_rate": 0,
                    "note": "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ",
                }
            except Exception as e:
                name = future_to_name[future]
                api_status[name] = {
                    "status": "error",
                    "response_time": 0,
                    "success_rate": 0,
                    "note": f"ã‚¨ãƒ©ãƒ¼: {str(e)[:20]}",
                }

    return api_status


@app.route("/")
def dashboard():
    """Main dashboard showing recent releases"""
    conn = get_db_connection()

    # Get recent releases (last 7 days) with proper title display
    recent_releases = conn.execute(
        """
        SELECT w.title as title, w.title as original_title,
               w.type, r.release_type, r.number, r.platform,
               r.release_date, r.source_url, r.notified
        FROM releases r
        JOIN works w ON r.work_id = w.id
        WHERE r.release_date >= date('now', '-7 days')
        ORDER BY r.release_date DESC, w.title
        LIMIT 50
    """
    ).fetchall()

    # Get upcoming releases (next 7 days) with proper title display
    upcoming_releases = conn.execute(
        """
        SELECT w.title as title, w.title as original_title,
               w.type, r.release_type, r.number, r.platform,
               r.release_date, r.source_url
        FROM releases r
        JOIN works w ON r.work_id = w.id
        WHERE r.release_date > date('now') AND r.release_date <= date('now', '+7 days')
        ORDER BY r.release_date, w.title
        LIMIT 50
    """
    ).fetchall()

    # Get statistics
    stats = {
        "total_works": conn.execute("SELECT COUNT(*) FROM works").fetchone()[0],
        "total_releases": conn.execute("SELECT COUNT(*) FROM releases").fetchone()[0],
        "pending_notifications": conn.execute(
            "SELECT COUNT(*) FROM releases WHERE notified = 0"
        ).fetchone()[0],
        "anime_count": conn.execute(
            'SELECT COUNT(*) FROM works WHERE type = "anime"'
        ).fetchone()[0],
        "manga_count": conn.execute(
            'SELECT COUNT(*) FROM works WHERE type = "manga"'
        ).fetchone()[0],
    }

    conn.close()

    return render_template(
        "dashboard.html",
        recent_releases=recent_releases,
        upcoming_releases=upcoming_releases,
        stats=stats,
    )


@app.route("/releases")
def releases():
    """Release history page with filtering and pagination"""
    page = request.args.get("page", 1, type=int)
    per_page = 25
    work_type = request.args.get("type", "all")
    platform = request.args.get("platform", "all")
    search = request.args.get("search", "")

    conn = get_db_connection()

    # Build query with filters - proper title display
    query = """
        SELECT w.title as title, w.title as original_title,
               w.type, r.release_type, r.number, r.platform,
               r.release_date, r.source_url, r.notified, r.created_at
        FROM releases r
        JOIN works w ON r.work_id = w.id
        WHERE 1=1
    """
    params = []

    if work_type != "all":
        query += " AND w.type = ?"
        params.append(work_type)

    if platform != "all":
        query += " AND r.platform = ?"
        params.append(platform)

    if search:
        query += " AND (w.title LIKE ? OR w.title_kana LIKE ?)"
        params.extend([f"%{search}%", f"%{search}%"])

    query += " ORDER BY r.release_date DESC LIMIT ? OFFSET ?"
    params.extend([per_page, (page - 1) * per_page])

    releases_data = conn.execute(query, params).fetchall()

    # Get total count for pagination - Build separate count query
    count_query = """
        SELECT COUNT(*)
        FROM releases r
        JOIN works w ON r.work_id = w.id
        WHERE 1=1
    """
    count_params = []

    if work_type != "all":
        count_query += " AND w.type = ?"
        count_params.append(work_type)

    if platform != "all":
        count_query += " AND r.platform = ?"
        count_params.append(platform)

    if search:
        count_query += " AND (w.title LIKE ? OR w.title_kana LIKE ?)"
        count_params.extend([f"%{search}%", f"%{search}%"])

    total_count = conn.execute(count_query, count_params).fetchone()[0]

    # Get available platforms for filter
    platforms = [
        row[0]
        for row in conn.execute(
            "SELECT DISTINCT platform FROM releases ORDER BY platform"
        ).fetchall()
    ]

    conn.close()

    total_pages = (total_count + per_page - 1) // per_page

    return render_template(
        "releases.html",
        releases=releases_data,
        current_page=page,
        total_pages=total_pages,
        work_type=work_type,
        platform=platform,
        search=search,
        platforms=platforms,
    )


@app.route("/calendar")
def calendar():
    """Calendar view of releases"""
    from calendar import monthrange

    month = request.args.get("month", datetime.now().month, type=int)
    year = request.args.get("year", datetime.now().year, type=int)

    # æœˆã®æœ€åˆã®æ—¥ã®æ›œæ—¥ã¨æ—¥æ•°ã‚’è¨ˆç®—
    first_weekday, days_in_month = monthrange(year, month)

    # æœˆã®æœ€åˆã®æ—¥
    first_day = datetime(year, month, 1)

    # Get releases for the specified month with proper title display
    conn = get_db_connection()
    releases_data = conn.execute(
        """
        SELECT w.title as title, w.title as original_title,
               w.type, r.release_type, r.number, r.platform,
               r.release_date, r.source_url
        FROM releases r
        JOIN works w ON r.work_id = w.id
        WHERE strftime('%Y', r.release_date) = ?
        AND strftime('%m', r.release_date) = ?
        ORDER BY r.release_date, w.title
    """,
        [str(year), f"{month:02d}"],
    ).fetchall()

    conn.close()

    # Organize releases by date
    releases_by_date = {}
    total_releases = 0
    for release in releases_data:
        date_str = release["release_date"]
        if date_str not in releases_by_date:
            releases_by_date[date_str] = []
        releases_by_date[date_str].append(dict(release))
        total_releases += 1

    return render_template(
        "calendar.html",
        releases_by_date=releases_by_date,
        current_month=month,
        current_year=year,
        first_weekday=first_weekday,
        days_in_month=days_in_month,
        total_releases=total_releases,
    )


@app.route("/config", methods=["GET", "POST"])
def config():
    """Configuration management interface"""
    if request.method == "POST":
        # Save configuration
        config_data = load_config()

        # Update NG keywords
        ng_keywords = request.form.get("ng_keywords", "").strip()
        if ng_keywords:
            config_data["ng_keywords"] = [
                kw.strip() for kw in ng_keywords.split("\n") if kw.strip()
            ]

        # Update other settings
        config_data["notification_email"] = request.form.get("notification_email", "")
        config_data["check_interval_hours"] = int(
            request.form.get("check_interval_hours", 24)
        )

        # Update enabled sources
        config_data["enabled_sources"] = {
            "anilist": "anilist" in request.form,
            "shobo_calendar": "shobo_calendar" in request.form,
            "bookwalker_rss": "bookwalker_rss" in request.form,
            "mangapocket_rss": "mangapocket_rss" in request.form,
        }

        # Update email settings
        if "email" not in config_data:
            config_data["email"] = {}
        config_data["email"].update(
            {
                "enabled": "email_enabled" in request.form,
                "subject_prefix": request.form.get(
                    "email_subject_prefix", "MangaAnimeé…ä¿¡ã‚·ã‚¹ãƒ†ãƒ "
                ),
                "format": request.form.get("email_format", "html"),
            }
        )

        # Update calendar settings
        if "calendar" not in config_data:
            config_data["calendar"] = {}
        config_data["calendar"].update(
            {
                "enabled": "calendar_enabled" in request.form,
                "calendar_id": request.form.get("calendar_id", "primary"),
                "event_duration": int(request.form.get("calendar_event_duration", 60)),
            }
        )

        # Update notification settings
        if "notifications" not in config_data:
            config_data["notifications"] = {}
        config_data["notifications"].update(
            {
                "anime": "notify_anime" in request.form,
                "manga": "notify_manga" in request.form,
                "updates": "notify_updates" in request.form,
                "min_interval": int(request.form.get("min_notification_interval", 60)),
                "max_per_day": int(request.form.get("max_notifications_per_day", 25)),
            }
        )

        try:
            save_config(config_data)
            flash("Configuration saved successfully!", "success")
        except Exception as e:
            flash(f"Error saving configuration: {str(e)}", "error")

        return redirect(url_for("config"))

    # Load current configuration
    config_data = load_config()

    return render_template("config.html", config=config_data)


@app.route("/logs")
def logs():
    """System logs and status page"""
    log_file = "logs/system.log"
    logs_data = []

    if os.path.exists(log_file):
        try:
            with open(log_file, "r", encoding="utf-8") as f:
                lines = f.readlines()
                # Get last 100 lines
                logs_data = [line.strip() for line in lines[-100:]]
        except Exception as e:
            logs_data = [f"Error reading log file: {str(e)}"]
    else:
        logs_data = ["No log file found"]

    # System status information
    status = {
        "database_exists": os.path.exists(DATABASE_PATH),
        "config_exists": os.path.exists(CONFIG_PATH),
        "last_run": "Not available",  # This would be updated by the main script
        "system_health": "OK",
    }

    return render_template("logs.html", logs=logs_data, status=status)


@app.route("/api/realtime-logs")
def api_realtime_logs():
    """API endpoint for real-time log data"""
    limit = request.args.get("limit", 50, type=int)
    level_filter = request.args.get("level", "all")

    # Get logs from multiple log files
    log_files = ["logs/app.log", "logs/system.log", "logs/backup.log"]

    all_logs = []

    for log_file in log_files:
        if os.path.exists(log_file):
            try:
                with open(log_file, "r", encoding="utf-8") as f:
                    lines = f.readlines()
                    for line in lines[-100:]:  # Get last 100 from each file
                        line = line.strip()
                        if line:
                            # Parse log entry
                            log_entry = parse_log_entry(line)
                            if log_entry and (
                                level_filter == "all"
                                or log_entry["level"].lower() == level_filter
                            ):
                                all_logs.append(log_entry)
            except Exception as e:
                logger.error(f"Error reading log file {log_file}: {e}")

    # Sort by timestamp and get recent entries
    all_logs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
    recent_logs = all_logs[:limit]

    # Add some current system status logs
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    if not recent_logs:
        # Add system status logs if no logs found
        recent_logs = [
            {
                "timestamp": current_time,
                "level": "INFO",
                "message": "ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«ç¨¼åƒä¸­ã§ã™",
                "formatted": f"[{current_time}] INFO: ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«ç¨¼åƒä¸­ã§ã™",
            },
            {
                "timestamp": current_time,
                "level": "INFO",
                "message": "RSSæ¥ç¶šè¨­å®šãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ",
                "formatted": f"[{current_time}] INFO: RSSæ¥ç¶šè¨­å®šãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ",
            },
            {
                "timestamp": current_time,
                "level": "SUCCESS",
                "message": "APIæ¥ç¶šãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ",
                "formatted": f"[{current_time}] SUCCESS: APIæ¥ç¶šãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ",
            },
        ]

    return jsonify(recent_logs)


def parse_log_entry(log_line):
    """Parse a log line into structured data"""
    import re

    # Try to match common log patterns
    patterns = [
        r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\s*-\s*\w*\s*-\s*(\w+)\s*-\s*(.*)",
        r"\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]\s*(\w+):\s*(.*)",
        r"(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*?(\w+):\s*(.*)",
    ]

    for pattern in patterns:
        match = re.match(pattern, log_line)
        if match:
            timestamp = match.group(1)
            level = match.group(2).upper()
            message = match.group(3)

            return {
                "timestamp": timestamp,
                "level": level,
                "message": message,
                "formatted": f"[{timestamp}] {level}: {message}",
            }

    # If no pattern matches, return the raw line
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return {
        "timestamp": current_time,
        "level": "INFO",
        "message": log_line,
        "formatted": f"[{current_time}] INFO: {log_line}",
    }


@app.route("/api/releases/recent")
def api_recent_releases():
    """API endpoint for recent releases (AJAX) with proper title display"""
    try:
        conn = get_db_connection()
        releases = conn.execute(
            """
            SELECT w.title, w.title_kana, w.type, r.release_type, r.number, r.platform,
                   r.release_date, r.notified
            FROM releases r
            JOIN works w ON r.work_id = w.id
            WHERE r.release_date >= date('now', '-1 days')
            ORDER BY r.release_date DESC
            LIMIT 10
        """
        ).fetchall()
        conn.close()

        data = [dict(release) for release in releases]
        logger.info(f"[API] Returning {len(data)} recent releases")
        return jsonify(data)
    except Exception as e:
        logger.error(f"[API] Error fetching recent releases: {e}", exc_info=True)
        return jsonify({"error": str(e), "message": "Failed to fetch recent releases"}), 500


@app.route("/api/releases/upcoming")
def api_upcoming_releases():
    """API endpoint for upcoming releases with proper title display"""
    try:
        conn = get_db_connection()
        releases = conn.execute(
            """
            SELECT w.id, w.title, w.title_kana, w.type,
                   r.id as release_id, r.release_type, r.number, r.platform,
                   r.release_date, r.source_url, r.notified, r.created_at
            FROM releases r
            JOIN works w ON r.work_id = w.id
            WHERE r.release_date >= date('now')
            ORDER BY r.release_date ASC
            LIMIT 50
        """
        ).fetchall()
        conn.close()

        data = [dict(release) for release in releases]
        logger.info(f"[API] Returning {len(data)} upcoming releases")
        return jsonify(data)
    except Exception as e:
        logger.error(f"[API] Error fetching upcoming releases: {e}", exc_info=True)
        return jsonify({"error": str(e), "message": "Failed to fetch upcoming releases"}), 500


@app.route("/admin")
def admin():
    """System administration interface"""
    return render_template("admin.html")


@app.route("/api/stats")
def api_stats():
    """API endpoint for dashboard statistics"""
    conn = get_db_connection()
    stats = {
        "total_works": conn.execute("SELECT COUNT(*) FROM works").fetchone()[0],
        "total_releases": conn.execute("SELECT COUNT(*) FROM releases").fetchone()[0],
        "pending_notifications": conn.execute(
            "SELECT COUNT(*) FROM releases WHERE notified = 0"
        ).fetchone()[0],
        "today_releases": conn.execute(
            "SELECT COUNT(*) FROM releases WHERE date(release_date) = date('now')"
        ).fetchone()[0],
    }
    conn.close()

    return jsonify(stats)


# Phase 2: Collection Dashboard Routes
@app.route("/collection-dashboard")
def collection_dashboard():
    """Collection status dashboard with real-time monitoring"""
    return render_template("collection_dashboard.html")


@app.route("/data-browser")
def data_browser():
    """Data browser with search and filtering capabilities"""
    return render_template("data_browser.html")


@app.route("/collection-settings")
def collection_settings():
    """Collection settings and configuration management"""
    return render_template("collection_settings.html")


@app.route("/api/rss-feeds")
def api_rss_feeds():
    """Get all RSS feed configurations"""
    try:
        from modules.manga_rss_enhanced import EnhancedMangaRSSCollector

        collector = EnhancedMangaRSSCollector()
        feeds = []

        # Convert MANGA_SOURCES to API response format
        for feed_id, feed_config in collector.MANGA_SOURCES.items():
            feed_data = {
                "id": feed_id,
                "name": feed_config.name,
                "url": feed_config.url,
                "category": feed_config.category,
                "enabled": feed_config.enabled,
                "priority": feed_config.priority,
                "timeout": feed_config.timeout,
                "parser_type": feed_config.parser_type,
                "status": "connected" if feed_config.enabled else "disabled",
                "stats": {
                    "itemsCollected": 0,  # TODO: Get from database
                    "successRate": 0.0     # TODO: Calculate from logs
                }
            }

            # Add error information if available
            # TODO: Retrieve error status from database or logs

            feeds.append(feed_data)

        return jsonify({
            "success": True,
            "feeds": feeds,
            "total": len(feeds)
        })

    except Exception as e:
        logging.error(f"Failed to get RSS feeds: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route("/api/rss-feeds/toggle", methods=["POST"])
def api_rss_feeds_toggle():
    """Toggle RSS feed enable/disable status"""
    try:
        data = request.get_json()
        feed_id = data.get("feedId")
        enabled = data.get("enabled", True)

        if not feed_id:
            return jsonify({
                "success": False,
                "error": "feedId is required"
            }), 400

        # TODO: Persist the enabled/disabled state to database or config file
        # For now, we'll just acknowledge the request

        logging.info(f"RSS feed '{feed_id}' {'enabled' if enabled else 'disabled'}")

        return jsonify({
            "success": True,
            "feedId": feed_id,
            "enabled": enabled
        })

    except Exception as e:
        logging.error(f"Failed to toggle RSS feed: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route("/api/rss-feeds/test", methods=["POST"])
def api_rss_feeds_test():
    """Test connection to an RSS feed"""
    try:
        data = request.get_json()
        feed_id = data.get("feedId")

        if not feed_id:
            return jsonify({
                "success": False,
                "error": "feedId is required"
            }), 400

        from modules.manga_rss_enhanced import EnhancedMangaRSSCollector

        collector = EnhancedMangaRSSCollector()
        feed_config = collector.MANGA_SOURCES.get(feed_id)

        if not feed_config:
            return jsonify({
                "success": False,
                "error": f"Feed '{feed_id}' not found"
            }), 404

        # Test the feed
        import feedparser
        import requests

        try:
            # Use requests with timeout
            response = requests.get(
                feed_config.url,
                timeout=feed_config.timeout,
                headers={
                    'User-Agent': 'Manga-Anime-Collector/1.0 (https://github.com/your-repo)'
                }
            )
            response.raise_for_status()

            # Parse the feed
            feed = feedparser.parse(response.content)

            if feed.bozo:
                # Feed has parsing errors
                return jsonify({
                    "success": False,
                    "error": f"Feed parsing error: {feed.bozo_exception}"
                })

            items_found = len(feed.entries)

            return jsonify({
                "success": True,
                "feedId": feed_id,
                "itemsFound": items_found,
                "feedTitle": feed.feed.get("title", "Unknown")
            })

        except requests.exceptions.Timeout:
            return jsonify({
                "success": False,
                "error": f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆ{feed_config.timeout}ç§’ï¼‰"
            })
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                return jsonify({
                    "success": False,
                    "error": f"ãƒ•ã‚£ãƒ¼ãƒ‰ '{feed_config.name}' ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼ˆã‚µã‚¤ãƒˆå´ã§RSSæä¾›çµ‚äº†ï¼‰",
                    "details": "ä»£æ›¿ãƒ•ã‚£ãƒ¼ãƒ‰: å°‘å¹´ã‚¸ãƒ£ãƒ³ãƒ—+ã€ã¨ãªã‚Šã®ãƒ¤ãƒ³ã‚°ã‚¸ãƒ£ãƒ³ãƒ—"
                })
            else:
                return jsonify({
                    "success": False,
                    "error": f"HTTPã‚¨ãƒ©ãƒ¼: {e.response.status_code}"
                })
        except Exception as e:
            return jsonify({
                "success": False,
                "error": str(e)
            })

    except Exception as e:
        logging.error(f"Failed to test RSS feed: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route("/api/rss-feeds/diagnose", methods=["POST"])
def api_rss_feeds_diagnose():
    """Diagnose RSS feed problems"""
    try:
        data = request.get_json()
        feed_id = data.get("feedId")

        if not feed_id:
            return jsonify({
                "success": False,
                "error": "feedId is required"
            }), 400

        from modules.manga_rss_enhanced import EnhancedMangaRSSCollector
        import requests

        collector = EnhancedMangaRSSCollector()
        feed_config = collector.MANGA_SOURCES.get(feed_id)

        if not feed_config:
            return jsonify({
                "success": False,
                "error": f"Feed '{feed_id}' not found"
            }), 404

        diagnosis = {
            "feedId": feed_id,
            "url": feed_config.url,
            "checks": []
        }

        # Check 1: DNS resolution
        try:
            from urllib.parse import urlparse
            hostname = urlparse(feed_config.url).hostname
            import socket
            socket.gethostbyname(hostname)
            diagnosis["checks"].append({
                "name": "DNSè§£æ±º",
                "status": "success",
                "message": f"ãƒ›ã‚¹ãƒˆ '{hostname}' ã¯è§£æ±ºã•ã‚Œã¾ã—ãŸ"
            })
        except Exception as e:
            diagnosis["checks"].append({
                "name": "DNSè§£æ±º",
                "status": "error",
                "message": f"DNSè§£æ±ºã«å¤±æ•—: {str(e)}"
            })

        # Check 2: HTTP connectivity
        try:
            response = requests.head(
                feed_config.url,
                timeout=10,
                allow_redirects=True,
                headers={'User-Agent': 'Manga-Anime-Collector/1.0'}
            )
            diagnosis["checks"].append({
                "name": "HTTPæ¥ç¶š",
                "status": "success" if response.status_code < 400 else "warning",
                "message": f"HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}"
            })
        except Exception as e:
            diagnosis["checks"].append({
                "name": "HTTPæ¥ç¶š",
                "status": "error",
                "message": f"æ¥ç¶šå¤±æ•—: {str(e)}"
            })

        # Check 3: SSL certificate (if HTTPS)
        if feed_config.url.startswith("https://"):
            try:
                import ssl
                import socket
                from urllib.parse import urlparse

                hostname = urlparse(feed_config.url).hostname
                context = ssl.create_default_context()

                with socket.create_connection((hostname, 443), timeout=10) as sock:
                    with context.wrap_socket(sock, server_hostname=hostname) as ssock:
                        cert = ssock.getpeercert()
                        diagnosis["checks"].append({
                            "name": "SSLè¨¼æ˜æ›¸",
                            "status": "success",
                            "message": "è¨¼æ˜æ›¸ã¯æœ‰åŠ¹ã§ã™"
                        })
            except Exception as e:
                diagnosis["checks"].append({
                    "name": "SSLè¨¼æ˜æ›¸",
                    "status": "error",
                    "message": f"è¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼: {str(e)}"
                })

        # Determine overall status
        error_count = sum(1 for check in diagnosis["checks"] if check["status"] == "error")
        warning_count = sum(1 for check in diagnosis["checks"] if check["status"] == "warning")

        if error_count > 0:
            diagnosis["overallStatus"] = "error"
            diagnosis["recommendation"] = "ã“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚URLã‚’ç¢ºèªã™ã‚‹ã‹ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ã—ã¦ãã ã•ã„ã€‚"
        elif warning_count > 0:
            diagnosis["overallStatus"] = "warning"
            diagnosis["recommendation"] = "æ¥ç¶šã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ç›£è¦–ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚"
        else:
            diagnosis["overallStatus"] = "success"
            diagnosis["recommendation"] = "ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ãŒæˆåŠŸã—ã¾ã—ãŸã€‚"

        return jsonify({
            "success": True,
            "diagnosis": diagnosis
        })

    except Exception as e:
        logging.error(f"Failed to diagnose RSS feed: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route("/api/collection-status")
def api_collection_status():
    """API endpoint for collection status information with caching"""
    current_time = time.time()

    # Check cache first
    if (
        api_status_cache["data"]
        and current_time - api_status_cache["timestamp"] < CACHE_DURATION
    ):
        return jsonify(api_status_cache["data"])

    conn = get_db_connection()

    # Get collection metrics (fast database queries)
    metrics = {
        "todayCollected": conn.execute(
            "SELECT COUNT(*) FROM releases WHERE date(created_at) = date('now')"
        ).fetchone()[0],
        "pendingCount": conn.execute(
            "SELECT COUNT(*) FROM releases WHERE notified = 0"
        ).fetchone()[0],
        "errorCount": 0,  # This would come from logging system
        "systemUptime": "2æ™‚é–“15åˆ†",  # This would come from system monitoring
    }

    # Test API connections (potentially slow)
    api_status = test_api_connections()

    conn.close()

    result = {"metrics": metrics, "apiStatus": api_status}

    # Update cache
    api_status_cache["data"] = result
    api_status_cache["timestamp"] = current_time

    return jsonify(result)


@app.route("/api/works")
def api_works():
    """API endpoint for works data with filtering and pagination"""
    # Get query parameters
    search = request.args.get("search", "")
    work_type = request.args.get("type", "")
    platform = request.args.get("platform", "")
    quality = request.args.get("quality", "")
    start_date = request.args.get("startDate", "")
    end_date = request.args.get("endDate", "")
    genre = request.args.get("genre", "")
    sort = request.args.get("sort", "newest")
    page = int(request.args.get("page", 1))
    per_page = 25

    conn = get_db_connection()

    # Build base query with proper title display
    query = """
        SELECT w.id, w.title, w.title_kana, w.title_en, w.type, w.official_url,
               GROUP_CONCAT(DISTINCT r.platform) as platforms,
               MIN(r.release_date) as next_release_date,
               COUNT(r.id) as release_count
        FROM works w
        LEFT JOIN releases r ON w.id = r.work_id
        WHERE 1=1
    """
    params = []

    # Apply filters
    if search:
        query += " AND (w.title LIKE ? OR w.title_kana LIKE ? OR w.title_en LIKE ?)"
        params.extend([f"%{search}%", f"%{search}%", f"%{search}%"])

    if work_type:
        query += " AND w.type = ?"
        params.append(work_type)

    if platform:
        query += " AND r.platform = ?"
        params.append(platform)

    if start_date:
        query += " AND r.release_date >= ?"
        params.append(start_date)

    if end_date:
        query += " AND r.release_date <= ?"
        params.append(end_date)

    # Add GROUP BY
    query += " GROUP BY w.id, w.title, w.title_kana, w.title_en, w.type, w.official_url"

    # Add sorting
    if sort == "newest":
        query += " ORDER BY MAX(r.created_at) DESC"
    elif sort == "oldest":
        query += " ORDER BY MIN(r.created_at) ASC"
    elif sort == "title_asc":
        query += " ORDER BY w.title ASC"
    elif sort == "title_desc":
        query += " ORDER BY w.title DESC"
    else:
        query += " ORDER BY MAX(r.created_at) DESC"

    # Add pagination
    offset = (page - 1) * per_page
    query += f" LIMIT {per_page} OFFSET {offset}"

    works = conn.execute(query, params).fetchall()

    # Get total count for pagination - Build separate count query
    count_query = """
        SELECT COUNT(DISTINCT w.id)
        FROM works w
        LEFT JOIN releases r ON w.id = r.work_id
        WHERE 1=1
    """
    count_params = []

    # Apply same filters as main query
    if search:
        count_query += (
            " AND (w.title LIKE ? OR w.title_kana LIKE ? OR w.title_en LIKE ?)"
        )
        count_params.extend([f"%{search}%", f"%{search}%", f"%{search}%"])

    if work_type:
        count_query += " AND w.type = ?"
        count_params.append(work_type)

    if platform:
        count_query += " AND r.platform = ?"
        count_params.append(platform)

    if start_date:
        count_query += " AND r.release_date >= ?"
        count_params.append(start_date)

    if end_date:
        count_query += " AND r.release_date <= ?"
        count_params.append(end_date)

    total_count = conn.execute(count_query, count_params).fetchone()[0]

    conn.close()

    # Format works data
    works_data = []
    for work in works:
        work_dict = dict(work)
        work_dict["platforms"] = (
            work_dict["platforms"].split(",") if work_dict["platforms"] else []
        )
        work_dict["quality_score"] = 85  # Mock quality score
        work_dict["genres"] = ["Action", "Adventure"]  # Mock genres
        work_dict["description"] = "ã‚µãƒ³ãƒ—ãƒ«èª¬æ˜æ–‡ã§ã™ã€‚"  # Mock description
        works_data.append(work_dict)

    return jsonify(
        {
            "works": works_data,
            "total": total_count,
            "filtered": len(works_data),
            "totalPages": (total_count + per_page - 1) // per_page,
            "currentPage": page,
        }
    )


@app.route("/api/works/<int:work_id>")
def api_work_detail(work_id):
    """API endpoint for individual work details"""
    conn = get_db_connection()

    work = conn.execute(
        """
        SELECT w.*, w.title, w.title_kana,
               GROUP_CONCAT(DISTINCT r.platform) as platforms
        FROM works w
        LEFT JOIN releases r ON w.id = r.work_id
        WHERE w.id = ?
        GROUP BY w.id
    """,
        [work_id],
    ).fetchone()

    if not work:
        conn.close()
        return jsonify({"error": "Work not found"}), 404

    # Get releases for this work
    releases = conn.execute(
        """
        SELECT * FROM releases WHERE work_id = ? ORDER BY release_date DESC
    """,
        [work_id],
    ).fetchall()

    conn.close()

    work_dict = dict(work)
    work_dict["platforms"] = (
        work_dict["platforms"].split(",") if work_dict["platforms"] else []
    )
    work_dict["releases"] = [dict(release) for release in releases]
    work_dict["quality_score"] = 85  # Mock quality score
    work_dict["genres"] = ["Action", "Adventure"]  # Mock genres
    work_dict["description"] = "ã‚µãƒ³ãƒ—ãƒ«èª¬æ˜æ–‡ã§ã™ã€‚"  # Mock description

    return jsonify(work_dict)


@app.route("/api/watchlist/add", methods=["POST"])
def api_add_to_watchlist():
    """API endpoint to add work to watchlist"""
    data = request.get_json()
    work_id = data.get("work_id")

    if not work_id:
        return jsonify({"error": "work_id is required"}), 400

    # This would add to user's watchlist in a real implementation
    # For now, just return success
    return jsonify({"success": True, "message": "Added to watchlist"})


@app.route("/api/manual-collection", methods=["POST"])
def api_manual_collection():
    """API endpoint to trigger manual collection"""
    # This would trigger the actual collection process
    # For now, just return success
    return jsonify({"success": True, "message": "Manual collection started"})


@app.route("/api/refresh-upcoming", methods=["POST"])
def api_refresh_upcoming():
    """API endpoint to refresh upcoming releases"""
    try:
        # This would trigger the actual collection process for upcoming releases
        # For now, return success with timestamp
        from datetime import datetime

        result = {
            "success": True,
            "message": "ä»Šå¾Œã®äºˆå®šã‚’æ›´æ–°ã—ã¾ã—ãŸ",
            "timestamp": datetime.now().isoformat(),
            "count": 0  # This would be the actual count of updated releases
        }

        logger.info("Upcoming releases refresh triggered")
        return jsonify(result)

    except Exception as e:
        logger.error(f"Error refreshing upcoming releases: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route("/api/refresh-history", methods=["POST"])
def api_refresh_history():
    """API endpoint to refresh release history"""
    try:
        # This would trigger the actual collection process for historical data
        # For now, return success with timestamp
        from datetime import datetime

        result = {
            "success": True,
            "message": "ãƒªãƒªãƒ¼ã‚¹å±¥æ­´ã‚’æ›´æ–°ã—ã¾ã—ãŸ",
            "timestamp": datetime.now().isoformat(),
            "count": 0  # This would be the actual count of updated releases
        }

        logger.info("Release history refresh triggered")
        return jsonify(result)

    except Exception as e:
        logger.error(f"Error refreshing release history: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route("/api/settings", methods=["GET", "POST"])
def api_settings():
    """API endpoint for settings management"""
    # Import database manager
    import sys
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from modules.db import get_db

    db_manager = get_db()

    if request.method == "GET":
        try:
            # Get all settings from database
            settings = db_manager.get_all_settings()

            # If no settings found, return defaults
            if not settings:
                settings = {
                    "notification_email": "kensan1969@gmail.com",
                    "check_interval_hours": 1,
                    "email_notifications_enabled": True,
                    "calendar_enabled": False,
                    "max_notifications_per_day": 50
                }

            return jsonify({
                "success": True,
                "settings": settings
            })

        except Exception as e:
            logger.error(f"Error getting settings: {e}")
            return jsonify({
                "success": False,
                "error": str(e)
            }), 500

    elif request.method == "POST":
        try:
            # Update settings
            data = request.get_json()

            if not data:
                return jsonify({
                    "success": False,
                    "error": "No data provided"
                }), 400

            # Update settings in database
            db_manager.update_settings(data)

            logger.info(f"Settings updated: {list(data.keys())}")

            return jsonify({
                "success": True,
                "message": "è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ",
                "settings": db_manager.get_all_settings()
            })

        except Exception as e:
            logger.error(f"Error updating settings: {e}")
            return jsonify({
                "success": False,
                "error": str(e)
            }), 500


@app.route("/api/collection-processes")
def api_collection_processes():
    """API endpoint for collection processes status"""
    # Mock collection processes data - in production this would come from actual process monitoring
    processes = [
        {
            "id": "anilist_api",
            "name": "AniList GraphQL API",
            "type": "ã‚¢ãƒ‹ãƒ¡æƒ…å ±",
            "status": "connected",
            "last_update": "2åˆ†å‰",
            "success_rate": 98,
            "response_time": "1.2s",
            "note": "APIæ­£å¸¸ç¨¼åƒä¸­",
        },
        {
            "id": "shobo_calendar",
            "name": "ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼",
            "type": "TVæ”¾é€æƒ…å ±",
            "status": "connected",
            "last_update": "5åˆ†å‰",
            "success_rate": 92,
            "response_time": "2.1s",
            "note": "ãƒ‡ãƒ¼ã‚¿å–å¾—æ­£å¸¸",
        },
        {
            "id": "yahoo_rss",
            "name": "Yahoo News RSS",
            "type": "ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±",
            "status": "connected",
            "last_update": "3åˆ†å‰",
            "success_rate": 95,
            "response_time": "0.8s",
            "note": "RSSå–å¾—æˆåŠŸ",
        },
        {
            "id": "nhk_rss",
            "name": "NHK News RSS",
            "type": "ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±",
            "status": "connected",
            "last_update": "1åˆ†å‰",
            "success_rate": 92,
            "response_time": "1.5s",
            "note": "RSSå–å¾—æˆåŠŸ",
        },
    ]

    return jsonify(processes)


@app.route("/api/collection-processes/retry", methods=["POST"])
def api_retry_collection_process():
    """API endpoint to retry a specific collection process"""
    data = request.get_json()
    process_id = data.get("process_id")

    if not process_id:
        return jsonify({"error": "process_id is required"}), 400

    # Fast retry operation (no sleep needed for UI responsiveness)
    return jsonify(
        {
            "success": True,
            "message": f"Collection process {process_id} retry completed",
            "process_id": process_id,
            "new_status": "connected",
        }
    )


@app.route("/debug")
def debug():
    """Debug test page"""
    return render_template("debug.html")


@app.route("/ws/collection-status")
def websocket_collection_status():
    """Fallback endpoint for collection status (replaces WebSocket for now)"""
    # Return regular JSON response instead of WebSocket error
    return (
        jsonify(
            {"status": "ok", "message": "Real-time updates available via API polling"}
        ),
        200,
    )


@app.route("/api/test-notification", methods=["POST"])
def api_test_notification():
    """API endpoint for sending test notifications"""
    import smtplib
    import ssl
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    from dotenv import load_dotenv

    try:
        # .envãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        load_dotenv()

        data = request.get_json() or {}
        message = data.get("message", "ãƒ†ã‚¹ãƒˆé€šçŸ¥ã§ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")

        logger.info(f"Test notification requested: {message}")

        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±å–å¾—
        gmail_address = os.getenv('GMAIL_ADDRESS')
        gmail_password = os.getenv('GMAIL_APP_PASSWORD')

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å–å¾—
        config = load_config()
        from_email = gmail_address or config.get('notification_email', '')
        to_email = gmail_address or config.get('notification_email', '')

        if not from_email or not to_email:
            return jsonify({
                "success": False,
                "error": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            }), 400

        if not gmail_password:
            return jsonify({
                "success": False,
                "error": "Gmailã‚¢ãƒ—ãƒªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªï¼‰"
            }), 400

        # ãƒ†ã‚¹ãƒˆãƒ¡ãƒ¼ãƒ«ä½œæˆ
        msg = MIMEMultipart('alternative')
        msg['Subject'] = 'ã€MangaAnimeã€‘ãƒ†ã‚¹ãƒˆé€šçŸ¥ âœ…'
        msg['From'] = from_email
        msg['To'] = to_email

        html_body = f"""
        <html>
        <head>
            <style>
                body {{ font-family: 'Segoe UI', Arial, sans-serif; background-color: #f5f5f5; padding: 20px; }}
                .container {{ max-width: 600px; margin: 0 auto; background: white; border-radius: 10px; padding: 30px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                h2 {{ color: #0d6efd; border-bottom: 3px solid #0d6efd; padding-bottom: 10px; }}
                .info-box {{ background: #e7f3ff; padding: 15px; border-radius: 5px; margin: 20px 0; }}
                ul {{ list-style-type: none; padding-left: 0; }}
                li {{ padding: 8px 0; border-bottom: 1px solid #eee; }}
                .footer {{ text-align: center; color: #6c757d; font-size: 0.9em; margin-top: 30px; padding-top: 20px; border-top: 1px solid #eee; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h2>ğŸ¬ MangaAnimeæƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ </h2>
                <div class="info-box">
                    <p><strong>ğŸ“§ {message}</strong></p>
                </div>
                <h3>ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±</h3>
                <ul>
                    <li><strong>é€ä¿¡å…ƒ:</strong> {from_email}</li>
                    <li><strong>é€ä¿¡å…ˆ:</strong> {to_email}</li>
                    <li><strong>é€ä¿¡æ—¥æ™‚:</strong> {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</li>
                    <li><strong>ã‚µãƒ¼ãƒãƒ¼:</strong> Gmail SMTP</li>
                </ul>
                <div class="footer">
                    <p>ğŸ¤– ã“ã®ãƒ¡ãƒ¼ãƒ«ã¯MangaAnimeæƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰è‡ªå‹•é€ä¿¡ã•ã‚Œã¾ã—ãŸ</p>
                    <p>ã‚·ã‚¹ãƒ†ãƒ ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ âœ…</p>
                </div>
            </div>
        </body>
        </html>
        """
        msg.attach(MIMEText(html_body, 'html'))

        # Gmail SMTPçµŒç”±ã§é€ä¿¡
        context = ssl.create_default_context()
        with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=context) as server:
            server.login(from_email, gmail_password)
            server.send_message(msg)

        logger.info(f"âœ… Test email sent successfully: {from_email} -> {to_email}")

        return jsonify({
            "success": True,
            "message": f"âœ… ãƒ†ã‚¹ãƒˆé€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸï¼\n\né€ä¿¡å…ˆ: {to_email}\nãƒ¡ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
            "details": {
                "from": from_email,
                "to": to_email,
                "sent_at": datetime.now().isoformat()
            }
        })

    except ImportError as e:
        logger.error(f"Failed to import email sender: {e}")
        return (
            jsonify(
                {
                    "success": False,
                    "error": "ãƒ¡ãƒ¼ãƒ«é€ä¿¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ",
                }
            ),
            500,
        )
    except Exception as e:
        logger.error(f"Test notification error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route("/api/test-configuration", methods=["POST"])
def api_test_configuration():
    """Test all system configurations"""
    import requests
    import sqlite3
    import os
    import smtplib
    import ssl

    results = {
        "gmail": {"status": "testing", "message": "", "details": {}},
        "database": {"status": "testing", "message": "", "details": {}},
        "anilist": {"status": "testing", "message": "", "details": {}},
        "rss_feeds": {"status": "testing", "message": "", "details": {}},
    }

    try:
        # Load configuration
        with open("config.json", "r", encoding="utf-8") as f:
            config = json.load(f)
    except Exception as e:
        return (
            jsonify({"success": False, "error": f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}"}),
            500,
        )

    # Test Gmail SMTP connection
    try:
        # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
        from dotenv import load_dotenv
        load_dotenv()

        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        sender_email = os.getenv('GMAIL_ADDRESS') or os.getenv('GMAIL_SENDER_EMAIL', '')
        sender_password = os.getenv('GMAIL_APP_PASSWORD', '')

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: config.jsonã‹ã‚‰å–å¾—
        if not sender_email:
            gmail_config = config.get("google", {}).get("gmail", {})
            sender_email = gmail_config.get("from_email", "")

        smtp_server = "smtp.gmail.com"
        smtp_port = 465  # SSLæ¥ç¶š

        if not sender_email or not sender_password:
            results["gmail"]["status"] = "error"
            results["gmail"]["message"] = "ãƒ¡ãƒ¼ãƒ«è¨­å®šãŒä¸å®Œå…¨ã§ã™ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰"
        else:
            # SSLæ¥ç¶šï¼ˆ465ãƒãƒ¼ãƒˆï¼‰
            context = ssl.create_default_context()
            with smtplib.SMTP_SSL(smtp_server, smtp_port, context=context, timeout=10) as server:
                server.login(sender_email, sender_password)

            results["gmail"]["status"] = "success"
            results["gmail"]["message"] = "Gmailæ¥ç¶šæˆåŠŸ"
            results["gmail"]["details"] = {
                "server": smtp_server,
                "port": smtp_port,
                "email": sender_email,
            }
    except Exception as e:
        results["gmail"]["status"] = "error"
        results["gmail"]["message"] = f"Gmailæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}"

    # Test Database connection
    try:
        db_path = config.get("database", {}).get("path", "./db.sqlite3")
        if not os.path.exists(db_path):
            results["database"]["status"] = "error"
            results["database"]["message"] = "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        else:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            # Check table existence
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]

            # Count records
            works_count = 0
            releases_count = 0
            if "works" in tables:
                cursor.execute("SELECT COUNT(*) FROM works")
                works_count = cursor.fetchone()[0]
            if "releases" in tables:
                cursor.execute("SELECT COUNT(*) FROM releases")
                releases_count = cursor.fetchone()[0]

            conn.close()

            results["database"]["status"] = "success"
            results["database"]["message"] = "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ"
            results["database"]["details"] = {
                "path": db_path,
                "tables": tables,
                "works_count": works_count,
                "releases_count": releases_count,
            }
    except Exception as e:
        results["database"]["status"] = "error"
        results["database"]["message"] = f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}"

    # Test AniList API
    try:
        anilist_config = config.get("apis", {}).get("anilist", {})
        graphql_url = anilist_config.get("graphql_url", "https://graphql.anilist.co")
        timeout = anilist_config.get("timeout_seconds", 30)

        # Simple AniList query
        query = """
        query {
            Media(id: 1) {
                id
                title {
                    romaji
                }
            }
        }
        """

        response = requests.post(
            graphql_url,
            json={"query": query},
            timeout=timeout,
            headers={"Content-Type": "application/json"},
        )

        if response.status_code == 200:
            data = response.json()
            if "data" in data:
                results["anilist"]["status"] = "success"
                results["anilist"]["message"] = "AniList APIæ¥ç¶šæˆåŠŸ"
                results["anilist"]["details"] = {
                    "url": graphql_url,
                    "response_time": f"{response.elapsed.total_seconds():.2f}ç§’",
                }
            else:
                results["anilist"]["status"] = "error"
                results["anilist"]["message"] = "AniList APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼"
        else:
            results["anilist"]["status"] = "error"
            results["anilist"][
                "message"
            ] = f"AniList API HTTPã‚¨ãƒ©ãƒ¼: {response.status_code}"

    except Exception as e:
        results["anilist"]["status"] = "error"
        results["anilist"]["message"] = f"AniList APIã‚¨ãƒ©ãƒ¼: {str(e)}"

    # Test RSS Feeds
    try:
        rss_config = config.get("apis", {}).get("rss_feeds", {})
        feeds = rss_config.get("feeds", [])
        timeout = rss_config.get("timeout_seconds", 20)
        user_agent = rss_config.get("user_agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

        feed_results = []
        success_count = 0

        for feed in feeds[:3]:  # Test first 3 feeds only
            feed_name = feed.get("name", "Unknown")
            feed_url = feed.get("url", "")
            enabled = feed.get("enabled", False)

            if not enabled:
                feed_results.append(
                    {
                        "name": feed_name,
                        "status": "disabled",
                        "message": "ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™",
                    }
                )
                continue

            try:
                # User-Agentãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã¦ãƒœãƒƒãƒˆå¯¾ç­–ã‚’å›é¿
                headers = {
                    'User-Agent': user_agent,
                    'Accept': 'application/rss+xml, application/xml, text/xml, */*'
                }
                response = requests.get(feed_url, headers=headers, timeout=timeout)
                if response.status_code == 200:
                    success_count += 1
                    feed_results.append(
                        {"name": feed_name, "status": "success", "message": "æ¥ç¶šæˆåŠŸ"}
                    )
                else:
                    feed_results.append(
                        {
                            "name": feed_name,
                            "status": "error",
                            "message": f"HTTPã‚¨ãƒ©ãƒ¼: {response.status_code}",
                        }
                    )
            except Exception as e:
                feed_results.append(
                    {
                        "name": feed_name,
                        "status": "error",
                        "message": f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}",
                    }
                )

        if success_count > 0:
            results["rss_feeds"]["status"] = "success"
            results["rss_feeds"][
                "message"
            ] = f"{success_count}/{len(feed_results)}å€‹ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ãŒæ­£å¸¸"
        else:
            results["rss_feeds"]["status"] = "error"
            results["rss_feeds"]["message"] = "ã™ã¹ã¦ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼"

        results["rss_feeds"]["details"] = {"feeds": feed_results}

    except Exception as e:
        results["rss_feeds"]["status"] = "error"
        results["rss_feeds"]["message"] = f"RSSãƒ•ã‚£ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"

    # Calculate overall success
    success_count = sum(
        1 for result in results.values() if result["status"] == "success"
    )
    total_tests = len(results)
    overall_success = success_count == total_tests

    return jsonify(
        {
            "success": overall_success,
            "summary": {
                "passed": success_count,
                "total": total_tests,
                "message": (
                    f"{success_count}/{total_tests}å€‹ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸ"
                    if overall_success
                    else f"{total_tests - success_count}å€‹ã®ãƒ†ã‚¹ãƒˆã§å•é¡ŒãŒç™ºç”Ÿ"
                ),
            },
            "results": results,
        }
    )


@app.route("/api/generate-ics", methods=["POST"])
def generate_ics():
    """é¸æŠã•ã‚ŒãŸãƒªãƒªãƒ¼ã‚¹ã‹ã‚‰iCalendarãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    from datetime import datetime as dt
    import uuid
    from flask import Response

    try:
        data = request.get_json()
        releases = data.get('releases', [])

        if not releases:
            return jsonify({'error': 'ç™»éŒ²ã™ã‚‹ãƒªãƒªãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“'}), 400

        # iCalendarå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        ics_content = ['BEGIN:VCALENDAR']
        ics_content.append('VERSION:2.0')
        ics_content.append('PRODID:-//MangaAnime Info System//Calendar//JP')
        ics_content.append('CALSCALE:GREGORIAN')
        ics_content.append('METHOD:PUBLISH')
        ics_content.append('X-WR-CALNAME:ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬ãƒªãƒªãƒ¼ã‚¹äºˆå®š')
        ics_content.append('X-WR-TIMEZONE:Asia/Tokyo')

        for release in releases:
            # ã‚¤ãƒ™ãƒ³ãƒˆIDç”Ÿæˆ
            event_uid = str(uuid.uuid4())

            # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
            type_icon = 'ğŸ¬' if release.get('type') == 'anime' else 'ğŸ“š'
            type_label = 'ã‚¢ãƒ‹ãƒ¡' if release.get('type') == 'anime' else 'ãƒãƒ³ã‚¬'
            release_text = 'è©±' if release.get('release_type') == 'episode' else 'å·»'

            title = f"{type_icon}ã€{type_label}ã€‘{release.get('title', '')} ç¬¬{release.get('number', '')}{release_text} | {release.get('platform', '')}"

            # è©³ç´°æƒ…å ±
            description = f"ä½œå“: {release.get('title', '')}\\n"
            description += f"ã‚¿ã‚¤ãƒ—: {type_label}\\n"
            description += f"{release_text}: ç¬¬{release.get('number', '')}{release_text}\\n"
            description += f"é…ä¿¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {release.get('platform', '')}\\n"
            if release.get('source_url'):
                description += f"ã‚½ãƒ¼ã‚¹URL: {release.get('source_url')}\\n"
            description += "\\n---\\nè‡ªå‹•ç™»éŒ²: MangaAnimeæƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ "

            # æ—¥ä»˜ï¼ˆYYYYMMDDå½¢å¼ï¼‰
            release_date = release.get('release_date', '')
            date_str = release_date.replace('-', '')

            # ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ
            ics_content.append('BEGIN:VEVENT')
            ics_content.append(f'UID:{event_uid}')
            ics_content.append(f'DTSTAMP:{dt.now().strftime("%Y%m%dT%H%M%SZ")}')
            ics_content.append(f'DTSTART;VALUE=DATE:{date_str}')
            ics_content.append(f'DTEND;VALUE=DATE:{date_str}')
            ics_content.append(f'SUMMARY:{title}')
            ics_content.append(f'DESCRIPTION:{description}')
            ics_content.append(f'LOCATION:{release.get("platform", "")}')
            ics_content.append('STATUS:CONFIRMED')
            ics_content.append('TRANSP:TRANSPARENT')
            ics_content.append('END:VEVENT')

        ics_content.append('END:VCALENDAR')

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
        ics_text = '\r\n'.join(ics_content)

        return Response(
            ics_text,
            mimetype='text/calendar',
            headers={
                'Content-Disposition': f'attachment; filename=anime_manga_releases_{dt.now().strftime("%Y%m%d")}.ics'
            }
        )

    except Exception as e:
        logger.error(f'iCalendarç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}')
        return jsonify({'error': str(e)}), 500


@app.route("/api/notification-status")
def api_notification_status():
    """é€šçŸ¥ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼é€£æºã®å®Ÿè¡ŒçŠ¶æ³ã‚’è¿”ã™APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆnotification_historyä½¿ç”¨ï¼‰"""
    try:
        from datetime import timedelta, time
        from datetime import datetime as dt

        conn = get_db_connection()

        # ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã®æœ€çµ‚å®Ÿè¡Œæ™‚åˆ»ã¨çµ±è¨ˆã‚’å–å¾—
        email_last = conn.execute("""
            SELECT executed_at, success, error_message, releases_count
            FROM notification_history
            WHERE notification_type = 'email'
            ORDER BY executed_at DESC
            LIMIT 1
        """).fetchone()

        # ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã®æœ¬æ—¥ã®çµ±è¨ˆ
        email_stats_today = conn.execute("""
            SELECT
                COUNT(*) as total_executions,
                SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as success_count,
                SUM(CASE WHEN success = 0 THEN 1 ELSE 0 END) as error_count,
                SUM(CASE WHEN success = 1 THEN releases_count ELSE 0 END) as total_releases
            FROM notification_history
            WHERE notification_type = 'email' AND DATE(executed_at) = DATE('now')
        """).fetchone()

        # ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã®ç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼
        email_recent_errors = conn.execute("""
            SELECT executed_at, error_message, releases_count
            FROM notification_history
            WHERE notification_type = 'email' AND success = 0
            ORDER BY executed_at DESC
            LIMIT 5
        """).fetchall()

        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç™»éŒ²ã®æœ€çµ‚å®Ÿè¡Œæ™‚åˆ»ã¨çµ±è¨ˆã‚’å–å¾—
        calendar_last = conn.execute("""
            SELECT executed_at, success, error_message, releases_count
            FROM notification_history
            WHERE notification_type = 'calendar'
            ORDER BY executed_at DESC
            LIMIT 1
        """).fetchone()

        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç™»éŒ²ã®æœ¬æ—¥ã®çµ±è¨ˆ
        calendar_stats_today = conn.execute("""
            SELECT
                COUNT(*) as total_executions,
                SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as success_count,
                SUM(CASE WHEN success = 0 THEN 1 ELSE 0 END) as error_count,
                SUM(CASE WHEN success = 1 THEN releases_count ELSE 0 END) as total_events
            FROM notification_history
            WHERE notification_type = 'calendar' AND DATE(executed_at) = DATE('now')
        """).fetchone()

        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç™»éŒ²ã®ç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼
        calendar_recent_errors = conn.execute("""
            SELECT executed_at, error_message, releases_count
            FROM notification_history
            WHERE notification_type = 'calendar' AND success = 0
            ORDER BY executed_at DESC
            LIMIT 5
        """).fetchall()

        # settingsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒã‚§ãƒƒã‚¯é–“éš”ã‚’å–å¾—
        check_interval = conn.execute("""
            SELECT value FROM settings WHERE key = 'check_interval_hours'
        """).fetchone()

        interval_hours = int(check_interval['value']) if check_interval else 1

        # æ¬¡å›å®Ÿè¡Œäºˆå®šæ™‚åˆ»ã‚’è¨ˆç®—
        now = dt.now()
        if email_last and email_last['executed_at']:
            last_executed = dt.fromisoformat(email_last['executed_at'])
            next_run = last_executed + timedelta(hours=interval_hours)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æ¬¡ã®æ•´æ™‚
            next_run = dt.combine(now.date(), time(now.hour + 1, 0))

        conn.close()

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ§‹ç¯‰
        response = {
            'email': {
                'lastExecuted': email_last['executed_at'] if email_last else None,
                'lastSuccess': email_last['success'] == 1 if email_last else None,
                'lastError': email_last['error_message'] if email_last and not email_last['success'] else None,
                'lastReleasesCount': email_last['releases_count'] if email_last else 0,
                'nextScheduled': next_run.isoformat(),
                'checkIntervalHours': interval_hours,
                'todayStats': {
                    'totalExecutions': email_stats_today['total_executions'] if email_stats_today else 0,
                    'successCount': email_stats_today['success_count'] if email_stats_today else 0,
                    'errorCount': email_stats_today['error_count'] if email_stats_today else 0,
                    'totalReleases': email_stats_today['total_releases'] if email_stats_today else 0,
                },
                'recentErrors': [
                    {
                        'time': row['executed_at'],
                        'message': row['error_message'],
                        'releasesCount': row['releases_count']
                    }
                    for row in email_recent_errors
                ],
                'status': 'success' if (email_last and email_last['success']) else ('error' if email_last else 'unknown')
            },
            'calendar': {
                'lastExecuted': calendar_last['executed_at'] if calendar_last else None,
                'lastSuccess': calendar_last['success'] == 1 if calendar_last else None,
                'lastError': calendar_last['error_message'] if calendar_last and not calendar_last['success'] else None,
                'lastEventsCount': calendar_last['releases_count'] if calendar_last else 0,
                'nextScheduled': next_run.isoformat(),
                'checkIntervalHours': interval_hours,
                'todayStats': {
                    'totalExecutions': calendar_stats_today['total_executions'] if calendar_stats_today else 0,
                    'successCount': calendar_stats_today['success_count'] if calendar_stats_today else 0,
                    'errorCount': calendar_stats_today['error_count'] if calendar_stats_today else 0,
                    'totalEvents': calendar_stats_today['total_events'] if calendar_stats_today else 0,
                },
                'recentErrors': [
                    {
                        'time': row['executed_at'],
                        'message': row['error_message'],
                        'eventsCount': row['releases_count']
                    }
                    for row in calendar_recent_errors
                ],
                'status': 'success' if (calendar_last and calendar_last['success']) else ('error' if calendar_last else 'unknown')
            },
            'overall': {
                'healthStatus': 'healthy' if (
                    (not email_last or email_last['success']) and
                    (not calendar_last or calendar_last['success'])
                ) else 'issues',
                'lastUpdate': now.isoformat()
            }
        }

        return jsonify(response)

    except Exception as e:
        logger.error(f'é€šçŸ¥çŠ¶æ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}')
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({'error': str(e)}), 500


# ============================================================================
# API Source Testing and Configuration Endpoints
# ============================================================================

@app.route('/api/sources')
def api_sources():
    """
    Get all collection sources with their status and configuration.
    
    Returns:
        JSON with list of all sources (APIs and RSS feeds) including:
        - Source name and type
        - Enabled/disabled status
        - Last test results
        - Configuration details
    """
    try:
        config = load_config()
        
        sources = {
            'apis': [],
            'rss_feeds': [],
            'summary': {
                'total_sources': 0,
                'enabled_sources': 0,
                'disabled_sources': 0,
                'last_updated': datetime.now().isoformat()
            }
        }
        
        # AniList API
        anilist_config = config.get('apis', {}).get('anilist', {})
        anilist_source = {
            'id': 'anilist',
            'name': 'AniList GraphQL API',
            'type': 'api',
            'enabled': anilist_config.get('enabled', True),
            'url': anilist_config.get('graphql_url', 'https://graphql.anilist.co'),
            'rate_limit': anilist_config.get('rate_limit', {}).get('requests_per_minute', 90),
            'timeout': anilist_config.get('timeout_seconds', 30),
            'description': 'ã‚¢ãƒ‹ãƒ¡æƒ…å ±å–å¾—ç”¨GraphQL API',
            'data_type': 'anime',
            'last_test': None,  # Will be populated if available
            'health_status': 'unknown'
        }
        sources['apis'].append(anilist_source)

        # Kitsu API
        kitsu_config = config.get('apis', {}).get('kitsu', {})
        if kitsu_config:
            kitsu_source = {
                'id': 'kitsu',
                'name': 'Kitsu API',
                'type': 'api',
                'enabled': kitsu_config.get('enabled', True),
                'url': kitsu_config.get('base_url', 'https://kitsu.io/api/edge'),
                'rate_limit': kitsu_config.get('rate_limit', {}).get('requests_per_minute', 90),
                'timeout': kitsu_config.get('timeout_seconds', 30),
                'description': 'ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬æƒ…å ±å–å¾—ç”¨REST API',
                'data_type': 'anime_manga',
                'last_test': None,
                'health_status': 'unknown'
            }
            sources['apis'].append(kitsu_source)

        # MangaDex API
        mangadex_config = config.get('apis', {}).get('mangadex', {})
        if mangadex_config:
            mangadex_source = {
                'id': 'mangadex',
                'name': 'MangaDex API',
                'type': 'api',
                'enabled': mangadex_config.get('enabled', True),
                'url': mangadex_config.get('base_url', 'https://api.mangadex.org'),
                'rate_limit': mangadex_config.get('rate_limit', {}).get('requests_per_minute', 40),
                'timeout': mangadex_config.get('timeout_seconds', 30),
                'description': 'ãƒãƒ³ã‚¬æƒ…å ±å–å¾—ç”¨REST API',
                'data_type': 'manga',
                'last_test': None,
                'health_status': 'unknown'
            }
            sources['apis'].append(mangadex_source)

        # MangaUpdates API
        mangaupdates_config = config.get('apis', {}).get('mangaupdates', {})
        if mangaupdates_config:
            mangaupdates_source = {
                'id': 'mangaupdates',
                'name': 'MangaUpdates API',
                'type': 'api',
                'enabled': mangaupdates_config.get('enabled', True),
                'url': mangaupdates_config.get('base_url', 'https://api.mangaupdates.com/v1'),
                'rate_limit': mangaupdates_config.get('rate_limit', {}).get('requests_per_minute', 30),
                'timeout': mangaupdates_config.get('timeout_seconds', 30),
                'description': 'ãƒãƒ³ã‚¬ãƒªãƒªãƒ¼ã‚¹æƒ…å ±å–å¾—ç”¨REST API',
                'data_type': 'manga',
                'last_test': None,
                'health_status': 'unknown'
            }
            sources['apis'].append(mangaupdates_source)

        # Syoboi Calendar API
        syoboi_config = config.get('apis', {}).get('syoboi', {})
        syoboi_source = {
            'id': 'syoboi',
            'name': 'ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼',
            'type': 'api',
            'enabled': syoboi_config.get('enabled', False),
            'url': syoboi_config.get('base_url', 'https://cal.syoboi.jp'),
            'rate_limit': syoboi_config.get('rate_limit', {}).get('requests_per_minute', 60),
            'description': 'æ—¥æœ¬ã®ã‚¢ãƒ‹ãƒ¡æ”¾é€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«',
            'data_type': 'anime',
            'last_test': None,
            'health_status': 'unknown'
        }
        sources['apis'].append(syoboi_source)
        
        # RSS Feeds
        rss_config = config.get('apis', {}).get('rss_feeds', {})
        rss_feeds = rss_config.get('feeds', [])
        
        for feed in rss_feeds:
            feed_source = {
                'id': feed.get('name', '').lower().replace(' ', '_').replace('ï¼‹', 'plus'),
                'name': feed.get('name', 'Unknown'),
                'type': 'rss',
                'enabled': feed.get('enabled', False),
                'url': feed.get('url', ''),
                'description': feed.get('description', ''),
                'data_type': feed.get('type', 'manga'),
                'verified': feed.get('verified', False),
                'timeout': feed.get('timeout', 25),
                'retry_count': feed.get('retry_count', 3),
                'last_test': None,
                'health_status': 'unknown' if feed.get('enabled') else 'disabled'
            }
            sources['rss_feeds'].append(feed_source)
        
        # Calculate summary
        total_apis = len(sources['apis'])
        total_rss = len(sources['rss_feeds'])
        sources['summary']['total_sources'] = total_apis + total_rss
        sources['summary']['enabled_sources'] = (
            sum(1 for api in sources['apis'] if api['enabled']) +
            sum(1 for rss in sources['rss_feeds'] if rss['enabled'])
        )
        sources['summary']['disabled_sources'] = (
            sources['summary']['total_sources'] - sources['summary']['enabled_sources']
        )
        
        return jsonify(sources)
        
    except Exception as e:
        logger.error(f"Failed to get sources: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({'error': str(e)}), 500


@app.route('/api/sources/anilist/test', methods=['POST'])
def api_test_anilist():
    """
    Test AniList GraphQL API connection.
    
    Returns:
        JSON with test results including:
        - Connection status
        - Response time
        - Error details if any
        - Sample data retrieval success
    """
    try:
        start_time = time.time()
        test_results = {
            'source': 'anilist',
            'timestamp': datetime.now().isoformat(),
            'tests': []
        }
        
        # Test 1: Basic connectivity
        try:
            basic_query = '{ Media(id: 1) { id title { romaji } } }'
            response = requests.post(
                'https://graphql.anilist.co',
                json={'query': basic_query},
                headers={'User-Agent': 'MangaAnimeNotifier/1.0'},
                timeout=5
            )
            basic_time = time.time() - start_time
            
            test_results['tests'].append({
                'name': 'basic_connectivity',
                'status': 'success' if response.status_code == 200 else 'failed',
                'response_time_ms': round(basic_time * 1000, 2),
                'http_status': response.status_code,
                'details': f'HTTP {response.status_code}' if response.status_code != 200 else 'GraphQL API responding'
            })
            
            if response.status_code == 200:
                data = response.json()
                if 'errors' in data:
                    test_results['tests'][-1]['status'] = 'warning'
                    test_results['tests'][-1]['details'] = f"GraphQL errors: {data['errors']}"
                    
        except requests.exceptions.Timeout:
            test_results['tests'].append({
                'name': 'basic_connectivity',
                'status': 'failed',
                'response_time_ms': 5000,
                'error': 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (5ç§’)'
            })
        except Exception as e:
            test_results['tests'].append({
                'name': 'basic_connectivity',
                'status': 'error',
                'error': str(e)
            })
        
        # Test 2: Current season query
        try:
            now = datetime.now()
            year = now.year
            month = now.month
            if month in [12, 1, 2]:
                season = "WINTER"
            elif month in [3, 4, 5]:
                season = "SPRING"
            elif month in [6, 7, 8]:
                season = "SUMMER"
            else:
                season = "FALL"
            
            season_query = f'''
            {{
                Page(page: 1, perPage: 5) {{
                    media(season: {season}, seasonYear: {year}, type: ANIME) {{
                        id
                        title {{ romaji }}
                        status
                    }}
                }}
            }}
            '''
            
            start_season = time.time()
            response = requests.post(
                'https://graphql.anilist.co',
                json={'query': season_query},
                headers={'User-Agent': 'MangaAnimeNotifier/1.0'},
                timeout=5
            )
            season_time = time.time() - start_season
            
            if response.status_code == 200:
                data = response.json()
                media_count = len(data.get('data', {}).get('Page', {}).get('media', []))
                test_results['tests'].append({
                    'name': 'current_season_query',
                    'status': 'success',
                    'response_time_ms': round(season_time * 1000, 2),
                    'results_count': media_count,
                    'details': f'{season} {year}ã‚·ãƒ¼ã‚ºãƒ³ã®ã‚¢ãƒ‹ãƒ¡{media_count}ä»¶å–å¾—'
                })
            else:
                test_results['tests'].append({
                    'name': 'current_season_query',
                    'status': 'failed',
                    'http_status': response.status_code,
                    'response_time_ms': round(season_time * 1000, 2)
                })
                
        except Exception as e:
            test_results['tests'].append({
                'name': 'current_season_query',
                'status': 'error',
                'error': str(e)
            })
        
        # Test 3: Rate limit check
        test_results['tests'].append({
            'name': 'rate_limit_info',
            'status': 'info',
            'details': 'AniList rate limit: 90 requests/minute',
            'configured_limit': 90
        })
        
        # Overall status
        failed_tests = sum(1 for test in test_results['tests'] if test['status'] in ['failed', 'error'])
        test_results['overall_status'] = 'success' if failed_tests == 0 else 'failed'
        test_results['success_rate'] = f"{((len(test_results['tests']) - failed_tests) / len(test_results['tests']) * 100):.1f}%"
        test_results['total_time_ms'] = round((time.time() - start_time) * 1000, 2)
        
        return jsonify(test_results)
        
    except Exception as e:
        logger.error(f"AniList test failed: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({
            'source': 'anilist',
            'overall_status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/api/sources/syoboi/test', methods=['POST'])
def api_test_syoboi():
    """
    Test Syoboi Calendar API connection.
    
    Returns:
        JSON with test results including:
        - Connection status
        - Response time
        - Sample data retrieval
    """
    try:
        start_time = time.time()
        test_results = {
            'source': 'syoboi',
            'timestamp': datetime.now().isoformat(),
            'tests': []
        }
        
        # Test 1: Title lookup
        try:
            response = requests.get(
                'https://cal.syoboi.jp/json.php?Req=TitleLookup&TID=1',
                headers={'User-Agent': 'MangaAnimeNotifier/1.0'},
                timeout=5
            )
            lookup_time = time.time() - start_time
            
            test_results['tests'].append({
                'name': 'title_lookup',
                'status': 'success' if response.status_code == 200 else 'failed',
                'response_time_ms': round(lookup_time * 1000, 2),
                'http_status': response.status_code,
                'details': 'ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢APIã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ' if response.status_code == 200 else f'HTTP {response.status_code}'
            })
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    test_results['tests'][-1]['data_format'] = 'valid_json'
                except:
                    test_results['tests'][-1]['status'] = 'warning'
                    test_results['tests'][-1]['data_format'] = 'invalid_json'
                    
        except requests.exceptions.Timeout:
            test_results['tests'].append({
                'name': 'title_lookup',
                'status': 'failed',
                'response_time_ms': 5000,
                'error': 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (5ç§’)'
            })
        except Exception as e:
            test_results['tests'].append({
                'name': 'title_lookup',
                'status': 'error',
                'error': str(e)
            })
        
        # Test 2: Program lookup
        try:
            start_prog = time.time()
            response = requests.get(
                'https://cal.syoboi.jp/json.php?Req=ProgramByDate&Start=20240101&Days=1',
                headers={'User-Agent': 'MangaAnimeNotifier/1.0'},
                timeout=5
            )
            prog_time = time.time() - start_prog
            
            test_results['tests'].append({
                'name': 'program_lookup',
                'status': 'success' if response.status_code == 200 else 'failed',
                'response_time_ms': round(prog_time * 1000, 2),
                'http_status': response.status_code,
                'details': 'ç•ªçµ„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—æˆåŠŸ' if response.status_code == 200 else f'HTTP {response.status_code}'
            })
            
        except Exception as e:
            test_results['tests'].append({
                'name': 'program_lookup',
                'status': 'error',
                'error': str(e)
            })
        
        # Overall status
        failed_tests = sum(1 for test in test_results['tests'] if test['status'] in ['failed', 'error'])
        test_results['overall_status'] = 'success' if failed_tests == 0 else 'failed'
        test_results['success_rate'] = f"{((len(test_results['tests']) - failed_tests) / len(test_results['tests']) * 100):.1f}%"
        test_results['total_time_ms'] = round((time.time() - start_time) * 1000, 2)
        
        return jsonify(test_results)
        
    except Exception as e:
        logger.error(f"Syoboi test failed: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({
            'source': 'syoboi',
            'overall_status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/api/sources/rss/test', methods=['POST'])
def api_test_rss():
    """
    Test RSS feed connection.
    
    Request JSON:
        {
            "feed_id": "shonenjump_plus" or "feed_url": "https://..."
        }
    
    Returns:
        JSON with test results
    """
    try:
        data = request.get_json() or {}
        feed_id = data.get('feed_id')
        feed_url = data.get('feed_url')
        
        if not feed_id and not feed_url:
            return jsonify({'error': 'feed_id or feed_url is required'}), 400
        
        # Find feed configuration
        config = load_config()
        rss_feeds = config.get('apis', {}).get('rss_feeds', {}).get('feeds', [])
        
        feed_config = None
        if feed_id:
            # Convert feed_id to match name
            for feed in rss_feeds:
                if feed.get('name', '').lower().replace(' ', '_').replace('ï¼‹', 'plus') == feed_id.lower():
                    feed_config = feed
                    break
        
        if not feed_config and feed_url:
            # Use provided URL
            feed_config = {
                'name': 'Custom Feed',
                'url': feed_url,
                'timeout': 25,
                'enabled': True
            }
        elif not feed_config:
            return jsonify({'error': f'Feed not found: {feed_id}'}), 404
        
        start_time = time.time()
        test_results = {
            'source': feed_config.get('name', 'Unknown'),
            'url': feed_config.get('url'),
            'timestamp': datetime.now().isoformat(),
            'tests': []
        }
        
        # Test 1: HTTP connectivity
        try:
            response = requests.get(
                feed_config['url'],
                headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'},
                timeout=feed_config.get('timeout', 25),
                allow_redirects=True
            )
            http_time = time.time() - start_time
            
            test_results['tests'].append({
                'name': 'http_connectivity',
                'status': 'success' if response.status_code == 200 else 'failed',
                'response_time_ms': round(http_time * 1000, 2),
                'http_status': response.status_code,
                'content_type': response.headers.get('content-type', 'unknown'),
                'content_length': len(response.content),
                'details': f'HTTP {response.status_code}' + (f' (ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ: {response.url})' if response.url != feed_config['url'] else '')
            })
            
            # Test 2: RSS/XML parsing
            if response.status_code == 200:
                try:
                    import feedparser
                    feed_start = time.time()
                    parsed_feed = feedparser.parse(response.content)
                    parse_time = time.time() - feed_start
                    
                    entries_count = len(parsed_feed.get('entries', []))
                    has_title = bool(parsed_feed.get('feed', {}).get('title'))
                    
                    test_results['tests'].append({
                        'name': 'rss_parsing',
                        'status': 'success' if entries_count > 0 else 'warning',
                        'response_time_ms': round(parse_time * 1000, 2),
                        'entries_count': entries_count,
                        'feed_title': parsed_feed.get('feed', {}).get('title', 'N/A'),
                        'has_valid_structure': has_title and entries_count > 0,
                        'details': f'{entries_count}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¤œå‡º' if entries_count > 0 else 'ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
                    })
                    
                    # Sample entry details
                    if entries_count > 0:
                        sample_entry = parsed_feed.entries[0]
                        test_results['sample_entry'] = {
                            'title': sample_entry.get('title', 'N/A'),
                            'link': sample_entry.get('link', 'N/A'),
                            'published': sample_entry.get('published', 'N/A'),
                            'has_description': bool(sample_entry.get('description') or sample_entry.get('summary'))
                        }
                    
                except Exception as parse_error:
                    test_results['tests'].append({
                        'name': 'rss_parsing',
                        'status': 'error',
                        'error': str(parse_error),
                        'details': 'RSSãƒ‘ãƒ¼ã‚¹å¤±æ•—'
                    })
            
        except requests.exceptions.Timeout:
            test_results['tests'].append({
                'name': 'http_connectivity',
                'status': 'failed',
                'response_time_ms': feed_config.get('timeout', 25) * 1000,
                'error': f'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ({feed_config.get("timeout", 25)}ç§’)'
            })
        except Exception as e:
            test_results['tests'].append({
                'name': 'http_connectivity',
                'status': 'error',
                'error': str(e)
            })
        
        # Overall status
        failed_tests = sum(1 for test in test_results['tests'] if test['status'] in ['failed', 'error'])
        test_results['overall_status'] = 'success' if failed_tests == 0 else 'failed'
        test_results['success_rate'] = f"{((len(test_results['tests']) - failed_tests) / len(test_results['tests']) * 100):.1f}%"
        test_results['total_time_ms'] = round((time.time() - start_time) * 1000, 2)
        
        return jsonify(test_results)
        
    except Exception as e:
        logger.error(f"RSS test failed: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({
            'overall_status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500


@app.route('/api/sources/toggle', methods=['POST'])
def api_toggle_source():
    """
    Toggle a collection source on/off.
    
    Request JSON:
        {
            "source_type": "anilist" | "syoboi" | "rss_feed",
            "source_id": "feed_name_for_rss",  # Required only for RSS feeds
            "enabled": true | false
        }
    
    Returns:
        JSON with updated source configuration
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'Request body is required'}), 400
        
        source_type = data.get('source_type')
        source_id = data.get('source_id')
        enabled = data.get('enabled')
        
        if not source_type:
            return jsonify({'error': 'source_type is required'}), 400
        
        if enabled is None:
            return jsonify({'error': 'enabled is required'}), 400
        
        # Load current configuration
        config = load_config()
        
        updated = False
        
        if source_type == 'anilist':
            if 'apis' not in config:
                config['apis'] = {}
            if 'anilist' not in config['apis']:
                config['apis']['anilist'] = {}
            config['apis']['anilist']['enabled'] = bool(enabled)
            updated = True
            
        elif source_type == 'syoboi':
            if 'apis' not in config:
                config['apis'] = {}
            if 'syoboi' not in config['apis']:
                config['apis']['syoboi'] = {}
            config['apis']['syoboi']['enabled'] = bool(enabled)
            updated = True
            
        elif source_type == 'rss_feed':
            if not source_id:
                return jsonify({'error': 'source_id is required for RSS feeds'}), 400
            
            rss_feeds = config.get('apis', {}).get('rss_feeds', {}).get('feeds', [])
            
            for feed in rss_feeds:
                feed_key = feed.get('name', '').lower().replace(' ', '_').replace('ï¼‹', 'plus')
                if feed_key == source_id.lower():
                    feed['enabled'] = bool(enabled)
                    updated = True
                    break
            
            if not updated:
                return jsonify({'error': f'RSS feed not found: {source_id}'}), 404
        else:
            return jsonify({'error': f'Invalid source_type: {source_type}'}), 400
        
        # Save updated configuration
        if updated:
            save_config(config)
            
            return jsonify({
                'success': True,
                'source_type': source_type,
                'source_id': source_id,
                'enabled': enabled,
                'message': f'Source {"enabled" if enabled else "disabled"} successfully',
                'timestamp': datetime.now().isoformat()
            })
        else:
            return jsonify({'error': 'Failed to update configuration'}), 500
        
    except Exception as e:
        logger.error(f"Failed to toggle source: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({'error': str(e)}), 500


@app.route('/api/sources/test-all', methods=['POST'])
def api_test_all_sources():
    """
    Test all enabled collection sources in parallel.
    
    Returns:
        JSON with test results for all sources
    """
    try:
        import concurrent.futures
        
        config = load_config()
        results = {
            'timestamp': datetime.now().isoformat(),
            'sources': [],
            'summary': {
                'total': 0,
                'success': 0,
                'failed': 0,
                'errors': 0
            }
        }
        
        def test_source(source_info):
            """Test a single source"""
            source_type = source_info['type']
            source_id = source_info['id']
            
            try:
                if source_type == 'anilist':
                    response = requests.post(
                        '/api/sources/anilist/test',
                        json={},
                        headers={'Content-Type': 'application/json'}
                    )
                    # Since we can't make internal requests, call the test function directly
                    with app.test_request_context(method='POST'):
                        test_result = api_test_anilist()
                        return json.loads(test_result[0].get_data(as_text=True))
                        
                elif source_type == 'syoboi':
                    with app.test_request_context(method='POST'):
                        test_result = api_test_syoboi()
                        return json.loads(test_result[0].get_data(as_text=True))
                        
                elif source_type == 'rss':
                    with app.test_request_context(
                        method='POST',
                        json={'feed_id': source_id}
                    ):
                        test_result = api_test_rss()
                        return json.loads(test_result[0].get_data(as_text=True))
                        
            except Exception as e:
                return {
                    'source': source_id,
                    'overall_status': 'error',
                    'error': str(e)
                }
        
        # Collect enabled sources
        sources_to_test = []
        
        # APIs
        if config.get('apis', {}).get('anilist', {}).get('enabled', True):
            sources_to_test.append({'type': 'anilist', 'id': 'anilist'})
        
        if config.get('apis', {}).get('syoboi', {}).get('enabled', False):
            sources_to_test.append({'type': 'syoboi', 'id': 'syoboi'})
        
        # RSS Feeds
        rss_feeds = config.get('apis', {}).get('rss_feeds', {}).get('feeds', [])
        for feed in rss_feeds:
            if feed.get('enabled', False):
                feed_id = feed.get('name', '').lower().replace(' ', '_').replace('ï¼‹', 'plus')
                sources_to_test.append({'type': 'rss', 'id': feed_id})
        
        # Test sources in parallel
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            future_to_source = {
                executor.submit(test_source, source): source
                for source in sources_to_test
            }
            
            for future in concurrent.futures.as_completed(future_to_source, timeout=30):
                source = future_to_source[future]
                try:
                    result = future.result()
                    results['sources'].append(result)
                    
                    # Update summary
                    results['summary']['total'] += 1
                    status = result.get('overall_status', 'error')
                    if status == 'success':
                        results['summary']['success'] += 1
                    elif status == 'failed':
                        results['summary']['failed'] += 1
                    else:
                        results['summary']['errors'] += 1
                        
                except Exception as e:
                    results['sources'].append({
                        'source': source['id'],
                        'overall_status': 'error',
                        'error': str(e)
                    })
                    results['summary']['total'] += 1
                    results['summary']['errors'] += 1
        
        return jsonify(results)
        
    except Exception as e:
        logger.error(f"Failed to test all sources: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({'error': str(e)}), 500

if __name__ == "__main__":
    # Initialize database if it doesn't exist
    if not os.path.exists(DATABASE_PATH):
        logger.warning(
            f"Database {DATABASE_PATH} not found. Please run the main system first to initialize the database."
        )

    # Create logs directory if it doesn't exist
    os.makedirs("logs", exist_ok=True)

    # Run the Flask app
    app.run(debug=True, host="0.0.0.0", port=3030)
