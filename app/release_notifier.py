#!/usr/bin/env python3
"""
ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬æƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®å‡¦ç†ã‚’é †æ¬¡å®Ÿè¡Œã—ã¾ã™ï¼š
1. æƒ…å ±åé›†ï¼ˆAniList APIã€RSSã€ã—ã‚‡ã¼ã„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼‰
2. ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
4. æœªé€šçŸ¥ãƒªãƒªãƒ¼ã‚¹ã®é€šçŸ¥å‡¦ç†ï¼ˆGmail + Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼‰

Usage:
    python3 release_notifier.py [--config CONFIG_PATH] [--dry-run] [--verbose] [--force-send]

Environment Variables:
    DATABASE_PATH: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    LOG_LEVEL: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« (DEBUG, INFO, WARNING, ERROR)
    GMAIL_FROM_EMAIL: Gmailé€ä¿¡è€…ã‚¢ãƒ‰ãƒ¬ã‚¹
    GMAIL_TO_EMAIL: Gmailå—ä¿¡è€…ã‚¢ãƒ‰ãƒ¬ã‚¹
"""

import argparse
import logging
import signal
import sys
import time
import traceback
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

# ç’°å¢ƒå¤‰æ•°ã‚’.envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
from dotenv import load_dotenv

load_dotenv()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent  # app/ã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆï¼‰
sys.path.insert(0, str(project_root))

from modules import get_config
from modules.db import DatabaseManager
from modules.email_scheduler import EmailScheduler
from modules.logger import setup_logging

logger = logging.getLogger(__name__)


class ReleaseNotifierSystem:
    """ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬æƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(
        self,
        config_path: Optional[str] = None,
        dry_run: bool = False,
        force_send: bool = False,
    ):
        """
        ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–

        Args:
            config_path (Optional[str]): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            dry_run (bool): ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®é€šçŸ¥ã¯é€ä¿¡ã—ãªã„ï¼‰
            force_send (bool): å¼·åˆ¶é€ä¿¡ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ™‚åˆ»ã«é–¢ä¿‚ãªãé€ä¿¡ï¼‰
        """
        self.dry_run = dry_run
        self.force_send = force_send
        self.config = get_config(config_path)

        # ãƒ­ã‚°ã®è¨­å®š
        setup_logging(self.config)
        self.logger = logging.getLogger(__name__)

        self.logger.info("=" * 60)
        self.logger.info(
            f"ğŸš€ {self.config.get_system_name()} v{self.config.get_system_version()} é–‹å§‹"
        )
        self.logger.info(f"ç’°å¢ƒ: {self.config.get_environment()}")
        self.logger.info(f"ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if dry_run else 'ç„¡åŠ¹'}")
        self.logger.info("=" * 60)

        # è¨­å®šã®æ¤œè¨¼
        config_errors = self.config.validate_config()
        if config_errors:
            for error in config_errors:
                self.logger.error(f"è¨­å®šã‚¨ãƒ©ãƒ¼: {error}")
            raise ValueError("è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–
        self.db = DatabaseManager(self.config.get_db_path())

        # ãƒ¡ãƒ¼ãƒ«é…ä¿¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®åˆæœŸåŒ–
        self.email_scheduler = EmailScheduler(self.config)

        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–ï¼ˆé…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§å¾ªç’°å‚ç…§ã‚’å›é¿ï¼‰
        self._collectors = None
        self._mailer = None
        self._calendar = None
        self._filter = None
        self._email_generator = None

        self.start_time = datetime.now()
        self.statistics = {
            "processed_sources": 0,
            "new_works": 0,
            "new_releases": 0,
            "notifications_sent": 0,
            "calendar_events_created": 0,
            "filtered_items": 0,
            "errors": 0,
            # Phase 2: Enhanced statistics
            "duplicate_items_removed": 0,
            "total_processing_time": 0.0,
            "average_response_time": 0.0,
            "performance_grade": "N/A",
        }

    def _import_modules(self):
        """å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        if self._collectors is None:
            from modules.anime_anilist import AniListCollector
            from modules.calendar_integration import GoogleCalendarManager
            from modules.filter_logic import ContentFilter
            from modules.mailer import EmailTemplateGenerator, GmailNotifier
            from modules.manga_rss import MangaRSSCollector

            # è¨­å®šã‚’è¾æ›¸å½¢å¼ã§æ¸¡ã™
            config_dict = self.config._config_data if hasattr(self.config, "_config_data") else {}

            self._collectors = {
                "anilist": AniListCollector(config_dict),
                "manga_rss": MangaRSSCollector(self.config),
                # 'syoboi': syoboi_calendar.SyoboiCollector(self.config)  # å°†æ¥å®Ÿè£…
            }
            self._filter = ContentFilter(self.config)
            self._mailer = GmailNotifier(self.config)
            self._calendar = GoogleCalendarManager(self.config)
            self._email_generator = EmailTemplateGenerator(self.config)

            self.logger.info("ã™ã¹ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    def collect_information(self) -> List[Dict[str, Any]]:
        """
        å„ç¨®ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±åé›† - Phase 2 Performance Optimized

        Returns:
            List[Dict[str, Any]]: åé›†ã—ãŸä½œå“ãƒ»ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        self.logger.info("ğŸ“¡ æƒ…å ±åé›†ã‚’é–‹å§‹ã—ã¾ã™... (Phase 2 æœ€é©åŒ–ç‰ˆ)")
        self._import_modules()

        # Phase 2: Performance monitoring integration
        from modules.monitoring import add_monitoring_alert, record_api_performance

        all_items = []
        collection_start_time = time.time()

        for source_name, collector in self._collectors.items():
            source_start_time = time.time()
            try:
                self.logger.info(f"  {source_name} ã‹ã‚‰æƒ…å ±åé›†ä¸­...")

                if source_name == "anilist":
                    items = collector.collect()
                else:
                    items = collector.collect()

                source_duration = time.time() - source_start_time

                if items:
                    self.logger.info(
                        f"  {source_name}: {len(items)} ä»¶ã®æƒ…å ±ã‚’å–å¾— (æ™‚é–“: {source_duration:.2f}ç§’)"
                    )
                    all_items.extend(items)
                    self.statistics["processed_sources"] += 1

                    # Performance monitoring
                    record_api_performance(source_name.replace("_", ""), source_duration, True)
                else:
                    self.logger.warning(
                        f"  {source_name}: ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ (æ™‚é–“: {source_duration:.2f}ç§’)"
                    )
                    record_api_performance(source_name.replace("_", ""), source_duration, False)

                # Adaptive rate limiting based on performance
                if source_duration > 5.0:
                    self.logger.info(
                        f"  {source_name} ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé…ã„ãŸã‚ã€é•·ã‚ã®å¾…æ©Ÿæ™‚é–“ã‚’è¨­å®š"
                    )
                    time.sleep(3)  # Longer wait for slow services
                else:
                    time.sleep(1)  # Normal rate limiting

            except Exception as e:
                source_duration = time.time() - source_start_time
                self.logger.error(
                    f"  {source_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e} (æ™‚é–“: {source_duration:.2f}ç§’)"
                )
                self.statistics["errors"] += 1

                # Performance monitoring for errors
                record_api_performance(source_name.replace("_", ""), source_duration, False)
                add_monitoring_alert(f"ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {source_name} - {e}", "ERROR")

                if self.logger.isEnabledFor(logging.DEBUG):
                    self.logger.debug(traceback.format_exc())

        total_collection_time = time.time() - collection_start_time
        self.logger.info(
            f"ğŸ“¡ æƒ…å ±åé›†å®Œäº†: ç·è¨ˆ {len(all_items)} ä»¶ (ç·æ™‚é–“: {total_collection_time:.2f}ç§’)"
        )

        # Performance analysis and alerting
        if total_collection_time > 60:  # More than 1 minute
            add_monitoring_alert(f"æƒ…å ±åé›†ãŒé…ã„: {total_collection_time:.1f}ç§’", "WARNING")

        if len(all_items) == 0:
            add_monitoring_alert("æƒ…å ±åé›†ã§ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶", "WARNING")

        return all_items

    def process_and_filter_data(self, raw_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

        Args:
            raw_items (List[Dict[str, Any]]): åé›†ã—ãŸç”Ÿãƒ‡ãƒ¼ã‚¿

        Returns:
            List[Dict[str, Any]]: å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
        """
        self.logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™...")
        self._import_modules()

        processed_items = []

        for item in raw_items:
            try:
                # NGã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if self._filter.should_filter(item):
                    self.logger.debug(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é™¤å¤–: {item.get('title', 'ä¸æ˜')}")
                    self.statistics["filtered_items"] += 1
                    continue

                processed_items.append(item)

            except Exception as e:
                self.logger.error(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                self.statistics["errors"] += 1

        self.logger.info(
            f"ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {len(processed_items)} ä»¶ãŒæ®‹å­˜ ({len(raw_items) - len(processed_items)} ä»¶é™¤å¤–)"
        )
        return processed_items

    def save_to_database(self, items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã€æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã‚’è¿”ã™

        Args:
            items (List[Dict[str, Any]]): å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿

        Returns:
            List[Dict[str, Any]]: æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹æƒ…å ±
        """
        self.logger.info("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚’é–‹å§‹ã—ã¾ã™...")

        new_releases = []

        for item in items:
            try:
                # ä½œå“ã®å–å¾—ã¾ãŸã¯ä½œæˆ
                work_id = self.db.get_or_create_work(
                    title=item.get("title", ""),
                    title_kana=item.get("title_kana"),
                    title_en=item.get("title_en"),
                    work_type=item.get("type", "unknown"),
                    official_url=item.get("official_url"),
                )

                if work_id:
                    # ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã®ä¿å­˜
                    release_id = self.db.create_release(
                        work_id=work_id,
                        release_type=item.get(
                            "release_type",
                            "episode" if item.get("type") == "anime" else "volume",
                        ),
                        number=item.get("number"),
                        platform=item.get("platform"),
                        release_date=item.get("release_date"),
                        source=item.get("source"),
                        source_url=item.get("source_url"),
                    )

                    if release_id:
                        # æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹ã¨ã—ã¦è¿½åŠ 
                        release_info = item.copy()
                        release_info["release_id"] = release_id
                        release_info["work_id"] = work_id
                        new_releases.append(release_info)
                        self.statistics["new_releases"] += 1

                if item.get("is_new_work", False):
                    self.statistics["new_works"] += 1

            except Exception as e:
                self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                self.statistics["errors"] += 1

        self.logger.info(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: {len(new_releases)} ä»¶ã®æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹")
        return new_releases

    def send_notifications(
        self, new_releases: List[Dict[str, Any]], force_send: bool = False
    ) -> bool:
        """
        ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã¨ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã®ä½œæˆï¼ˆåˆ†æ•£é…ä¿¡å¯¾å¿œï¼‰

        Args:
            new_releases (List[Dict[str, Any]]): æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹æƒ…å ±
            force_send (bool): å¼·åˆ¶é€ä¿¡ãƒ•ãƒ©ã‚°ï¼ˆæ™‚åˆ»ã«é–¢ä¿‚ãªãé€ä¿¡ï¼‰

        Returns:
            bool: é€šçŸ¥å‡¦ç†ãŒæˆåŠŸã—ãŸå ´åˆTrue
        """
        if not new_releases:
            self.logger.info("ğŸ“§ æ–°ã—ã„ãƒªãƒªãƒ¼ã‚¹ãŒãªã„ãŸã‚ã€é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return True

        self.logger.info(f"ğŸ“§ åˆ†æ•£é…ä¿¡å¯¾å¿œé€šçŸ¥å‡¦ç†ã‚’é–‹å§‹: {len(new_releases)} ä»¶")
        self._import_modules()

        # é…ä¿¡è¨ˆç”»ã®ä½œæˆ
        batches = self.email_scheduler.plan_delivery(new_releases)

        if not batches:
            self.logger.warning("ğŸ“§ é…ä¿¡ãƒãƒƒãƒãŒä½œæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return False

        success = True
        sent_batches = 0

        try:
            # Gmailèªè¨¼
            if not self._mailer.authenticate():
                self.logger.error("Gmailèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False

            # Calendarèªè¨¼
            if not self._calendar.authenticate():
                self.logger.error("Google Calendarèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False

            # å„ãƒãƒƒãƒã®å‡¦ç†
            for batch in batches:
                should_send = force_send or self.email_scheduler.should_send_now(batch.schedule)

                if not should_send:
                    next_time = self.email_scheduler.get_next_delivery_time(batch.schedule)
                    self.logger.info(
                        f"ğŸ“§ ãƒãƒƒãƒ {batch.current_batch}/{batch.total_batches} ã¯ "
                        f"{batch.schedule.to_time_str()} é…ä¿¡äºˆå®š (æ¬¡å›: {next_time.strftime('%m/%d %H:%M')})"
                    )
                    continue

                # ãƒãƒƒãƒé…ä¿¡å®Ÿè¡Œ
                batch_success = self._send_batch(batch)

                if batch_success:
                    sent_batches += 1
                    self.email_scheduler.mark_batch_sent(batch.batch_id)
                    self.logger.info(
                        f"âœ… ãƒãƒƒãƒ {batch.current_batch}/{batch.total_batches} "
                        f"é…ä¿¡å®Œäº† ({len(batch.releases)} ä»¶)"
                    )
                else:
                    self.logger.error(
                        f"âŒ ãƒãƒƒãƒ {batch.current_batch}/{batch.total_batches} " "é…ä¿¡å¤±æ•—"
                    )
                    success = False

            # çµ±è¨ˆæ›´æ–°
            self.statistics["notifications_sent"] += sent_batches

            if sent_batches > 0:
                self.logger.info(f"ğŸ“§ åˆ†æ•£é…ä¿¡å®Œäº†: {sent_batches}/{len(batches)} ãƒãƒƒãƒé€ä¿¡")
            else:
                self.logger.info("ğŸ“§ é…ä¿¡æ™‚åˆ»ã§ã¯ãªã„ãŸã‚ã€ãƒãƒƒãƒé€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—")

        except Exception as e:
            self.logger.error(f"åˆ†æ•£é…ä¿¡å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            success = False

        return success

    def _send_batch(self, batch) -> bool:
        """
        å˜ä¸€ãƒãƒƒãƒã®é€ä¿¡å‡¦ç†

        Args:
            batch: EmailBatch ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

        Returns:
            bool: é€ä¿¡æˆåŠŸã®å ´åˆTrue
        """
        try:
            if not self.dry_run:
                # ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã®ä½œæˆã¨é€ä¿¡
                notification = self._email_generator.generate_release_notification(
                    batch.releases, subject_prefix=batch.get_subject_prefix()
                )

                if not self._mailer.send_notification(notification):
                    self.logger.error(f"ãƒãƒƒãƒ {batch.batch_id} ã®ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã«å¤±æ•—")
                    return False

                # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã®ä½œæˆ
                calendar_results = self._calendar.bulk_create_release_events(batch.releases)
                created_events = len([v for v in calendar_results.values() if v])

                if created_events > 0:
                    self.logger.info(f"âœ… ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’ {created_events} ä»¶ä½œæˆ")
                    self.statistics["calendar_events_created"] += created_events

                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®é€šçŸ¥æ¸ˆã¿ãƒ•ãƒ©ã‚°æ›´æ–°
                for release in batch.releases:
                    if "release_id" in release:
                        self.db.mark_release_notified(release["release_id"])

            else:
                self.logger.info(f"ğŸ”’ [DRY-RUN] ãƒãƒƒãƒ {batch.batch_id} ({len(batch.releases)} ä»¶)")

                # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ç”¨ã®è©³ç´°è¡¨ç¤º
                for release in batch.releases:
                    title = release.get("title", "ä¸æ˜ãªã‚¿ã‚¤ãƒˆãƒ«")
                    number = release.get("number", "")
                    platform = release.get("platform", "")
                    self.logger.info(f"  ğŸ“§ [DRY-RUN] {title} {number} ({platform})")

            return True

        except Exception as e:
            self.logger.error(f"ãƒãƒƒãƒé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def cleanup_old_data(self):
        """å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # è¨­å®šã‹ã‚‰ä¿æŒæœŸé–“ã‚’å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥ï¼‰
            retention_days = self.config.get_value("database.backup_retention_days", 30)
            cutoff_date = datetime.now() - timedelta(days=retention_days)

            cleaned_count = self.db.cleanup_old_releases(cutoff_date)
            if cleaned_count > 0:
                self.logger.info(f"ğŸ§¹ {cleaned_count} ä»¶ã®å¤ã„ãƒªãƒªãƒ¼ã‚¹æƒ…å ±ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def _format_delivery_stats(self) -> str:
        """åˆ†æ•£é…ä¿¡çµ±è¨ˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        try:
            stats = self.email_scheduler.get_delivery_stats()
            return """ç·ãƒãƒƒãƒæ•°: {stats['total_batches']}
  é€ä¿¡æ¸ˆã¿ãƒãƒƒãƒæ•°: {stats['sent_batches']}
  æœªé€ä¿¡ãƒãƒƒãƒæ•°: {stats['pending_batches']}
  å®Œäº†ç‡: {stats['completion_rate']:.1f}%
  æœ€çµ‚æ›´æ–°: {stats['last_update']}"""
        except Exception:
            return "çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼"

    def generate_report(self) -> str:
        """å®Ÿè¡Œçµæœãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ - Phase 2 Enhanced"""
        execution_time = datetime.now() - self.start_time

        # Phase 2: Enhanced monitoring integration
        from modules.monitoring import get_collection_health_status

        health_status = get_collection_health_status()

        # Calculate performance metrics
        items_per_second = (
            self.statistics["new_releases"] / execution_time.total_seconds()
            if execution_time.total_seconds() > 0
            else 0
        )
        error_rate = (
            self.statistics["errors"] / max(self.statistics["processed_sources"], 1)
        ) * 100

        report = """
{'=' * 60}
ğŸ“Š Phase 2 å®Ÿè¡Œçµæœãƒ¬ãƒãƒ¼ãƒˆ
{'=' * 60}
å®Ÿè¡Œæ™‚é–“: {execution_time.total_seconds():.1f}ç§’
é–‹å§‹æ™‚åˆ»: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
å®Œäº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ† ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ã‚°ãƒ¬ãƒ¼ãƒ‰: {health_status.get('system_health_grade', 'N/A')}

ğŸ“ˆ å‡¦ç†çµ±è¨ˆ:
  å‡¦ç†ã‚½ãƒ¼ã‚¹æ•°: {self.statistics['processed_sources']}
  æ–°ä½œå“æ•°: {self.statistics['new_works']}
  æ–°ãƒªãƒªãƒ¼ã‚¹æ•°: {self.statistics['new_releases']}
  ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é™¤å¤–æ•°: {self.statistics['filtered_items']}
  ğŸš€ å‡¦ç†é€Ÿåº¦: {items_per_second:.2f} ãƒªãƒªãƒ¼ã‚¹/ç§’

ğŸ“§ é€šçŸ¥çµ±è¨ˆ:
  ãƒ¡ãƒ¼ãƒ«é€šçŸ¥é€ä¿¡æ•°: {self.statistics['notifications_sent']}
  ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆæ•°: {self.statistics['calendar_events_created']}

âŒ ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ:
  ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå›æ•°: {self.statistics['errors']}
  ğŸ“‰ ã‚¨ãƒ©ãƒ¼ç‡: {error_rate:.1f}%

ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ:
  ç·ä½œå“æ•°: {self.db.get_work_stats().get('total', 0)}
  ç·ãƒªãƒªãƒ¼ã‚¹æ•°: {self.db.get_work_stats().get('total_releases', 0)}
  æœªé€šçŸ¥æ•°: {len(self.db.get_unnotified_releases(100))}

ğŸ“… åˆ†æ•£é…ä¿¡çµ±è¨ˆ:
  {self._format_delivery_stats()}

ğŸ“€ Phase 2 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™:
  ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚¢ã‚¯ãƒ†ã‚£ãƒ–: {health_status.get('monitoring_active', False)}
  ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {health_status.get('active_alerts_count', 0)} ä»¶
  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰: {health_status.get('performance_trend', 'N/A')}
"""

        # Add critical issues if any
        critical_issues = health_status.get("critical_issues", [])
        if critical_issues:
            report += """
âš ï¸ é‡è¦ãªå•é¡Œ:
"""
            for issue in critical_issues[:5]:  # Show max 5 issues
                report += f"  â€¢ {issue}\n"

        # Add collection performance details
        collection_perf = health_status.get("collection_performance", {})
        if collection_perf:
            report += """
ğŸ” åé›†ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:
"""
            for service, metrics in collection_perf.items():
                if any(v > 0 for v in metrics.values() if isinstance(v, (int, float))):
                    report += f"  {service}:\n"
                    if "requests" in metrics and metrics["requests"] > 0:
                        report += f"    ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {metrics['requests']}\n"
                    if "feeds_processed" in metrics and metrics["feeds_processed"] > 0:
                        report += f"    å‡¦ç†ãƒ•ã‚£ãƒ¼ãƒ‰æ•°: {metrics['feeds_processed']}\n"
                    if "queries" in metrics and metrics["queries"] > 0:
                        report += f"    ã‚¯ã‚¨ãƒªæ•°: {metrics['queries']}\n"
                    if "errors" in metrics:
                        report += f"    ã‚¨ãƒ©ãƒ¼æ•°: {metrics['errors']}\n"

        report += f"\n{'=' * 60}\n"
        return report.strip()

    def run(self) -> bool:
        """
        ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œå‡¦ç†

        Returns:
            bool: æ­£å¸¸ã«å®Œäº†ã—ãŸå ´åˆTrue
        """
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: æƒ…å ±åé›†
            raw_items = self.collect_information()

            # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            processed_items = self.process_and_filter_data(raw_items)

            # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            new_releases = self.save_to_database(processed_items)

            # ã‚¹ãƒ†ãƒƒãƒ—4: é€šçŸ¥å‡¦ç†
            force_send = getattr(self, "force_send", False)
            notification_success = self.send_notifications(new_releases, force_send=force_send)

            # ã‚¹ãƒ†ãƒƒãƒ—5: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.cleanup_old_data()

            # ã‚¹ãƒ†ãƒƒãƒ—6: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.email_scheduler.cleanup_old_state()

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = self.generate_report()
            self.logger.info(report)

            if self.statistics["errors"] > 0:
                self.logger.warning(f"âš ï¸ {self.statistics['errors']} ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")

            success = notification_success and self.statistics["errors"] == 0

            if success:
                self.logger.info("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            else:
                self.logger.error("âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")

            return success

        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
            return False
        except Exception as e:
            self.logger.error(f"ğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if self.logger.isEnabledFor(logging.DEBUG):
                self.logger.debug(traceback.format_exc())
            return False
        finally:
            # ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            try:
                if hasattr(self, "db") and self.db:
                    self.db.close()
            except Exception:
                pass

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        # ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            if hasattr(self, "db") and self.db:
                self.db.close()
        except Exception:
            pass


def signal_handler(signum, frame):
    """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    logger.info("\nğŸ›‘ çµ‚äº†ã‚·ã‚°ãƒŠãƒ«ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
    sys.exit(0)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # å¼•æ•°è§£æ
    parser = argparse.ArgumentParser(
        description="ã‚¢ãƒ‹ãƒ¡ãƒ»ãƒãƒ³ã‚¬æƒ…å ±é…ä¿¡ã‚·ã‚¹ãƒ†ãƒ ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""ä½¿ç”¨ä¾‹:
  python3 release_notifier.py                    # é€šå¸¸å®Ÿè¡Œ
  python3 release_notifier.py --dry-run          # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆé€šçŸ¥ãªã—ï¼‰
  python3 release_notifier.py --verbose          # è©³ç´°ãƒ­ã‚°
  python3 release_notifier.py --force-send       # å¼·åˆ¶é€ä¿¡ï¼ˆæ™‚åˆ»ç„¡è¦–ï¼‰
  python3 release_notifier.py --config custom.json --dry-run --verbose

åˆ†æ•£é…ä¿¡ã«ã¤ã„ã¦:
  ãƒ»100ä»¶ä»¥ä¸Šã®ãƒªãƒªãƒ¼ã‚¹: 2å›åˆ†æ•£ï¼ˆæœ8æ™‚ã€å¤œ20æ™‚ï¼‰
  ãƒ»200ä»¶ä»¥ä¸Šã®ãƒªãƒªãƒ¼ã‚¹: 3å›åˆ†æ•£ï¼ˆæœ8æ™‚ã€æ˜¼12æ™‚ã€å¤œ20æ™‚ï¼‰
  ãƒ»æ—¥æœ¬æ™‚é–“ï¼ˆAsia/Tokyoï¼‰ã§é…ä¿¡""",
    )

    parser.add_argument("--config", type=str, help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: config.json)")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®é€šçŸ¥ã¯é€ä¿¡ã—ãªã„ï¼‰",
    )
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›")
    parser.add_argument(
        "--force-send", action="store_true", help="æ™‚åˆ»ã«é–¢ä¿‚ãªãå¼·åˆ¶çš„ã«é€šçŸ¥ã‚’é€ä¿¡"
    )

    args = parser.parse_args()

    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®š
    if args.verbose:
        import os

        os.environ["LOG_LEVEL"] = "DEBUG"

    exit_code = 0

    try:
        # ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œ
        with ReleaseNotifierSystem(
            config_path=args.config, dry_run=args.dry_run, force_send=args.force_send
        ) as system:
            success = system.run()
            exit_code = 0 if success else 1

    except Exception as e:
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        exit_code = 2

    sys.exit(exit_code)


if __name__ == "__main__":
    main()
