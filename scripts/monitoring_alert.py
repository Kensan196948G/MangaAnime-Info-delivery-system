#!/usr/bin/env python3
"""
CI/CDç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 

ä¿®å¾©æˆåŠŸç‡ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã€ç•°å¸¸æ¤œçŸ¥ã€ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ã‚’è¡Œã„ã¾ã™ã€‚
"""

import argparse
import json
import logging
import os
import subprocess
import sys
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MetricsCollector:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, log_dir: Path = Path('logs')):
        self.log_dir = log_dir
        self.metrics = defaultdict(list)

    def collect_repair_metrics(self) -> Dict:
        """ä¿®å¾©ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        metrics = {
            'total_repairs': 0,
            'successful_repairs': 0,
            'failed_repairs': 0,
            'success_rate': 0.0,
            'average_loops': 0.0,
            'error_reduction_rate': 0.0,
            'recent_failures': []
        }

        # repair_summary.json ã‚’èª­ã¿è¾¼ã¿
        summary_files = list(self.log_dir.glob('repair_summary_*.json'))
        summary_files.append(Path('repair_summary.json'))

        valid_summaries = []

        for summary_file in summary_files:
            if summary_file.exists():
                try:
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        valid_summaries.append(data)
                except Exception as e:
                    logger.warning(f"{summary_file}ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

        if not valid_summaries:
            logger.warning("ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç”¨ã®ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return metrics

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        total_success = 0
        total_failed = 0
        total_loops = 0
        total_reduction = 0.0

        for summary in valid_summaries:
            final_status = summary.get('final_status', '')

            if final_status in ['success', 'partial_success', 'improved']:
                total_success += 1
            elif final_status == 'failed':
                total_failed += 1
                # æœ€è¿‘ã®å¤±æ•—ã‚’è¨˜éŒ²
                if len(metrics['recent_failures']) < 10:
                    metrics['recent_failures'].append({
                        'timestamp': summary.get('timestamp', ''),
                        'loops': summary.get('total_loops', 0),
                        'errors': len(summary.get('detected_errors', []))
                    })

            total_loops += summary.get('total_loops', 0)
            total_reduction += summary.get('error_reduction_rate', 0.0)

        metrics['total_repairs'] = len(valid_summaries)
        metrics['successful_repairs'] = total_success
        metrics['failed_repairs'] = total_failed
        metrics['success_rate'] = (total_success / len(valid_summaries) * 100) if valid_summaries else 0
        metrics['average_loops'] = total_loops / len(valid_summaries) if valid_summaries else 0
        metrics['error_reduction_rate'] = total_reduction / len(valid_summaries) if valid_summaries else 0

        return metrics

    def collect_ci_metrics(self) -> Dict:
        """CI/CDãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        metrics = {
            'total_runs': 0,
            'successful_runs': 0,
            'failed_runs': 0,
            'average_duration': 0.0,
            'recent_runs': []
        }

        # GitHub Actions ã®å®Ÿè¡Œå±¥æ­´ã‚’å–å¾—ï¼ˆgh CLIä½¿ç”¨ï¼‰
        try:
            result = subprocess.run(
                ['gh', 'run', 'list', '--limit', '50', '--json',
                 'conclusion,status,createdAt,updatedAt,name,databaseId'],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                runs = json.loads(result.stdout)

                for run in runs:
                    conclusion = run.get('conclusion', '')

                    if conclusion == 'success':
                        metrics['successful_runs'] += 1
                    elif conclusion in ['failure', 'timed_out', 'cancelled']:
                        metrics['failed_runs'] += 1

                    metrics['total_runs'] += 1

                    # æœ€è¿‘ã®å®Ÿè¡Œã‚’è¨˜éŒ²
                    if len(metrics['recent_runs']) < 10:
                        metrics['recent_runs'].append({
                            'name': run.get('name', ''),
                            'conclusion': conclusion,
                            'created_at': run.get('createdAt', '')
                        })

                # æˆåŠŸç‡è¨ˆç®—
                if metrics['total_runs'] > 0:
                    metrics['success_rate'] = (
                        metrics['successful_runs'] / metrics['total_runs'] * 100
                    )

        except Exception as e:
            logger.error(f"CI ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")

        return metrics


class AnomalyDetector:
    """ç•°å¸¸æ¤œçŸ¥ã‚¯ãƒ©ã‚¹"""

    def __init__(self, metrics: Dict):
        self.metrics = metrics
        self.anomalies = []

    def detect_continuous_failures(self, threshold: int = 10) -> bool:
        """é€£ç¶šå¤±æ•—ã‚’æ¤œçŸ¥"""
        recent_failures = self.metrics.get('recent_failures', [])

        if len(recent_failures) >= threshold:
            self.anomalies.append({
                'type': 'continuous_failures',
                'severity': 'critical',
                'message': f'ç›´è¿‘{len(recent_failures)}å›ã®ä¿®å¾©ãŒå¤±æ•—ã—ã¦ã„ã¾ã™',
                'threshold': threshold
            })
            return True

        return False

    def detect_low_success_rate(self, threshold: float = 50.0) -> bool:
        """æˆåŠŸç‡ä½ä¸‹ã‚’æ¤œçŸ¥"""
        success_rate = self.metrics.get('success_rate', 0.0)

        if success_rate < threshold:
            self.anomalies.append({
                'type': 'low_success_rate',
                'severity': 'high',
                'message': f'ä¿®å¾©æˆåŠŸç‡ãŒä½ä¸‹ã—ã¦ã„ã¾ã™: {success_rate:.1f}%',
                'threshold': threshold,
                'current_value': success_rate
            })
            return True

        return False

    def detect_high_loop_count(self, threshold: int = 8) -> bool:
        """ãƒ«ãƒ¼ãƒ—å›æ•°å¢—åŠ ã‚’æ¤œçŸ¥"""
        avg_loops = self.metrics.get('average_loops', 0.0)

        if avg_loops > threshold:
            self.anomalies.append({
                'type': 'high_loop_count',
                'severity': 'medium',
                'message': f'å¹³å‡ãƒ«ãƒ¼ãƒ—å›æ•°ãŒå¢—åŠ ã—ã¦ã„ã¾ã™: {avg_loops:.1f}',
                'threshold': threshold,
                'current_value': avg_loops
            })
            return True

        return False

    def detect_all_anomalies(self) -> List[Dict]:
        """ã™ã¹ã¦ã®ç•°å¸¸ã‚’æ¤œçŸ¥"""
        self.detect_continuous_failures(threshold=5)
        self.detect_low_success_rate(threshold=60.0)
        self.detect_high_loop_count(threshold=7)

        logger.info(f"{len(self.anomalies)}å€‹ã®ç•°å¸¸ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
        return self.anomalies


class AlertNotifier:
    """ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.notifications = []

    def send_github_notification(self, anomalies: List[Dict], metrics: Dict) -> bool:
        """GitHub Issue/Discussion ã«é€šçŸ¥"""
        if not anomalies:
            logger.info("ç•°å¸¸ãŒãªã„ãŸã‚ã€é€šçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return True

        # ç•°å¸¸ã®é‡å¤§åº¦åˆ¥ã«åˆ†é¡
        critical_anomalies = [a for a in anomalies if a['severity'] == 'critical']
        high_anomalies = [a for a in anomalies if a['severity'] == 'high']
        medium_anomalies = [a for a in anomalies if a['severity'] == 'medium']

        # Issueæœ¬æ–‡ã‚’ä½œæˆ
        issue_body = f"""
## ğŸš¨ CI/CDç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ©ãƒ¼ãƒˆ

**æ¤œçŸ¥æ™‚åˆ»**: {datetime.now().isoformat()}

### ç•°å¸¸ã‚µãƒãƒªãƒ¼
- **ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«**: {len(critical_anomalies)}
- **é«˜**: {len(high_anomalies)}
- **ä¸­**: {len(medium_anomalies)}

### æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸

"""

        for anomaly in anomalies:
            severity_emoji = {
                'critical': 'ğŸ”´',
                'high': 'ğŸŸ ',
                'medium': 'ğŸŸ¡'
            }.get(anomaly['severity'], 'âšª')

            issue_body += f"""
#### {severity_emoji} {anomaly['type'].replace('_', ' ').title()}
- **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: {anomaly['message']}
- **é‡å¤§åº¦**: {anomaly['severity']}
"""

            if 'threshold' in anomaly:
                issue_body += f"- **é–¾å€¤**: {anomaly['threshold']}\n"

            if 'current_value' in anomaly:
                issue_body += f"- **ç¾åœ¨å€¤**: {anomaly['current_value']:.1f}\n"

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æƒ…å ±ã‚’è¿½åŠ 
        issue_body += f"""

### ğŸ“Š ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹

| é …ç›® | å€¤ |
|------|-----|
| ç·ä¿®å¾©å›æ•° | {metrics.get('total_repairs', 0)} |
| æˆåŠŸå›æ•° | {metrics.get('successful_repairs', 0)} |
| å¤±æ•—å›æ•° | {metrics.get('failed_repairs', 0)} |
| æˆåŠŸç‡ | {metrics.get('success_rate', 0):.1f}% |
| å¹³å‡ãƒ«ãƒ¼ãƒ—å›æ•° | {metrics.get('average_loops', 0):.1f} |
| ã‚¨ãƒ©ãƒ¼å‰Šæ¸›ç‡ | {metrics.get('error_reduction_rate', 0):.1f}% |

### æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
1. ç›´è¿‘ã®å¤±æ•—ãƒ­ã‚°ã‚’ç¢ºèª
2. ä¿®å¾©ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¦‹ç›´ã—
3. ãƒ†ã‚¹ãƒˆç’°å¢ƒã§å†ç¾ç¢ºèª
4. å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ä»‹å…¥

---
ğŸ¤– è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸã‚¢ãƒ©ãƒ¼ãƒˆ
"""

        # GitHub Issueä½œæˆ
        try:
            result = subprocess.run(
                ['gh', 'issue', 'create',
                 '--title', f'ğŸš¨ CI/CDç•°å¸¸æ¤œçŸ¥ - {datetime.now().strftime("%Y-%m-%d %H:%M")}',
                 '--body', issue_body,
                 '--label', 'alert,monitoring,auto-repair'],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                logger.info("GitHub Issue ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ")
                return True
            else:
                logger.error(f"GitHub Issue ä½œæˆå¤±æ•—: {result.stderr}")
                return False

        except Exception as e:
            logger.error(f"GitHub é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def send_slack_notification(self, anomalies: List[Dict], webhook_url: str) -> bool:
        """Slack Webhook ã«é€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"""
        if not webhook_url:
            logger.info("Slack Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False

        try:
            import requests

            critical_count = len([a for a in anomalies if a['severity'] == 'critical'])

            payload = {
                'text': f'ğŸš¨ CI/CDç•°å¸¸æ¤œçŸ¥: {len(anomalies)}å€‹ã®ç•°å¸¸ã‚’æ¤œå‡º',
                'blocks': [
                    {
                        'type': 'section',
                        'text': {
                            'type': 'mrkdwn',
                            'text': f'*CI/CDç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ©ãƒ¼ãƒˆ*\n{len(anomalies)}å€‹ã®ç•°å¸¸ã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼ˆã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«: {critical_count}ï¼‰'
                        }
                    }
                ]
            }

            for anomaly in anomalies[:5]:  # æœ€åˆã®5å€‹ã®ã¿
                payload['blocks'].append({
                    'type': 'section',
                    'text': {
                        'type': 'mrkdwn',
                        'text': f"*{anomaly['type']}*: {anomaly['message']}"
                    }
                })

            response = requests.post(webhook_url, json=payload, timeout=10)

            if response.status_code == 200:
                logger.info("Slacké€šçŸ¥ã‚’é€ä¿¡ã—ã¾ã—ãŸ")
                return True
            else:
                logger.error(f"Slacké€šçŸ¥å¤±æ•—: {response.status_code}")
                return False

        except ImportError:
            logger.warning("requests ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        except Exception as e:
            logger.error(f"Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
            return False


def main():
    parser = argparse.ArgumentParser(description='CI/CDç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ')
    parser.add_argument('--collect-metrics', action='store_true',
                        help='ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†')
    parser.add_argument('--detect-anomalies', action='store_true',
                        help='ç•°å¸¸ã‚’æ¤œçŸ¥')
    parser.add_argument('--send-alerts', action='store_true',
                        help='ã‚¢ãƒ©ãƒ¼ãƒˆã‚’é€ä¿¡')
    parser.add_argument('--slack-webhook', type=str,
                        help='Slack Webhook URL')
    parser.add_argument('--all', action='store_true',
                        help='ã™ã¹ã¦ã®ç›£è¦–ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ')

    args = parser.parse_args()

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    collector = MetricsCollector()
    repair_metrics = collector.collect_repair_metrics()
    ci_metrics = collector.collect_ci_metrics()

    combined_metrics = {**repair_metrics, **ci_metrics}

    logger.info("\n" + "="*60)
    logger.info("ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å®Œäº†")
    logger.info(f"  ç·ä¿®å¾©å›æ•°: {repair_metrics['total_repairs']}")
    logger.info(f"  æˆåŠŸç‡: {repair_metrics['success_rate']:.1f}%")
    logger.info(f"  å¹³å‡ãƒ«ãƒ¼ãƒ—å›æ•°: {repair_metrics['average_loops']:.1f}")
    logger.info("="*60)

    # ç•°å¸¸æ¤œçŸ¥
    if args.detect_anomalies or args.all:
        detector = AnomalyDetector(combined_metrics)
        anomalies = detector.detect_all_anomalies()

        # ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
        if (args.send_alerts or args.all) and anomalies:
            notifier = AlertNotifier()
            notifier.send_github_notification(anomalies, combined_metrics)

            # Slacké€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            slack_webhook = args.slack_webhook or os.environ.get('SLACK_WEBHOOK_URL')
            if slack_webhook:
                notifier.send_slack_notification(anomalies, slack_webhook)

    # çµæœã‚’JSONã§ä¿å­˜
    output = {
        'timestamp': datetime.now().isoformat(),
        'metrics': combined_metrics,
        'anomalies': detector.anomalies if args.detect_anomalies or args.all else []
    }

    with open('monitoring_report.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)

    logger.info("ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆã‚’ monitoring_report.json ã«ä¿å­˜ã—ã¾ã—ãŸ")

    sys.exit(0)


if __name__ == '__main__':
    main()
