name: CI Pipeline (Improved)
# æ”¹å–„ã•ã‚ŒãŸCIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ - ãƒãƒ«ãƒPythonã€ã‚«ãƒãƒ¬ãƒƒã‚¸å¼·åˆ¶ã€ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ãƒ†ã‚¹ãƒˆ

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

permissions:
  contents: read
  checks: write
  pull-requests: write

jobs:
  lint:
    name: ğŸ” Code Quality Checks
    runs-on: ubuntu-latest

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸ Setup Python 3.13
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'

    - name: ğŸ“¦ Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black bandit safety

    - name: ğŸ¨ Check code formatting (Black)
      run: black --check modules/ tests/
      continue-on-error: true

    - name: ğŸ” Run Flake8
      run: |
        flake8 modules/ tests/ \
          --count \
          --select=E9,F63,F7,F82 \
          --show-source \
          --statistics

    - name: ğŸ”’ Security scan (Bandit)
      run: |
        bandit -r modules/ -f json -o bandit-report.json
      continue-on-error: true

    - name: ğŸ“Š Upload security report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-report
        path: bandit-report.json

  test:
    name: ğŸ§ª Tests (Python ${{ matrix.python-version }} on ${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        python-version: ['3.10', '3.11', '3.12', '3.13']

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸ Setup Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: ğŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov pytest-mock pytest-xdist faker

    - name: ğŸ§ª Run tests with coverage
      run: |
        pytest tests/ \
          -v \
          --cov=modules \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=25 \
          --tb=short \
          -n auto
      continue-on-error: ${{ matrix.os == 'windows-latest' }}

    - name: ğŸ“Š Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.13' && matrix.os == 'ubuntu-latest'
      with:
        files: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

    - name: ğŸ“ˆ Upload coverage HTML
      uses: actions/upload-artifact@v4
      if: matrix.python-version == '3.13' && matrix.os == 'ubuntu-latest'
      with:
        name: coverage-report
        path: htmlcov/

    - name: ğŸ“‹ Generate test report
      if: always()
      run: |
        pytest tests/ \
          --tb=no \
          --junitxml=pytest-report.xml \
          --html=pytest-report.html \
          --self-contained-html
      continue-on-error: true

    - name: ğŸ“Š Publish test results
      uses: EnricoMi/publish-unit-test-result-action@v2
      if: always() && matrix.os == 'ubuntu-latest' && matrix.python-version == '3.13'
      with:
        files: pytest-report.xml

  integration-tests:
    name: ğŸ”— Integration Tests
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸ Setup Python 3.13
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'

    - name: ğŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-mock faker

    - name: ğŸ”— Run integration tests
      run: |
        pytest tests/ \
          -v \
          -m "integration" \
          --tb=short
      continue-on-error: true

  performance-tests:
    name: âš¡ Performance Tests
    runs-on: ubuntu-latest
    needs: test

    steps:
    - name: ğŸ“¥ Checkout repository
      uses: actions/checkout@v4

    - name: ğŸ Setup Python 3.13
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'

    - name: ğŸ“¦ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-benchmark pytest-asyncio faker

    - name: âš¡ Run performance tests
      run: |
        pytest tests/ \
          -v \
          -m "performance" \
          --benchmark-only \
          --benchmark-json=benchmark-result.json
      continue-on-error: true

    - name: ğŸ“Š Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: benchmark-result.json

  summary:
    name: ğŸ“‹ Test Summary
    runs-on: ubuntu-latest
    needs: [lint, test, integration-tests, performance-tests]
    if: always()

    steps:
    - name: âœ… All checks passed
      if: ${{ needs.test.result == 'success' }}
      run: |
        echo "âœ… All tests passed successfully!"
        echo "Coverage threshold met (60%+)"
        echo "Ready for deployment"

    - name: âš ï¸ Some checks failed
      if: ${{ needs.test.result != 'success' }}
      run: |
        echo "âš ï¸ Some tests failed"
        echo "Please review the test results above"
        exit 1
